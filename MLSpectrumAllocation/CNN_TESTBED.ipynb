{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# IMPORTS\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras import layers, models, Input\n",
    "from keras import backend as K\n",
    "from keras import regularizers\n",
    "from keras.utils import Sequence\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from collections import namedtuple\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import datetime, time\n",
    "import os, sys\n",
    "import tqdm\n",
    "import gc\n",
    "from multiprocessing import Process\n",
    "Point = namedtuple('Point', ('x', 'y'))\n",
    "Circle = namedtuple('Circle', ('r'))\n",
    "Square = namedtuple('Square', ('side'))\n",
    "Rectangle = namedtuple('Rectangle', ('length', 'width'))\n",
    "PointWithDistance = namedtuple('PointWithDistance', ('p', 'dist'))\n",
    "float_memory_used = 'float16'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INIT\n",
    "# PART 1\n",
    "# number_samples = [5] + list(range(10, 101, 10)) + [120, 150, 200, 250, 300, 400, 500, 700] + list(range(1000, 10001, 1000))\n",
    "number_samples = [30, 60, 90, 120, 150, 180, 210] \n",
    "# number_samples = [4096, 4915, 5734, 6554, 7373, 8192]\n",
    "\n",
    "# cnn_type = \"classification\"  # {\"classification\", \"regression\"}\n",
    "validation_size, noise_floor = 0.2, -90.0#-110.0\n",
    "su_power = 0 # this is not actually su power just a number to show there is an SU in its image\n",
    "max_x, max_y, number_image_channels, su_szie = 100, 100, 5, 10  # su_size:30 for 1000, 10 for 100\n",
    "cell_size = int(max(max_x, max_y)/10)\n",
    "pu_shape, su_shape = 'circle', 'circle' # shape = {'circle', 'square', 'point'}\n",
    "style = \"raw_power_min_max_norm\"  # {\"raw_power_zscore_norm\", \"image_intensity\", \"raw_power_min_max_norm\"}\n",
    "intensity_degradation, slope = 'log', 5  # 'log', 'linear', slope 3 for 1000, 5 for 100\n",
    "max_pus_num, max_sus_num = 4, 1\n",
    "propagation_model = 'testbed' # 'splat', 'log', 'testbed'\n",
    "noise, std = False, 1 # False for splat\n",
    "if su_shape == 'circle':\n",
    "    su_param = Circle(su_szie)\n",
    "elif su_shape == 'square':\n",
    "    su_param = Square(su_szie)\n",
    "else:\n",
    "    su_param = None\n",
    "    \n",
    "sensors = False\n",
    "if sensors:\n",
    "    sensors_num = 18\n",
    "    sensors_file_path = \"rsc/sensors/\" + str(max(max_x, max_y)) + \"/\" + str(sensors_num) + \"/sensors\"\n",
    "# num_pus = (data_reg.shape[1] - 3)//3\n",
    "\n",
    "# PART 2\n",
    "number_of_proccessors = 5\n",
    "memory_size_allowed = 4 # in Gigabyte\n",
    "float_size = 0\n",
    "if float_memory_used == \"float16\":\n",
    "    float_size = 16\n",
    "elif float_memory_used == \"float\" or \"float32\":\n",
    "    float_size = 32\n",
    "elif float_memory_used == \"float8\":\n",
    "    float_size = 8\n",
    "\n",
    "\n",
    "batch_size = int(memory_size_allowed / (max_x * max_y * number_image_channels * float_size/(8 * 1024 ** 3)))\n",
    "\n",
    "\n",
    "dtime = datetime.datetime.now().strftime('_%Y%m_%d%H_%M')\n",
    "color = \"color\" if number_image_channels > 1 else \"gray\"\n",
    "image_dir = 'ML/data/pictures_' + str(max_x) + '_' + str(max_y) + '/' + propagation_model + (\n",
    "    \"/noisy_std_\" + str(std) if noise else \"\") + '/pu_' + pu_shape + '_su_' + su_shape + '_' + (\n",
    "    \"\" if su_shape == 'point' else str(su_szie)) + \"/\" + style + \"/\" + color +'/' + (\n",
    "    \"\" if pu_shape == 'point' and su_shape == 'point' else (intensity_degradation + '_' + str(slope))) + (\n",
    "    \"/\" + str(sensors_num) + \"sensors\" if sensors else \"/pus\") + \"/images\"\n",
    "\n",
    "if not os.path.exists(image_dir):\n",
    "        os.makedirs(image_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/images'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-48.2, -48.38, ' -48.37', ' -48.44', -48.41, -47.95, -48.37, -48.4,\n",
       "       -48.08, -48.23, ' -48.28', -47.93, -48.47, -48.03, -48.31, ' nan',\n",
       "       ' -48.14', -48.32, 2.0, 8.0, 26], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe_sensor.values[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  8.  6. 66.  9.  6. 34. nan nan nan nan nan nan nan nan 34.]\n",
      "[-48.18 -48.29 -48.33 -48.18 -48.23 -48.33 -47.68 -48.31 -48.28 -48.34\n",
      " -48.39 -48.42 -48.41 -48.37 -48.36 -48.32 -48.37 -48.37 9.0 6.0 34]\n"
     ]
    }
   ],
   "source": [
    "print(data_reg[46])\n",
    "print(data_reg_sensor[46])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shahrokh/anaconda3/envs/research/lib/python3.7/site-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in less\n"
     ]
    }
   ],
   "source": [
    "# LOAD DATA\n",
    "num_columns = (sensors_num if sensors else max_pus_num * 3 + 1) + max_sus_num * 3\n",
    "cols = [i for i in range(num_columns)]\n",
    "dataset_name = \"testbed_pu_1\"\n",
    "# max_dataset_name = \"dynamic_pus_max_power_60000_min10_max20PUs_1SUs_square100grid_splat_2020_06_28_13_45.txt\"\n",
    "with open('/'.join(image_dir.split('/')[:-1]) + '/datasets' + dtime + '.txt', 'w') as set_file:\n",
    "    set_file.write(dataset_name + \"\\n\")\n",
    "#     set_file.write(max_dataset_name)\n",
    "\n",
    "dataframe = pd.read_csv('ML/data/'\n",
    "                        + dataset_name, delimiter=',', header=None, names=cols)\n",
    "# dataframe_max = pd.read_csv('../../../java_workspace/research/spectrum_allocation/resources/data/'\n",
    "#                             + max_dataset_name, delimiter=',', header=None)\n",
    "\n",
    "dataframe.reset_index(drop=True, inplace=True)\n",
    "# dataframe_max.reset_index(drop=True, inplace=True)\n",
    "# dataframe_max[dataframe_max.shape[1] - 1] = dataframe_max[dataframe_max.shape[1] - 1].astype(float)\n",
    "\n",
    "# dataframe_tot = pd.concat([dataframe, dataframe_max.iloc[:, dataframe_max.columns.values[-1:]]], axis=1,\n",
    "#                         ignore_index=True)\n",
    "\n",
    "# idx = dataframe_tot[dataframe_tot[dataframe_tot.columns[-1]] == -float('inf')].index\n",
    "# dataframe_tot.drop(idx, inplace=True)\n",
    "dataframe = dataframe.sample(frac=1).reset_index(drop=True)\n",
    "data_reg = dataframe.values\n",
    "data_reg[data_reg < noise_floor] = noise_floor\n",
    "# data_reg = np.concatenate((dataframe_tot.values[:, 0:dataframe_tot.shape[1]-3], \n",
    "#                            dataframe_tot.values[:, dataframe_tot.shape[1]-1:dataframe_tot.shape[1]]), axis=1)\n",
    "# data_class = dataframe_tot.values[:, 0:dataframe_tot.shape[1]-1]\n",
    "# y_class_power = dataframe_tot.values[:, -1]\n",
    "\n",
    "if sensors:\n",
    "    sensors_location = []\n",
    "    with open(sensors_file_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            line = line.split(',')\n",
    "            sensors_location.append(Point(int(float(line[0])), int(float(line[1]))))\n",
    "if not sensors:\n",
    "    for sample_idx in range(data_reg.shape[0]):\n",
    "        data_reg[sample_idx][-1] = data_reg[sample_idx][int(data_reg[sample_idx][0]) * 3 + 3]\n",
    "        \n",
    "del dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(299, 16)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_reg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_reg = np.concatenate((data_reg[:,:2500], np.ones((4000, 1)), data_reg[:, 2500:2504],\n",
    "               data_reg[:, 2505:]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_reg[0, sensors_num:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_reg = data_reg[:][:30000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_reg[512:1024, :] = data_reg[:512, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_reg[4096:8192, sensors_num:] = data_reg[:4096, sensors_num:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_reg[10, :])\n",
    "print(data_reg[266, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidian_distance(p1: Point, p2: Point):\n",
    "    return ((p1.x - p2.x) ** 2 + (p1.y - p2.y) ** 2) ** 0.5\n",
    "\n",
    "def calculate_mu_sigma(data, num_pus):\n",
    "    sum_non_noise = 0\n",
    "    for pu_n in range(num_pus): # calculate mu\n",
    "        sum_non_noise += data[pu_n*3+2]\n",
    "    mu = ((max_x * max_y - num_pus) * noise_floor + sum_non_noise)/(max_x * max_y)\n",
    "    sum_square = 0\n",
    "    for pu_n in range(num_pus): # calculate sigma\n",
    "        sum_square += (data[pu_n*3+2]-mu)**2\n",
    "    sum_square += (max_x * max_y - num_pus) * (noise_floor - mu)**2\n",
    "    sigma = math.sqrt(sum_square/(max_x * max_y))\n",
    "    return mu, sigma\n",
    "\n",
    "def get_pu_param(pu_shape: str, intensity_degradation: str, pu_p: float, noise_floor: float, slope: float):\n",
    "    pu_param = None\n",
    "    if pu_shape == 'circle':\n",
    "        if intensity_degradation == \"linear\":\n",
    "            pu_param = Circle(int((pu_p - noise_floor) / slope)) # linear\n",
    "        elif intensity_degradation == \"log\":\n",
    "            pu_param = Circle(int(10 ** ((pu_p - noise_floor) / (10 *slope)))) # log_based\n",
    "    elif pu_shape == 'square':\n",
    "        if intensity_degradation == \"linear\":\n",
    "            pu_param = Square(int(2 ** 0.5 * (pu_p - noise_floor) / slope)) # linear\n",
    "        elif intensity_degradation == \"log\":\n",
    "            pu_param = Square(int(2 ** 0.5 * 10 ** ((pu_p - noise_floor) / (10 *slope)))) # log_based\n",
    "    elif pu_shape == 'point':\n",
    "        pu_param = None\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported PU shape(create_image)! \", pu_shape)\n",
    "    return pu_param\n",
    "\n",
    "def create_image(data, slope, sensors_num, style=\"raw_power_z_score\", noise_floor=-90, pu_shape= 'circle', pu_param=None, \n",
    "                 su_shape='circle', su_param=None, intensity_degradation=\"log\", max_pu_power: float=0):  \n",
    "    # style = {\"raw_power_zscore_norm\", \"image_intensity\", \"raw_power_min_max_norm\"}\n",
    "    # intensity_degradation= {\"log\", \"linear\"}\n",
    "    # if param is None, it's automatically calculated. Highest brightness(or power value) (255 or 1.) would\n",
    "    # assigned to the center(PU location) and radius(side) would be calculated based on its power, slope, and noise floor.\n",
    "    # If it is given, intensity(power) of pixel beside center would be calculated in the same fashin with an exception that \n",
    "    # intensity below zero(noise_floor) would be replaced by zero(noise_floor)\n",
    "    if style == \"raw_power_min_max_norm\":\n",
    "        # In this way, PUs' location are replaced with their power(dBm) and the power would fade with \n",
    "        # slope till gets noise_floor(in circle shape)\n",
    "        \n",
    "        # creating pu matrix\n",
    "        image = np.zeros((1,number_image_channels,max_x, max_y), dtype=float_memory_used)\n",
    "        if not sensors:\n",
    "            pus_num = int(data[0])\n",
    "            pus_cluster = [(7, 7), (7, 2), (2, 2), (2, 7)]\n",
    "#             print(pus_num)\n",
    "            for pu_i in range(pus_num):\n",
    "                pu_x = max(0, min(max_x-1, int(data[pu_i * 3 + 1]))) \n",
    "                pu_y = max(0, min(max_x-1, int(data[pu_i * 3 + 2])))\n",
    "                pus_dist_cluster = [math.sqrt((pu_x - x)**2 + (pu_y - y)**2) for x,y in pus_cluster]\n",
    "                pu_p = data[pu_i * 3 + 3]\n",
    "                pu_channel_idx = pus_dist_cluster.index(min(pus_dist_cluster))\n",
    "                pu_x *= cell_size\n",
    "                pu_y *= cell_size\n",
    "#                 print(pu_x, pu_y, pu_p)\n",
    "                if pu_param is None:\n",
    "                    pu_param_p = get_pu_param(pu_shape, intensity_degradation, pu_p, noise_floor, slope)\n",
    "                else:\n",
    "                    pu_param_p = pu_param\n",
    "                points = points_inside_shape(center=Point(pu_x, pu_y), shape=pu_shape, param=pu_param_p)\n",
    "                for point in points:\n",
    "                    if 0 <= point.p.x < max_x and 0 <= point.p.y < max_y: # TODO should pass image size\n",
    "                        if intensity_degradation == \"linear\":\n",
    "                            image[0][pu_channel_idx][point.p.x][point.p.y] += (pu_p - slope * point.dist - noise_floor)/(\n",
    "                                max_pu_power - noise_floor)\n",
    "                        elif intensity_degradation == \"log\":\n",
    "                            if point.dist < 1:\n",
    "                                image[0][pu_channel_idx][point.p.x][point.p.y] += (pu_p - noise_floor) / (max_pu_power - noise_floor)\n",
    "                            else:\n",
    "                                image[0][pu_channel_idx][point.p.x][point.p.y] += (pu_p - slope * 10*math.log10(point.dist) - noise_floor)/(\n",
    "                                    max_pu_power - noise_floor)\n",
    "        else:\n",
    "            ss_param, ss_shape = pu_param, pu_shape\n",
    "            for ss_i in range(sensors_num):\n",
    "                ss_x, ss_y, ss_p = max(0, min(max_x-1, int(sensors_location[ss_i].x))), max(0, min(max_x-1, int(\n",
    "                    sensors_location[ss_i].y))), max(noise_floor, data[ss_i])\n",
    "                ss_channel = 0 \n",
    "                if -62.5 <= ss_p < -50.0:\n",
    "                    ss_channel = 1\n",
    "                elif -75.0 <= ss_p < -62.6:\n",
    "                    ss_channel = 2\n",
    "                elif -87.5 <= ss_p < -75.0:\n",
    "                    ss_channel = 3\n",
    "                elif -100.0 <= ss_p < -87.5:\n",
    "                    ss_channel = 4\n",
    "#                 elif -70.0 <= ss_p < -65.0:\n",
    "#                     ss_channel = 5\n",
    "                elif ss_p < -100.0:\n",
    "                    ss_channel = 5\n",
    "                if ss_param is None:\n",
    "                    ss_param_p = get_pu_param(ss_shape, intensity_degradation, ss_p, noise_floor, slope)\n",
    "                else:\n",
    "                    ss_param_p = ss_param\n",
    "                points = points_inside_shape(center=Point(ss_x, ss_y), shape=ss_shape, param=ss_param_p)\n",
    "                for point in points:\n",
    "                    if 0 <= point.p.x < max_x and 0 <= point.p.y < max_y: # TODO should pass image size\n",
    "                        if intensity_degradation == \"linear\":\n",
    "                            image[0][ss_channel][point.p.x][point.p.y] += (ss_p - slope * point.dist - noise_floor)/(\n",
    "                                max_pu_power - noise_floor)\n",
    "                        elif intensity_degradation == \"log\":\n",
    "                            if point.dist < 1:\n",
    "                                image[0][ss_channel][point.p.x][point.p.y] += (ss_p - noise_floor) / (max_pu_power - noise_floor)\n",
    "                            else:\n",
    "                                image[0][ss_channel][point.p.x][point.p.y] += (ss_p - slope * 10*math.log10(point.dist) - noise_floor)/(\n",
    "                                    max_pu_power - noise_floor)\n",
    "        del points\n",
    "        # creating su matrix\n",
    "        su_num_idx = sensors_num if sensors else (pus_num * 3 + 1) - 1\n",
    "        su_num = 1\n",
    "#         print(su_num)\n",
    "#         su_num = (len(data) - pus_num * (3 if not sensors else 1)) // 2\n",
    "#         if not (len(data) - pus_num * (3 if not sensors else 1)) % 2:\n",
    "#             raise ValueError(\"Data provided is not correct; can't get SUs' information(create_image)\")\n",
    "        if su_param is None:\n",
    "            # if su_param is unavailable, a circle(square) with radius(side) 1 is created\n",
    "            if su_shape == 'circle':\n",
    "                su_param = Circle(1)\n",
    "            elif su_shape == 'square':\n",
    "                su_param = Square(1)\n",
    "            elif su_shape == 'point':\n",
    "                su_param = None\n",
    "            else:\n",
    "                raise ValueError(\"Unsupported SU shape(create_image)! \", su_shape)\n",
    "        \n",
    "        for su_i in range(su_num - 1):\n",
    "            su_x = max(0, min(max_x-1, int(data[su_num_idx + su_i * 3 + 1])))\n",
    "            su_y = max(0, min(max_x-1, int(data[su_num_idx + su_i * 3 + 2])))\n",
    "            su_p = data[su_num_idx + su_i * 3 + 3]\n",
    "#             su_p = su_intensity\n",
    "            points = points_inside_shape(center=Point(su_x, su_y), param=su_param, shape=su_shape)\n",
    "            su_channel = 0 if number_image_channels == 1 else -1\n",
    "            for point in points:\n",
    "                if 0 <= point.p.x < max_x and 0 <= point.p.y < max_y: # TODO should pass image size\n",
    "                    if intensity_degradation == \"linear\":\n",
    "                            su_val = (su_p - slope * point.dist - noise_floor)/(max_pu_power - noise_floor)\n",
    "                    elif intensity_degradation == \"log\":\n",
    "                        if point.dist < 1:\n",
    "                            su_val = (su_p - noise_floor) / (max_pu_power - noise_floor)\n",
    "                        else:\n",
    "                            su_val = (su_p - slope * 10*math.log10(point.dist) - noise_floor)/(\n",
    "                                max_pu_power - noise_floor)\n",
    "                    image[0][su_channel][point.p.x][point.p.y] += su_val\n",
    "            del points\n",
    "        # the last and  target SU\n",
    "        su_intensity = 1.\n",
    "        su_x = max(0, min(max_x-1, int(data[su_num_idx + (su_num - 1) * 3 + 1]))) * cell_size\n",
    "        su_y = max(0, min(max_x-1, int(data[su_num_idx + (su_num - 1) * 3 + 2]))) * cell_size\n",
    "#         print(su_x, su_y)\n",
    "        points = points_inside_shape(center=Point(su_x, su_y), param=su_param, shape=su_shape)\n",
    "        su_channel = 0 if number_image_channels == 1 else -1\n",
    "        for point in points:\n",
    "            if 0 <= point.p.x < max_x and 0 <= point.p.y < max_y: # TODO should pass image size\n",
    "                image[0][su_channel][point.p.x][point.p.y] += su_intensity\n",
    "        del points\n",
    "        return image\n",
    "        \n",
    "#         pu_image = [[(noise_floor - mu)/sigma] * max_y for _ in range(max_x)]\n",
    "    elif style == \"image_intensity\":\n",
    "        # creating PU image\n",
    "        image = np.zeros((1,number_image_channels,max_x, max_y), dtype=float_memory_used)\n",
    "        for pu_i in range(pus_num):\n",
    "            pu_x, pu_y, pu_p = max(0, min(max_x-1, int(data[pu_i*3]))), max(0, min(max_x-1, int(data[pu_i*3+1]))), data[pu_i*3+2]\n",
    "            if pu_param is None:\n",
    "                pu_param_p = get_pu_param(pu_shape, intensity_degradation, pu_p, noise_floor, slope)\n",
    "            else:\n",
    "                pu_param_p = pu_param\n",
    "            points = points_inside_shape(center=Point(pu_x, pu_y), shape=pu_shape, param=pu_param_p)\n",
    "            for point in points:\n",
    "                if 0 <= point.p.x < max_x and 0 <= point.p.y < max_y: # TODO should pass image size\n",
    "                    if intensity_degradation == \"linear\":\n",
    "                        image[0][0][point.p.x][point.p.y] += max((pu_p - slope * point.dist + abs(noise_floor))\n",
    "                                                              /(pu_p + abs(noise_floor)), 0)\n",
    "                    elif intensity_degradation == \"log\":\n",
    "                        if point.dist < 1:\n",
    "                            image[0][0][point.p.x][point.p.y] = 1\n",
    "                        else:\n",
    "                            image[0][0][point.p.x][point.p.y] += max((pu_p - slope * 10*math.log10(point.dist) + abs(noise_floor))\n",
    "                                                                 /(pu_p + abs(noise_floor)), 0)\n",
    "                    image[0][0][point.p.x][point.p.y] = min(image[0][0][point.p.x][point.p.y], 1.0)\n",
    "                        \n",
    "        # creating SU image\n",
    "        su_num = (len(data) - pus_num * 3) // 2\n",
    "        if not (len(data) - pus_num * 3) % 2:\n",
    "            raise ValueError(\"Data provided is not correct; can't get SUs' information(create_image)\")\n",
    "#         su_image = np.zeros((max_x, max_y), dtype=float_memory_used)\n",
    "        if su_param is None:\n",
    "            # if su_param is unavailable, a circle(square) with radius(side) 1 is created\n",
    "            if su_shape == 'circle':\n",
    "                su_param = Circle(1)\n",
    "            elif su_shape == 'square':\n",
    "                su_param = Square(1)\n",
    "            elif su_shape == 'point':\n",
    "                su_param = None\n",
    "            else:\n",
    "                raise ValueError(\"Unsupported SU shape(create_image)! \", su_shape)\n",
    "        su_intensity = 1.\n",
    "        for su_i in range(su_num):\n",
    "            su_x, su_y, su_p = max(0, min(max_x-1, int(data[pus_num * (3 if not sensors else 1) +su_i*2]))\n",
    "                                  ), max(0, min(max_x-1, int(data[pus_num * (3 if not sensors else 1) + su_i*2+1]))), su_intensity\n",
    "            points = points_inside_shape(center=Point(su_x, su_y), param=su_param, shape=su_shape)\n",
    "            for point in points:\n",
    "                if 0 <= point.p.x < max_x and 0 <= point.p.y < max_y: # TODO should pass image size\n",
    "                    if number_image_channels > 1:\n",
    "                        image[0][1][point.p.x][point.p.y] = su_intensity\n",
    "                    elif number_image_channels == 1:\n",
    "                        image[0][0][point.p.x][point.p.y] = su_intensity\n",
    "#         return np.array([pu_image, su_image, [[0.] * max_y for _ in range(max_x)]], dtype='float32') # return like this to be able to display as an RGB image with pyplot.imshow(imsave)\n",
    "#         return np.append(pu_image, su_image, axis=0)\n",
    "        return image\n",
    "        \n",
    "            \n",
    "    else:\n",
    "        raise ValueError(\"Unsupported style(create_image)! \", style)\n",
    "        \n",
    "def points_inside_shape(center: Point, shape: str, param)-> list:\n",
    "    # This function returns points+distance around center with defined shape\n",
    "    if shape == 'circle':\n",
    "        # First creates points inside a square(around orgigin) with 2*r side and then remove those with distance > r.\n",
    "        # Shift all remaining around center. O(4r^2)\n",
    "        r, origin = param.r, Point(0, 0)\n",
    "        square_points = set((Point(x, y) for x in range(max(-r, -max_x), min(r, max_x) + 1) \n",
    "                             for y in range(max(-r, -max_y), min(r, max_y) + 1)))\n",
    "        points = []\n",
    "        while square_points:\n",
    "            p = square_points.pop()\n",
    "            dist = euclidian_distance(p, origin)\n",
    "            if dist <= r:\n",
    "                points.append(PointWithDistance(Point(p.x + center.x, p.y + center.y), dist))\n",
    "                if p.x != 0:\n",
    "                    points.append(PointWithDistance(Point(-p.x + center.x, p.y + center.y), dist))\n",
    "                    square_points.remove(Point(-p.x, p.y))\n",
    "                if p.y != 0:\n",
    "                    points.append(PointWithDistance(Point(p.x + center.x, -p.y + center.y), dist))\n",
    "                    square_points.remove(Point(p.x, -p.y))\n",
    "                if p.x != 0 and p.y != 0:\n",
    "                    points.append(PointWithDistance(Point(-p.x + center.x, -p.y + center.y), dist))\n",
    "                    square_points.remove(Point(-p.x, -p.y))\n",
    "        del square_points\n",
    "        return points\n",
    "    elif shape == 'square':\n",
    "        half_side = param.side // 2\n",
    "        return [PointWithDistance(Point(x, y), euclidian_distance(Point(x, y), center)) for x in range(-half_side + center.x,\n",
    "                                                                                               half_side + center.x+1) \n",
    "                         for y in range(-half_side + center.y, half_side + center.y + 1)]\n",
    "    elif shape == 'point':\n",
    "        return [PointWithDistance(center, 0)]\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported shape(points_inside_shape)! \", shape)\n",
    "        \n",
    "def read_image(image_num):\n",
    "    if style == \"image_intensity\":\n",
    "        image = plt.imread(image_dir + '/image' + str(image_num)+'.png')\n",
    "        image = np.swapaxes(image, 0, 2)\n",
    "        image = np.array(image[:number_image_channels], dtype=float_memory_used).reshape(1, number_image_channels, max_x, max_y)\n",
    "    elif  style == \"raw_power_min_max_norm\" or style == \"raw_power_zscore_norm\":\n",
    "        suffix = 'npz'  # npy, npz\n",
    "        image = np.load(image_dir + '/image' + str(image_num) + '.' + suffix)  \n",
    "        if type(image) == np.lib.npyio.NpzFile:\n",
    "            image = image['a']\n",
    "    \n",
    "    return image\n",
    "    \n",
    "# TODO: Consider using min_max normalization becasue difference between values using\n",
    "# z-score is huge since most of the pixels have the same value, noise floor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.hist(data_reg[:,0:1:sensors_num], bins='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_v = -float('inf')\n",
    "min_v = float('inf')\n",
    "for sample_idx in range(data_reg.shape[0]):\n",
    "    pu_n = int(data_reg[sample_idx][0])\n",
    "    max_v = max(max_v, max(data_reg[sample_idx][3:pu_n*3+1:3]))\n",
    "    min_v = min(min_v, min(data_reg[sample_idx][3:pu_n*3+1:3]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not sensors:\n",
    "    noise_floor = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving images once to save time\n",
    "# run this cell just for creating images\n",
    "def creating_image(start, end):\n",
    "    # for image_num in range(115, data_reg.shape[0]):\n",
    "    # for image_num in range(1625, 5000):\n",
    "    for image_num in tqdm.tqdm(range(start, end+1)):  #4463, data_reg.shape[0]\n",
    "        image = create_image(data=data_reg[image_num], slope=slope, style=style, \n",
    "                             noise_floor=noise_floor,\n",
    "                             pu_shape=pu_shape, su_shape=su_shape, su_param=su_param, \n",
    "                             sensors_num=(sensors_num if sensors else 0), \n",
    "                             intensity_degradation=intensity_degradation, \n",
    "                             max_pu_power=max_v)\n",
    "        if style == \"image_intensity\":\n",
    "            if number_image_channels != 3:\n",
    "                image = np.append(np.array(image[0]), np.zeros((3-number_image_channels,max_x, max_y), \n",
    "                                                               dtype=float_memory_used), axis=0)\n",
    "            image_save = np.swapaxes(image, 0, 2)\n",
    "            plt.imsave(image_dir + '/image' + str(image_num)+'.png', image_save)\n",
    "        elif style == \"raw_power_min_max_norm\" or style == \"raw_power_zscore_norm\":\n",
    "    #         np.save(image_dir + '/image' + str(image_num), image)\n",
    "            np.savez_compressed(image_dir + '/image' + str(image_num), a=image)\n",
    "        del image\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [00:01<00:00, 44.73it/s]\n",
      "100%|██████████| 59/59 [00:01<00:00, 42.79it/s]\n",
      "100%|██████████| 63/63 [00:01<00:00, 45.30it/s]\n",
      "100%|██████████| 59/59 [00:01<00:00, 40.39it/s]\n",
      "100%|██████████| 59/59 [00:01<00:00, 39.12it/s]\n"
     ]
    }
   ],
   "source": [
    "jobs = []\n",
    "proc_sizes = [data_reg.shape[0]//number_of_proccessors] * (number_of_proccessors)\n",
    "proc_sizes[-1] += data_reg.shape[0]%number_of_proccessors\n",
    "proc_idx = [(sum(proc_sizes[:i]), sum(proc_sizes[:i+1])-1) for i in range(number_of_proccessors)]\n",
    "\n",
    "for i in range(number_of_proccessors):\n",
    "    p = Process(target=creating_image, args=(proc_idx[i][0], proc_idx[i][1]))\n",
    "    jobs.append(p)\n",
    "    p.start()\n",
    "for i in range(number_of_proccessors):\n",
    "    jobs[i].join()\n",
    "\n",
    "for i in range(number_of_proccessors):\n",
    "    jobs[i].terminate()\n",
    "    jobs[i].close()\n",
    "del jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for idx, point in enumerate(sensors_location):\n",
    "    print(idx+1, point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, point in enumerate(sensors_location):\n",
    "    print(idx+1, point,\"close\") if math.sqrt((point.x-917)**2+(point.y-415)**2)<=1.5 else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = [0, 0, 0, 0]\n",
    "idxx = [[],[],[],[]]\n",
    "for i in range(data_reg.shape[0]):\n",
    "    pus_c = int(data_reg[i][0]) * 3 + 1\n",
    "    idx = int(data_reg[i][pus_c]) - 1\n",
    "    count[idx] += 1\n",
    "    idxx[idx].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(count)\n",
    "print(idxx[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "imm = read_image(150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imm[300].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_reg[:,-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.,  5.,  2., 36.,  0.,  0., 50.,  3.,  5., 48.,  6.,  0., 44.,\n",
       "       nan, nan, 44.])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_reg[150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f4135796f50>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 4320x4320 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(60,60))         # Sample figsize in inches\n",
    "sns.heatmap(imm[0][4], ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model(num_filters, kernel_lam, bias_lam):\n",
    "#     num_filters, lam = 5, 5\n",
    "    data_format = 'channels_first'\n",
    "    convolution_init, dense_init = \"lecun_normal\", \"RandomNormal\"\n",
    "    convolution_filter, dense_filter = 'selu', 'linear' #softsign, sigmoid; relu, linear\n",
    "    filter_shape, pool_size = (3, 3), (2,2)\n",
    "    cnn = models.Sequential()\n",
    "    cnn.add(layers.Conv2D(num_filters, filter_shape, padding='same', activation=convolution_filter, \n",
    "                          input_shape=(number_image_channels, max_x, max_y), data_format=data_format,\n",
    "                          kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "                          kernel_initializer=convolution_init))\n",
    "#     cnn.add(BatchNormalization(axis=1))\n",
    "#     cnn.add(layers.Conv2D(4*num_filters, filter_shape, padding='same', activation=convolution_filter, \n",
    "#                           input_shape=(number_image_channels, max_x, max_y), data_format=data_format,\n",
    "#                           kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "#                           kernel_initializer='lecun_normal'))\n",
    "    cnn.add(layers.MaxPooling2D(pool_size=pool_size, data_format=data_format))\n",
    "    cnn.add(BatchNormalization(axis=1))\n",
    "#     cnn.add(layers.Dropout(0.25))\n",
    "    \n",
    "    cnn.add(layers.Conv2D(2*num_filters, filter_shape,padding='same', activation=convolution_filter, data_format=data_format, \n",
    "                         kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "                         kernel_initializer=convolution_init))\n",
    "#     cnn.add(BatchNormalization(axis=1))\n",
    "#     cnn.add(layers.Conv2D(3*num_filters, filter_shape, padding='same', activation=convolution_filter, \n",
    "#                           input_shape=(number_image_channels, max_x, max_y), data_format=data_format,\n",
    "#                           kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "#                           kernel_initializer='lecun_normal'))\n",
    "    cnn.add(layers.MaxPooling2D(pool_size=pool_size, data_format=data_format))\n",
    "    cnn.add(BatchNormalization(axis=1))\n",
    "#     cnn.add(layers.Dropout(0.25))\n",
    "    \n",
    "    cnn.add(layers.Conv2D(3*num_filters, filter_shape, padding='same', activation=convolution_filter, data_format=data_format, \n",
    "                         kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "                         kernel_initializer=convolution_init))\n",
    "#     cnn.add(BatchNormalization(axis=1))\n",
    "#     cnn.add(layers.Conv2D(2*num_filters, filter_shape, padding='same', activation=convolution_filter, \n",
    "#                           input_shape=(number_image_channels, max_x, max_y), data_format=data_format,\n",
    "#                           kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "#                           kernel_initializer='lecun_normal'))\n",
    "    cnn.add(layers.MaxPooling2D(pool_size, data_format=data_format))\n",
    "    cnn.add(BatchNormalization(axis=1))\n",
    "#     cnn.add(layers.Dropout(0.25))\n",
    "    \n",
    "    cnn.add(layers.Conv2D(4*num_filters, filter_shape, padding='same', activation=convolution_filter, data_format=data_format, \n",
    "                         kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "                         kernel_initializer=convolution_init))\n",
    "#     cnn.add(BatchNormalization(axis=1))\n",
    "#     cnn.add(layers.Conv2D(num_filters, filter_shape, padding='same', activation=convolution_filter, data_format=data_format, \n",
    "#                          kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "#                          kernel_initializer='lecun_normal'))\n",
    "    cnn.add(layers.MaxPooling2D(pool_size, data_format=data_format))\n",
    "    cnn.add(BatchNormalization(axis=1))\n",
    "#     cnn.add(layers.Dropout(0.25))\n",
    "# from here for 1000\n",
    "    if max(max_x, max_y) == 1000:\n",
    "        cnn.add(layers.Conv2D(4*num_filters, filter_shape, padding='same', activation=convolution_filter, data_format=data_format, \n",
    "                             kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "                             kernel_initializer=convolution_init))\n",
    "    #     cnn.add(BatchNormalization(axis=1))\n",
    "    #     cnn.add(layers.Conv2D(num_filters, filter_shape, padding='same', activation=convolution_filter, data_format=data_format, \n",
    "    #                          kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "    #                          kernel_initializer='lecun_normal'))\n",
    "        cnn.add(layers.MaxPooling2D(pool_size, data_format=data_format))\n",
    "        cnn.add(BatchNormalization(axis=1))\n",
    "    #     cnn.add(layers.Dropout(0.25))\n",
    "\n",
    "        cnn.add(layers.Conv2D(4*num_filters, filter_shape, padding='same', activation=convolution_filter, data_format=data_format, \n",
    "                             kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam), \n",
    "                             kernel_initializer=convolution_init))\n",
    "    #     cnn.add(BatchNormalization(axis=1))\n",
    "    #     cnn.add(layers.Conv2D(2*num_filters, filter_shape, padding='same', activation=convolution_filter, data_format=data_format, \n",
    "    #                          kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "    #                          kernel_initializer='lecun_normal'))\n",
    "        cnn.add(layers.MaxPooling2D(pool_size, data_format=data_format))\n",
    "        cnn.add(BatchNormalization(axis=1))\n",
    "    #     cnn.add(layers.Dropout(0.25))\n",
    "\n",
    "        cnn.add(layers.Conv2D(4*num_filters, filter_shape, padding='same', activation=convolution_filter, data_format=data_format, \n",
    "                             kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam), \n",
    "                             kernel_initializer=convolution_init))\n",
    "    #     cnn.add(BatchNormalization(axis=1))\n",
    "    #     cnn.add(layers.Conv2D(3*num_filters, filter_shape, padding='same', activation=convolution_filter, data_format=data_format, \n",
    "    #                          kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "    #                          kernel_initializer='lecun_normal'))\n",
    "        cnn.add(layers.MaxPooling2D(pool_size, data_format=data_format))\n",
    "        cnn.add(BatchNormalization(axis=1))\n",
    "    #     cnn.add(layers.Dropout(0.25))\n",
    "    \n",
    "    cnn.add(layers.Flatten())\n",
    "    cnn.add(layers.Dense(20, activation=convolution_filter, kernel_regularizer=regularizers.l2(kernel_lam),\n",
    "                         bias_regularizer=regularizers.l2(bias_lam), kernel_initializer=convolution_init))\n",
    "    cnn.add(BatchNormalization())\n",
    "    cnn.add(layers.Dense(20, activation=convolution_filter, kernel_regularizer=regularizers.l2(kernel_lam),\n",
    "                         bias_regularizer=regularizers.l2(bias_lam), kernel_initializer=convolution_init))\n",
    "#     cnn.add(BatchNormalization())\n",
    "    cnn.add(layers.Dense(1, activation=dense_filter, kernel_regularizer=regularizers.l2(kernel_lam),\n",
    "                         bias_regularizer=regularizers.l2(bias_lam), kernel_initializer=dense_init))\n",
    "    return cnn\n",
    "\n",
    "\n",
    "class DataBatchGenerator(Sequence):\n",
    "    def __init__(self, dataset:np.ndarray, batch_size:int, start_idx:int,\n",
    "                 number_image_channels:int,\n",
    "                 max_x, max_y, float_memory_used, conserve=0):\n",
    "#         print(dataset.shape[0])\n",
    "        self.dataset, self.batch_size, self.start_idx = dataset, batch_size, start_idx\n",
    "        self.number_image_channels, self.max_x, self.max_y = number_image_channels, max_x, max_y\n",
    "        self.float_memory_used = float_memory_used\n",
    "        self.conserve = conserve\n",
    "    \n",
    "    def __len__(self):\n",
    "        return np.ceil(self.dataset.shape[0] / self.batch_size).astype(np.int)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        size = min(self.dataset.shape[0] - idx * self.batch_size, self.batch_size)\n",
    "        batch_x = np.empty((size, self.number_image_channels, self.max_x, self.max_y), dtype=self.float_memory_used)\n",
    "        batch_y = np.empty((size), dtype=self.float_memory_used)\n",
    "        for i in range(size):\n",
    "            batch_x[i] = read_image(self.start_idx + idx * self.batch_size + i)\n",
    "            batch_y[i] = self.dataset[idx * self.batch_size + i][- 1 - self.conserve]\n",
    "        return batch_x, batch_y\n",
    "    \n",
    "def custom_loss(fp_penalty_coef, fn_penalty_coef):\n",
    "    # custom loss function that penalize false positive and negative differently\n",
    "    def loss(y_true, y_pred):\n",
    "        res = y_pred - y_true\n",
    "        res = tf.where(res > 0, res * fp_penalty_coef, res * fn_penalty_coef)\n",
    "        return K.mean(K.square(res))\n",
    "    return loss\n",
    "\n",
    "def fp_mae(y_true, y_pred):\n",
    "    # custom metric that replace false negative with zero and return the mean of new vector\n",
    "    res = y_pred - y_true\n",
    "    res = tf.nn.relu(res)\n",
    "#     res = tf.where(res <= 0, 0, res)\n",
    "    return K.mean(res)\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = cnn_model(10, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_21 (Conv2D)           (None, 10, 100, 100)      460       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 10, 50, 50)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 10, 50, 50)        40        \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 20, 50, 50)        1820      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling (None, 20, 25, 25)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 20, 25, 25)        80        \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 30, 25, 25)        5430      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling (None, 30, 12, 12)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 30, 12, 12)        120       \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 40, 12, 12)        10840     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling (None, 40, 6, 6)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 40, 6, 6)          160       \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 1440)              0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 20)                28820     \n",
      "_________________________________________________________________\n",
      "batch_normalization_30 (Batc (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 48,291\n",
      "Trainable params: 48,051\n",
      "Non-trainable params: 240\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number_samples: 30 , New samples: 30\n",
      "Validation size: 6 , starts: 30 , ends: 35\n",
      "\n",
      "Epoch 00001: val_mae improved from inf to 48.03308, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00002: val_mae did not improve from 48.03308\n",
      "\n",
      "Epoch 00003: val_mae did not improve from 48.03308\n",
      "\n",
      "Epoch 00004: val_mae did not improve from 48.03308\n",
      "\n",
      "Epoch 00005: val_mae did not improve from 48.03308\n",
      "\n",
      "Epoch 00006: val_mae did not improve from 48.03308\n",
      "\n",
      "Epoch 00007: val_mae did not improve from 48.03308\n",
      "\n",
      "Epoch 00008: val_mae did not improve from 48.03308\n",
      "\n",
      "Epoch 00009: val_mae improved from 48.03308 to 48.03055, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00010: val_mae improved from 48.03055 to 48.02336, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00011: val_mae improved from 48.02336 to 48.01647, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00012: val_mae improved from 48.01647 to 48.00937, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00013: val_mae improved from 48.00937 to 48.00198, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00014: val_mae improved from 48.00198 to 47.99365, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00015: val_mae improved from 47.99365 to 47.98520, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00016: val_mae improved from 47.98520 to 47.97686, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00017: val_mae improved from 47.97686 to 47.96833, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00018: val_mae improved from 47.96833 to 47.95993, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00019: val_mae improved from 47.95993 to 47.95144, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00020: val_mae improved from 47.95144 to 47.94264, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00021: val_mae improved from 47.94264 to 47.93306, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00022: val_mae improved from 47.93306 to 47.92206, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00023: val_mae improved from 47.92206 to 47.90944, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00024: val_mae improved from 47.90944 to 47.89566, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00025: val_mae improved from 47.89566 to 47.88080, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00026: val_mae improved from 47.88080 to 47.86543, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00027: val_mae improved from 47.86543 to 47.84937, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00028: val_mae improved from 47.84937 to 47.83240, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00029: val_mae improved from 47.83240 to 47.81485, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00030: val_mae improved from 47.81485 to 47.79727, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00031: val_mae improved from 47.79727 to 47.77914, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00032: val_mae improved from 47.77914 to 47.76046, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00033: val_mae improved from 47.76046 to 47.73967, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00034: val_mae improved from 47.73967 to 47.71907, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00035: val_mae improved from 47.71907 to 47.69823, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00036: val_mae improved from 47.69823 to 47.67761, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00037: val_mae improved from 47.67761 to 47.65733, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00038: val_mae improved from 47.65733 to 47.63701, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00039: val_mae improved from 47.63701 to 47.61732, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00040: val_mae improved from 47.61732 to 47.59614, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00041: val_mae improved from 47.59614 to 47.57364, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00042: val_mae improved from 47.57364 to 47.55066, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00043: val_mae improved from 47.55066 to 47.52530, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00044: val_mae improved from 47.52530 to 47.49894, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00045: val_mae improved from 47.49894 to 47.47219, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00046: val_mae improved from 47.47219 to 47.44682, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_0.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00047: val_mae improved from 47.44682 to 47.42126, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00048: val_mae improved from 47.42126 to 47.39442, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00049: val_mae improved from 47.39442 to 47.36482, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00050: val_mae improved from 47.36482 to 47.33364, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00051: val_mae improved from 47.33364 to 47.29774, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00052: val_mae improved from 47.29774 to 47.26271, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00053: val_mae improved from 47.26271 to 47.22957, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00054: val_mae improved from 47.22957 to 47.19841, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00055: val_mae improved from 47.19841 to 47.16216, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00056: val_mae improved from 47.16216 to 47.12742, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00057: val_mae improved from 47.12742 to 47.08961, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00058: val_mae improved from 47.08961 to 47.04520, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00059: val_mae improved from 47.04520 to 46.99441, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00060: val_mae improved from 46.99441 to 46.94214, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00061: val_mae improved from 46.94214 to 46.89528, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00062: val_mae improved from 46.89528 to 46.85057, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00063: val_mae improved from 46.85057 to 46.80617, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00064: val_mae improved from 46.80617 to 46.75946, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00065: val_mae improved from 46.75946 to 46.70840, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00066: val_mae improved from 46.70840 to 46.66240, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00067: val_mae improved from 46.66240 to 46.61412, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00068: val_mae improved from 46.61412 to 46.56639, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00069: val_mae improved from 46.56639 to 46.51841, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00070: val_mae improved from 46.51841 to 46.45865, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00071: val_mae improved from 46.45865 to 46.38813, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00072: val_mae improved from 46.38813 to 46.31297, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00073: val_mae improved from 46.31297 to 46.23532, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00074: val_mae improved from 46.23532 to 46.16477, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00075: val_mae improved from 46.16477 to 46.08931, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00076: val_mae improved from 46.08931 to 45.99871, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00077: val_mae improved from 45.99871 to 45.91452, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00078: val_mae improved from 45.91452 to 45.83545, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00079: val_mae improved from 45.83545 to 45.76799, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00080: val_mae improved from 45.76799 to 45.70220, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00081: val_mae improved from 45.70220 to 45.63480, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00082: val_mae improved from 45.63480 to 45.57144, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00083: val_mae improved from 45.57144 to 45.50336, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00084: val_mae improved from 45.50336 to 45.44791, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00085: val_mae improved from 45.44791 to 45.39051, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00086: val_mae improved from 45.39051 to 45.31620, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00087: val_mae improved from 45.31620 to 45.21733, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_0.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00088: val_mae improved from 45.21733 to 45.12332, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00089: val_mae improved from 45.12332 to 45.04424, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00090: val_mae improved from 45.04424 to 44.98021, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00091: val_mae improved from 44.98021 to 44.92291, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00092: val_mae improved from 44.92291 to 44.86456, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00093: val_mae improved from 44.86456 to 44.79485, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00094: val_mae improved from 44.79485 to 44.70785, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00095: val_mae improved from 44.70785 to 44.59863, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00096: val_mae improved from 44.59863 to 44.51152, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00097: val_mae improved from 44.51152 to 44.44350, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00098: val_mae improved from 44.44350 to 44.39682, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00099: val_mae improved from 44.39682 to 44.33170, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00100: val_mae improved from 44.33170 to 44.25253, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_0.h5\n",
      "\n",
      "Lambda: 0.001 , Time: 0:00:31\n",
      "Train Error(all epochs): 45.53444 \n",
      " [48.304, 48.266, 48.242, 48.222, 48.207, 48.195, 48.184, 48.172, 48.162, 48.152, 48.142, 48.133, 48.124, 48.115, 48.106, 48.096, 48.086, 48.075, 48.065, 48.054, 48.042, 48.031, 48.019, 48.008, 47.996, 47.984, 47.971, 47.958, 47.945, 47.931, 47.917, 47.903, 47.888, 47.873, 47.857, 47.841, 47.825, 47.809, 47.792, 47.775, 47.757, 47.739, 47.722, 47.703, 47.684, 47.665, 47.644, 47.623, 47.602, 47.581, 47.558, 47.533, 47.511, 47.488, 47.463, 47.439, 47.412, 47.384, 47.356, 47.329, 47.298, 47.268, 47.238, 47.209, 47.18, 47.148, 47.114, 47.08, 47.044, 47.009, 46.973, 46.935, 46.892, 46.847, 46.807, 46.769, 46.729, 46.687, 46.642, 46.6, 46.554, 46.506, 46.46, 46.419, 46.366, 46.32, 46.271, 46.226, 46.176, 46.12, 46.065, 46.008, 45.949, 45.894, 45.839, 45.785, 45.723, 45.656, 45.592, 45.534]\n",
      "Train FP Error(all epochs): 0.0 \n",
      " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Val Error(all epochs): 44.252532958984375 \n",
      " [48.033, 48.041, 48.045, 48.047, 48.047, 48.045, 48.042, 48.037, 48.031, 48.023, 48.016, 48.009, 48.002, 47.994, 47.985, 47.977, 47.968, 47.96, 47.951, 47.943, 47.933, 47.922, 47.909, 47.896, 47.881, 47.865, 47.849, 47.832, 47.815, 47.797, 47.779, 47.76, 47.74, 47.719, 47.698, 47.678, 47.657, 47.637, 47.617, 47.596, 47.574, 47.551, 47.525, 47.499, 47.472, 47.447, 47.421, 47.394, 47.365, 47.334, 47.298, 47.263, 47.23, 47.198, 47.162, 47.127, 47.09, 47.045, 46.994, 46.942, 46.895, 46.851, 46.806, 46.759, 46.708, 46.662, 46.614, 46.566, 46.518, 46.459, 46.388, 46.313, 46.235, 46.165, 46.089, 45.999, 45.915, 45.835, 45.768, 45.702, 45.635, 45.571, 45.503, 45.448, 45.391, 45.316, 45.217, 45.123, 45.044, 44.98, 44.923, 44.865, 44.795, 44.708, 44.599, 44.512, 44.443, 44.397, 44.332, 44.253]\n",
      "Val FP Error(all epochs): 0.0 \n",
      " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "Epoch 00001: val_mae improved from inf to 48.13321, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00002: val_mae did not improve from 48.13321\n",
      "\n",
      "Epoch 00003: val_mae did not improve from 48.13321\n",
      "\n",
      "Epoch 00004: val_mae did not improve from 48.13321\n",
      "\n",
      "Epoch 00005: val_mae did not improve from 48.13321\n",
      "\n",
      "Epoch 00006: val_mae did not improve from 48.13321\n",
      "\n",
      "Epoch 00007: val_mae did not improve from 48.13321\n",
      "\n",
      "Epoch 00008: val_mae did not improve from 48.13321\n",
      "\n",
      "Epoch 00009: val_mae did not improve from 48.13321\n",
      "\n",
      "Epoch 00010: val_mae did not improve from 48.13321\n",
      "\n",
      "Epoch 00011: val_mae did not improve from 48.13321\n",
      "\n",
      "Epoch 00012: val_mae improved from 48.13321 to 48.11903, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00013: val_mae improved from 48.11903 to 48.10348, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00014: val_mae improved from 48.10348 to 48.08770, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00015: val_mae improved from 48.08770 to 48.07219, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00016: val_mae improved from 48.07219 to 48.05770, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00017: val_mae improved from 48.05770 to 48.04199, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00018: val_mae improved from 48.04199 to 48.02536, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00019: val_mae improved from 48.02536 to 48.00769, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00020: val_mae improved from 48.00769 to 47.99016, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00021: val_mae improved from 47.99016 to 47.97368, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00022: val_mae improved from 47.97368 to 47.95717, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_1.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00023: val_mae improved from 47.95717 to 47.94006, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00024: val_mae improved from 47.94006 to 47.92150, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00025: val_mae improved from 47.92150 to 47.90198, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00026: val_mae improved from 47.90198 to 47.88113, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00027: val_mae improved from 47.88113 to 47.85836, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00028: val_mae improved from 47.85836 to 47.83466, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00029: val_mae improved from 47.83466 to 47.81016, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00030: val_mae improved from 47.81016 to 47.78439, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00031: val_mae improved from 47.78439 to 47.75302, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00032: val_mae improved from 47.75302 to 47.71531, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00033: val_mae improved from 47.71531 to 47.67734, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00034: val_mae improved from 47.67734 to 47.63877, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00035: val_mae improved from 47.63877 to 47.60139, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00036: val_mae improved from 47.60139 to 47.56765, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00037: val_mae improved from 47.56765 to 47.53643, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00038: val_mae improved from 47.53643 to 47.50300, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00039: val_mae improved from 47.50300 to 47.46899, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00040: val_mae improved from 47.46899 to 47.43262, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00041: val_mae improved from 47.43262 to 47.39386, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00042: val_mae improved from 47.39386 to 47.35095, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00043: val_mae improved from 47.35095 to 47.30672, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00044: val_mae improved from 47.30672 to 47.26321, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00045: val_mae improved from 47.26321 to 47.22060, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00046: val_mae improved from 47.22060 to 47.18121, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00047: val_mae improved from 47.18121 to 47.14518, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00048: val_mae improved from 47.14518 to 47.10999, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00049: val_mae improved from 47.10999 to 47.07318, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00050: val_mae improved from 47.07318 to 47.03671, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00051: val_mae improved from 47.03671 to 46.99953, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00052: val_mae improved from 46.99953 to 46.95521, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00053: val_mae improved from 46.95521 to 46.90703, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00054: val_mae improved from 46.90703 to 46.86245, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00055: val_mae improved from 46.86245 to 46.82607, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00056: val_mae improved from 46.82607 to 46.79171, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00057: val_mae improved from 46.79171 to 46.74849, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00058: val_mae improved from 46.74849 to 46.69981, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00059: val_mae improved from 46.69981 to 46.65548, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00060: val_mae improved from 46.65548 to 46.61605, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00061: val_mae improved from 46.61605 to 46.57244, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00062: val_mae improved from 46.57244 to 46.52138, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00063: val_mae improved from 46.52138 to 46.45823, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_1.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00064: val_mae improved from 46.45823 to 46.40451, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00065: val_mae improved from 46.40451 to 46.36099, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00066: val_mae improved from 46.36099 to 46.32394, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00067: val_mae improved from 46.32394 to 46.27532, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00068: val_mae improved from 46.27532 to 46.21880, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00069: val_mae improved from 46.21880 to 46.16663, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00070: val_mae improved from 46.16663 to 46.12362, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00071: val_mae improved from 46.12362 to 46.08371, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00072: val_mae improved from 46.08371 to 46.03697, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00073: val_mae improved from 46.03697 to 45.98959, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00074: val_mae improved from 45.98959 to 45.95241, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00075: val_mae improved from 45.95241 to 45.89627, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00076: val_mae improved from 45.89627 to 45.83534, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00077: val_mae improved from 45.83534 to 45.77856, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00078: val_mae improved from 45.77856 to 45.73300, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00079: val_mae improved from 45.73300 to 45.68844, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00080: val_mae improved from 45.68844 to 45.64266, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00081: val_mae improved from 45.64266 to 45.58405, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00082: val_mae improved from 45.58405 to 45.51187, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00083: val_mae improved from 45.51187 to 45.43939, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00084: val_mae improved from 45.43939 to 45.36496, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00085: val_mae improved from 45.36496 to 45.28848, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00086: val_mae improved from 45.28848 to 45.21109, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00087: val_mae improved from 45.21109 to 45.13475, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00088: val_mae improved from 45.13475 to 45.02417, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00089: val_mae improved from 45.02417 to 44.92351, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00090: val_mae improved from 44.92351 to 44.83596, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00091: val_mae improved from 44.83596 to 44.75312, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00092: val_mae improved from 44.75312 to 44.64653, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00093: val_mae improved from 44.64653 to 44.52626, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00094: val_mae improved from 44.52626 to 44.46818, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00095: val_mae improved from 44.46818 to 44.39365, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00096: val_mae improved from 44.39365 to 44.28886, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00097: val_mae improved from 44.28886 to 44.16199, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00098: val_mae improved from 44.16199 to 44.02198, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00099: val_mae improved from 44.02198 to 43.89461, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00100: val_mae improved from 43.89461 to 43.83854, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_1.h5\n",
      "\n",
      "Lambda: 0.01 , Time: 0:00:30\n",
      "Train Error(all epochs): 45.08489 \n",
      " [48.274, 48.196, 48.14, 48.094, 48.06, 48.038, 48.019, 48.003, 47.988, 47.975, 47.963, 47.951, 47.94, 47.928, 47.916, 47.903, 47.889, 47.875, 47.86, 47.845, 47.831, 47.817, 47.802, 47.787, 47.772, 47.757, 47.742, 47.726, 47.71, 47.693, 47.677, 47.659, 47.642, 47.624, 47.606, 47.587, 47.568, 47.548, 47.529, 47.508, 47.488, 47.466, 47.444, 47.422, 47.399, 47.376, 47.353, 47.329, 47.306, 47.281, 47.255, 47.229, 47.201, 47.173, 47.144, 47.117, 47.089, 47.06, 47.029, 46.998, 46.966, 46.934, 46.902, 46.866, 46.831, 46.796, 46.76, 46.724, 46.688, 46.652, 46.614, 46.575, 46.535, 46.495, 46.456, 46.413, 46.369, 46.324, 46.28, 46.237, 46.191, 46.142, 46.092, 46.044, 45.996, 45.946, 45.896, 45.844, 45.786, 45.73, 45.675, 45.619, 45.561, 45.497, 45.438, 45.374, 45.304, 45.229, 45.155, 45.085]\n",
      "Train FP Error(all epochs): 0.0 \n",
      " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Val Error(all epochs): 43.83854293823242 \n",
      " [48.133, 48.161, 48.175, 48.183, 48.186, 48.185, 48.18, 48.172, 48.161, 48.148, 48.134, 48.119, 48.103, 48.088, 48.072, 48.058, 48.042, 48.025, 48.008, 47.99, 47.974, 47.957, 47.94, 47.921, 47.902, 47.881, 47.858, 47.835, 47.81, 47.784, 47.753, 47.715, 47.677, 47.639, 47.601, 47.568, 47.536, 47.503, 47.469, 47.433, 47.394, 47.351, 47.307, 47.263, 47.221, 47.181, 47.145, 47.11, 47.073, 47.037, 47.0, 46.955, 46.907, 46.862, 46.826, 46.792, 46.748, 46.7, 46.655, 46.616, 46.572, 46.521, 46.458, 46.405, 46.361, 46.324, 46.275, 46.219, 46.167, 46.124, 46.084, 46.037, 45.99, 45.952, 45.896, 45.835, 45.779, 45.733, 45.688, 45.643, 45.584, 45.512, 45.439, 45.365, 45.288, 45.211, 45.135, 45.024, 44.924, 44.836, 44.753, 44.647, 44.526, 44.468, 44.394, 44.289, 44.162, 44.022, 43.895, 43.839]\n",
      "Val FP Error(all epochs): 0.0 \n",
      " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_mae improved from inf to 47.99507, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00002: val_mae did not improve from 47.99507\n",
      "\n",
      "Epoch 00003: val_mae did not improve from 47.99507\n",
      "\n",
      "Epoch 00004: val_mae did not improve from 47.99507\n",
      "\n",
      "Epoch 00005: val_mae did not improve from 47.99507\n",
      "\n",
      "Epoch 00006: val_mae did not improve from 47.99507\n",
      "\n",
      "Epoch 00007: val_mae did not improve from 47.99507\n",
      "\n",
      "Epoch 00008: val_mae did not improve from 47.99507\n",
      "\n",
      "Epoch 00009: val_mae did not improve from 47.99507\n",
      "\n",
      "Epoch 00010: val_mae did not improve from 47.99507\n",
      "\n",
      "Epoch 00011: val_mae did not improve from 47.99507\n",
      "\n",
      "Epoch 00012: val_mae improved from 47.99507 to 47.98764, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00013: val_mae improved from 47.98764 to 47.97825, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00014: val_mae improved from 47.97825 to 47.96742, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00015: val_mae improved from 47.96742 to 47.95569, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00016: val_mae improved from 47.95569 to 47.94345, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00017: val_mae improved from 47.94345 to 47.93039, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00018: val_mae improved from 47.93039 to 47.91637, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00019: val_mae improved from 47.91637 to 47.90143, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00020: val_mae improved from 47.90143 to 47.88588, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00021: val_mae improved from 47.88588 to 47.86880, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00022: val_mae improved from 47.86880 to 47.84984, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00023: val_mae improved from 47.84984 to 47.82812, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00024: val_mae improved from 47.82812 to 47.80436, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00025: val_mae improved from 47.80436 to 47.77849, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00026: val_mae improved from 47.77849 to 47.75003, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00027: val_mae improved from 47.75003 to 47.72064, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00028: val_mae improved from 47.72064 to 47.68962, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00029: val_mae improved from 47.68962 to 47.65737, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00030: val_mae improved from 47.65737 to 47.62326, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00031: val_mae improved from 47.62326 to 47.58725, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00032: val_mae improved from 47.58725 to 47.54952, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00033: val_mae improved from 47.54952 to 47.51177, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00034: val_mae improved from 47.51177 to 47.47416, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00035: val_mae improved from 47.47416 to 47.43542, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00036: val_mae improved from 47.43542 to 47.39557, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00037: val_mae improved from 47.39557 to 47.35295, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00038: val_mae improved from 47.35295 to 47.31002, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00039: val_mae improved from 47.31002 to 47.26606, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00040: val_mae improved from 47.26606 to 47.21727, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00041: val_mae improved from 47.21727 to 47.16513, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00042: val_mae improved from 47.16513 to 47.11232, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00043: val_mae improved from 47.11232 to 47.05944, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00044: val_mae improved from 47.05944 to 47.00503, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00045: val_mae improved from 47.00503 to 46.94799, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00046: val_mae improved from 46.94799 to 46.89415, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00047: val_mae improved from 46.89415 to 46.84544, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00048: val_mae improved from 46.84544 to 46.79426, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00049: val_mae improved from 46.79426 to 46.74057, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_2.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00050: val_mae improved from 46.74057 to 46.67784, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00051: val_mae improved from 46.67784 to 46.61157, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00052: val_mae improved from 46.61157 to 46.54834, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00053: val_mae improved from 46.54834 to 46.48811, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00054: val_mae improved from 46.48811 to 46.42707, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00055: val_mae improved from 46.42707 to 46.36604, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00056: val_mae improved from 46.36604 to 46.30791, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00057: val_mae improved from 46.30791 to 46.23697, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00058: val_mae improved from 46.23697 to 46.16365, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00059: val_mae improved from 46.16365 to 46.08580, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00060: val_mae improved from 46.08580 to 46.00266, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00061: val_mae improved from 46.00266 to 45.92073, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00062: val_mae improved from 45.92073 to 45.83545, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00063: val_mae improved from 45.83545 to 45.75100, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00064: val_mae improved from 45.75100 to 45.65900, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00065: val_mae improved from 45.65900 to 45.55865, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00066: val_mae improved from 45.55865 to 45.46709, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00067: val_mae improved from 45.46709 to 45.37453, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00068: val_mae improved from 45.37453 to 45.28359, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00069: val_mae improved from 45.28359 to 45.18305, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00070: val_mae improved from 45.18305 to 45.09277, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00071: val_mae improved from 45.09277 to 44.98898, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00072: val_mae improved from 44.98898 to 44.87816, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00073: val_mae improved from 44.87816 to 44.77537, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00074: val_mae improved from 44.77537 to 44.67225, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00075: val_mae improved from 44.67225 to 44.56949, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00076: val_mae improved from 44.56949 to 44.46650, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00077: val_mae improved from 44.46650 to 44.35013, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00078: val_mae improved from 44.35013 to 44.24458, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00079: val_mae improved from 44.24458 to 44.13335, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00080: val_mae improved from 44.13335 to 44.02602, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00081: val_mae improved from 44.02602 to 43.91729, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00082: val_mae improved from 43.91729 to 43.80468, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00083: val_mae improved from 43.80468 to 43.67639, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00084: val_mae improved from 43.67639 to 43.57019, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00085: val_mae improved from 43.57019 to 43.45975, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00086: val_mae improved from 43.45975 to 43.33815, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00087: val_mae improved from 43.33815 to 43.21156, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00088: val_mae improved from 43.21156 to 43.08968, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00089: val_mae improved from 43.08968 to 43.00631, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00090: val_mae improved from 43.00631 to 42.88385, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_2.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00091: val_mae improved from 42.88385 to 42.75528, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00092: val_mae improved from 42.75528 to 42.60920, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00093: val_mae improved from 42.60920 to 42.47408, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00094: val_mae improved from 42.47408 to 42.32233, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00095: val_mae improved from 42.32233 to 42.15784, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00096: val_mae improved from 42.15784 to 41.96710, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00097: val_mae improved from 41.96710 to 41.77020, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00098: val_mae improved from 41.77020 to 41.54179, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00099: val_mae improved from 41.54179 to 41.30657, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00100: val_mae improved from 41.30657 to 41.09455, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_2.h5\n",
      "\n",
      "Lambda: 0.1 , Time: 0:00:30\n",
      "Train Error(all epochs): 44.75763 \n",
      " [48.31, 48.25, 48.207, 48.177, 48.158, 48.143, 48.131, 48.12, 48.108, 48.098, 48.088, 48.079, 48.07, 48.061, 48.052, 48.042, 48.032, 48.022, 48.011, 48.0, 47.989, 47.978, 47.967, 47.955, 47.943, 47.93, 47.918, 47.905, 47.891, 47.878, 47.864, 47.849, 47.834, 47.818, 47.801, 47.784, 47.766, 47.748, 47.729, 47.71, 47.691, 47.669, 47.649, 47.628, 47.605, 47.582, 47.558, 47.531, 47.506, 47.481, 47.454, 47.427, 47.397, 47.366, 47.334, 47.302, 47.271, 47.236, 47.198, 47.162, 47.126, 47.089, 47.051, 47.01, 46.968, 46.926, 46.884, 46.841, 46.795, 46.748, 46.701, 46.656, 46.613, 46.565, 46.514, 46.465, 46.414, 46.363, 46.309, 46.252, 46.195, 46.136, 46.077, 46.019, 45.958, 45.894, 45.827, 45.76, 45.691, 45.615, 45.537, 45.463, 45.388, 45.312, 45.233, 45.145, 45.053, 44.955, 44.854, 44.758]\n",
      "Train FP Error(all epochs): 0.0 \n",
      " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Val Error(all epochs): 41.09455490112305 \n",
      " [47.995, 48.008, 48.013, 48.017, 48.018, 48.018, 48.015, 48.012, 48.007, 48.001, 47.995, 47.988, 47.978, 47.967, 47.956, 47.943, 47.93, 47.916, 47.901, 47.886, 47.869, 47.85, 47.828, 47.804, 47.778, 47.75, 47.721, 47.69, 47.657, 47.623, 47.587, 47.55, 47.512, 47.474, 47.435, 47.396, 47.353, 47.31, 47.266, 47.217, 47.165, 47.112, 47.059, 47.005, 46.948, 46.894, 46.845, 46.794, 46.741, 46.678, 46.612, 46.548, 46.488, 46.427, 46.366, 46.308, 46.237, 46.164, 46.086, 46.003, 45.921, 45.835, 45.751, 45.659, 45.559, 45.467, 45.375, 45.284, 45.183, 45.093, 44.989, 44.878, 44.775, 44.672, 44.569, 44.467, 44.35, 44.245, 44.133, 44.026, 43.917, 43.805, 43.676, 43.57, 43.46, 43.338, 43.212, 43.09, 43.006, 42.884, 42.755, 42.609, 42.474, 42.322, 42.158, 41.967, 41.77, 41.542, 41.307, 41.095]\n",
      "Val FP Error(all epochs): 0.0 \n",
      " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "Epoch 00001: val_mae improved from inf to 48.08258, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00002: val_mae did not improve from 48.08258\n",
      "\n",
      "Epoch 00003: val_mae did not improve from 48.08258\n",
      "\n",
      "Epoch 00004: val_mae did not improve from 48.08258\n",
      "\n",
      "Epoch 00005: val_mae did not improve from 48.08258\n",
      "\n",
      "Epoch 00006: val_mae did not improve from 48.08258\n",
      "\n",
      "Epoch 00007: val_mae did not improve from 48.08258\n",
      "\n",
      "Epoch 00008: val_mae did not improve from 48.08258\n",
      "\n",
      "Epoch 00009: val_mae did not improve from 48.08258\n",
      "\n",
      "Epoch 00010: val_mae improved from 48.08258 to 48.07038, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00011: val_mae improved from 48.07038 to 48.05776, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00012: val_mae improved from 48.05776 to 48.04457, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00013: val_mae improved from 48.04457 to 48.03075, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00014: val_mae improved from 48.03075 to 48.01647, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00015: val_mae improved from 48.01647 to 48.00183, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00016: val_mae improved from 48.00183 to 47.98719, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00017: val_mae improved from 47.98719 to 47.97240, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00018: val_mae improved from 47.97240 to 47.95694, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00019: val_mae improved from 47.95694 to 47.94002, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00020: val_mae improved from 47.94002 to 47.92176, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00021: val_mae improved from 47.92176 to 47.90191, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00022: val_mae improved from 47.90191 to 47.88068, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00023: val_mae improved from 47.88068 to 47.85796, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_3.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00024: val_mae improved from 47.85796 to 47.83489, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00025: val_mae improved from 47.83489 to 47.81257, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00026: val_mae improved from 47.81257 to 47.79197, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00027: val_mae improved from 47.79197 to 47.77188, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00028: val_mae improved from 47.77188 to 47.75080, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00029: val_mae improved from 47.75080 to 47.72974, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00030: val_mae improved from 47.72974 to 47.70732, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00031: val_mae improved from 47.70732 to 47.68287, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00032: val_mae improved from 47.68287 to 47.65521, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00033: val_mae improved from 47.65521 to 47.62539, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00034: val_mae improved from 47.62539 to 47.59095, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00035: val_mae improved from 47.59095 to 47.55510, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00036: val_mae improved from 47.55510 to 47.51862, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00037: val_mae improved from 47.51862 to 47.47974, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00038: val_mae improved from 47.47974 to 47.43882, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00039: val_mae improved from 47.43882 to 47.39953, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00040: val_mae improved from 47.39953 to 47.36218, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00041: val_mae improved from 47.36218 to 47.32366, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00042: val_mae improved from 47.32366 to 47.28505, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00043: val_mae improved from 47.28505 to 47.24315, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00044: val_mae improved from 47.24315 to 47.19919, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00045: val_mae improved from 47.19919 to 47.15439, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00046: val_mae improved from 47.15439 to 47.11098, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00047: val_mae improved from 47.11098 to 47.06702, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00048: val_mae improved from 47.06702 to 47.02288, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00049: val_mae improved from 47.02288 to 46.97741, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00050: val_mae improved from 46.97741 to 46.93351, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00051: val_mae improved from 46.93351 to 46.89032, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00052: val_mae improved from 46.89032 to 46.84441, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00053: val_mae improved from 46.84441 to 46.79979, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00054: val_mae improved from 46.79979 to 46.75905, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00055: val_mae improved from 46.75905 to 46.72202, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00056: val_mae improved from 46.72202 to 46.68657, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00057: val_mae improved from 46.68657 to 46.65271, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00058: val_mae improved from 46.65271 to 46.61662, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00059: val_mae improved from 46.61662 to 46.57447, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00060: val_mae improved from 46.57447 to 46.52816, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00061: val_mae improved from 46.52816 to 46.48143, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00062: val_mae improved from 46.48143 to 46.42579, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00063: val_mae improved from 46.42579 to 46.37187, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00064: val_mae improved from 46.37187 to 46.31597, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_3.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00065: val_mae improved from 46.31597 to 46.25822, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00066: val_mae improved from 46.25822 to 46.19534, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00067: val_mae improved from 46.19534 to 46.11501, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00068: val_mae improved from 46.11501 to 46.02515, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00069: val_mae improved from 46.02515 to 45.94240, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00070: val_mae improved from 45.94240 to 45.87867, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00071: val_mae improved from 45.87867 to 45.81016, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00072: val_mae improved from 45.81016 to 45.72972, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00073: val_mae improved from 45.72972 to 45.64636, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00074: val_mae improved from 45.64636 to 45.58090, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00075: val_mae improved from 45.58090 to 45.53371, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00076: val_mae improved from 45.53371 to 45.49710, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00077: val_mae improved from 45.49710 to 45.46051, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00078: val_mae improved from 45.46051 to 45.43518, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00079: val_mae improved from 45.43518 to 45.42231, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00080: val_mae improved from 45.42231 to 45.41631, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00081: val_mae improved from 45.41631 to 45.39905, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00082: val_mae improved from 45.39905 to 45.37080, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00083: val_mae improved from 45.37080 to 45.33007, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00084: val_mae improved from 45.33007 to 45.28835, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00085: val_mae improved from 45.28835 to 45.24956, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00086: val_mae improved from 45.24956 to 45.18303, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00087: val_mae improved from 45.18303 to 45.11376, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00088: val_mae improved from 45.11376 to 45.04062, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00089: val_mae improved from 45.04062 to 44.94600, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00090: val_mae improved from 44.94600 to 44.86959, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00091: val_mae improved from 44.86959 to 44.79476, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00092: val_mae improved from 44.79476 to 44.71805, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00093: val_mae improved from 44.71805 to 44.65250, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00094: val_mae improved from 44.65250 to 44.57199, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00095: val_mae improved from 44.57199 to 44.51872, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00096: val_mae improved from 44.51872 to 44.41376, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00097: val_mae improved from 44.41376 to 44.36470, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00098: val_mae improved from 44.36470 to 44.28043, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00099: val_mae improved from 44.28043 to 44.22523, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00100: val_mae improved from 44.22523 to 44.12441, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/30/best_model_lambda_3.h5\n",
      "\n",
      "Lambda: 1 , Time: 0:00:31\n",
      "Train Error(all epochs): 45.187298 \n",
      " [48.298, 48.228, 48.191, 48.164, 48.138, 48.118, 48.103, 48.091, 48.079, 48.067, 48.055, 48.043, 48.032, 48.02, 48.007, 47.996, 47.984, 47.971, 47.958, 47.945, 47.931, 47.918, 47.904, 47.889, 47.876, 47.862, 47.848, 47.833, 47.818, 47.802, 47.786, 47.771, 47.755, 47.738, 47.72, 47.702, 47.684, 47.665, 47.648, 47.63, 47.61, 47.59, 47.569, 47.549, 47.528, 47.505, 47.481, 47.457, 47.434, 47.41, 47.383, 47.357, 47.331, 47.304, 47.276, 47.249, 47.222, 47.195, 47.166, 47.135, 47.106, 47.073, 47.043, 47.011, 46.975, 46.942, 46.905, 46.865, 46.823, 46.782, 46.735, 46.686, 46.638, 46.59, 46.543, 46.494, 46.448, 46.407, 46.356, 46.299, 46.246, 46.201, 46.157, 46.1, 46.045, 45.995, 45.946, 45.89, 45.836, 45.782, 45.731, 45.672, 45.614, 45.554, 45.496, 45.438, 45.382, 45.322, 45.249, 45.187]\n",
      "Train FP Error(all epochs): 0.0 \n",
      " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Val Error(all epochs): 44.12440872192383 \n",
      " [48.083, 48.109, 48.127, 48.135, 48.134, 48.124, 48.11, 48.097, 48.083, 48.07, 48.058, 48.045, 48.031, 48.016, 48.002, 47.987, 47.972, 47.957, 47.94, 47.922, 47.902, 47.881, 47.858, 47.835, 47.813, 47.792, 47.772, 47.751, 47.73, 47.707, 47.683, 47.655, 47.625, 47.591, 47.555, 47.519, 47.48, 47.439, 47.4, 47.362, 47.324, 47.285, 47.243, 47.199, 47.154, 47.111, 47.067, 47.023, 46.977, 46.934, 46.89, 46.844, 46.8, 46.759, 46.722, 46.687, 46.653, 46.617, 46.574, 46.528, 46.481, 46.426, 46.372, 46.316, 46.258, 46.195, 46.115, 46.025, 45.942, 45.879, 45.81, 45.73, 45.646, 45.581, 45.534, 45.497, 45.461, 45.435, 45.422, 45.416, 45.399, 45.371, 45.33, 45.288, 45.25, 45.183, 45.114, 45.041, 44.946, 44.87, 44.795, 44.718, 44.652, 44.572, 44.519, 44.414, 44.365, 44.28, 44.225, 44.124]\n",
      "Val FP Error(all epochs): 0.0 \n",
      " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "Trainig set size: 30 , Time: 0:02:03 , best_lambda: 0.1 , min_  error: 41.095\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test starts:  36 , ends:  298\n",
      "2/2 [==============================] - 1s 334ms/step\n",
      "average_error:  39.999 , fp_average_error:  0.0\n",
      "\n",
      "\n",
      "\n",
      "number_samples: 60 , New samples: 60\n",
      "Validation size: 12 , starts: 60 , ends: 71\n",
      "\n",
      "Epoch 00001: val_mae improved from inf to 46.28682, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00002: val_mae did not improve from 46.28682\n",
      "\n",
      "Epoch 00003: val_mae did not improve from 46.28682\n",
      "\n",
      "Epoch 00004: val_mae did not improve from 46.28682\n",
      "\n",
      "Epoch 00005: val_mae improved from 46.28682 to 46.28252, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00006: val_mae improved from 46.28252 to 46.27585, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00007: val_mae improved from 46.27585 to 46.26804, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00008: val_mae improved from 46.26804 to 46.25830, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00009: val_mae improved from 46.25830 to 46.24648, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00010: val_mae improved from 46.24648 to 46.23304, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00011: val_mae improved from 46.23304 to 46.21774, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00012: val_mae improved from 46.21774 to 46.20131, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00013: val_mae improved from 46.20131 to 46.18401, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00014: val_mae improved from 46.18401 to 46.16679, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00015: val_mae improved from 46.16679 to 46.14879, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00016: val_mae improved from 46.14879 to 46.12992, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00017: val_mae improved from 46.12992 to 46.11176, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00018: val_mae improved from 46.11176 to 46.09415, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00019: val_mae improved from 46.09415 to 46.07678, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00020: val_mae improved from 46.07678 to 46.06066, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00021: val_mae improved from 46.06066 to 46.04494, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00022: val_mae improved from 46.04494 to 46.02958, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00023: val_mae improved from 46.02958 to 46.01431, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00024: val_mae improved from 46.01431 to 45.99905, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00025: val_mae improved from 45.99905 to 45.98356, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00026: val_mae improved from 45.98356 to 45.96773, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00027: val_mae improved from 45.96773 to 45.95122, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00028: val_mae improved from 45.95122 to 45.93543, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00029: val_mae improved from 45.93543 to 45.92125, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00030: val_mae improved from 45.92125 to 45.90767, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00031: val_mae improved from 45.90767 to 45.89438, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00032: val_mae improved from 45.89438 to 45.88054, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00033: val_mae improved from 45.88054 to 45.86520, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00034: val_mae improved from 45.86520 to 45.84816, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00035: val_mae improved from 45.84816 to 45.83072, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00036: val_mae improved from 45.83072 to 45.81252, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00037: val_mae improved from 45.81252 to 45.79141, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00038: val_mae improved from 45.79141 to 45.76993, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00039: val_mae improved from 45.76993 to 45.74754, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00040: val_mae improved from 45.74754 to 45.72455, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00041: val_mae improved from 45.72455 to 45.70169, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00042: val_mae improved from 45.70169 to 45.68008, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_0.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00043: val_mae improved from 45.68008 to 45.65652, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00044: val_mae improved from 45.65652 to 45.63041, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00045: val_mae improved from 45.63041 to 45.60489, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00046: val_mae improved from 45.60489 to 45.57612, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00047: val_mae improved from 45.57612 to 45.54883, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00048: val_mae improved from 45.54883 to 45.52040, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00049: val_mae improved from 45.52040 to 45.48584, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00050: val_mae improved from 45.48584 to 45.44916, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00051: val_mae improved from 45.44916 to 45.41385, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00052: val_mae improved from 45.41385 to 45.38019, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00053: val_mae improved from 45.38019 to 45.34803, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00054: val_mae improved from 45.34803 to 45.31797, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00055: val_mae improved from 45.31797 to 45.28448, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00056: val_mae improved from 45.28448 to 45.25305, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00057: val_mae improved from 45.25305 to 45.22336, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00058: val_mae improved from 45.22336 to 45.19739, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00059: val_mae improved from 45.19739 to 45.17433, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00060: val_mae improved from 45.17433 to 45.14389, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00061: val_mae improved from 45.14389 to 45.11113, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00062: val_mae improved from 45.11113 to 45.07811, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00063: val_mae improved from 45.07811 to 45.03923, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00064: val_mae improved from 45.03923 to 44.99311, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00065: val_mae improved from 44.99311 to 44.94899, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00066: val_mae improved from 44.94899 to 44.90871, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00067: val_mae improved from 44.90871 to 44.86754, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00068: val_mae improved from 44.86754 to 44.82706, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00069: val_mae improved from 44.82706 to 44.78311, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00070: val_mae improved from 44.78311 to 44.74693, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00071: val_mae improved from 44.74693 to 44.70918, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00072: val_mae improved from 44.70918 to 44.66898, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00073: val_mae improved from 44.66898 to 44.62912, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00074: val_mae improved from 44.62912 to 44.58329, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00075: val_mae improved from 44.58329 to 44.54514, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00076: val_mae improved from 44.54514 to 44.49798, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00077: val_mae improved from 44.49798 to 44.44002, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00078: val_mae improved from 44.44002 to 44.38193, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00079: val_mae improved from 44.38193 to 44.32006, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00080: val_mae improved from 44.32006 to 44.26927, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00081: val_mae improved from 44.26927 to 44.22255, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00082: val_mae improved from 44.22255 to 44.15918, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00083: val_mae improved from 44.15918 to 44.10556, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_0.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00084: val_mae improved from 44.10556 to 44.04861, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00085: val_mae improved from 44.04861 to 43.98555, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00086: val_mae improved from 43.98555 to 43.92263, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00087: val_mae improved from 43.92263 to 43.85539, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00088: val_mae improved from 43.85539 to 43.81482, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00089: val_mae improved from 43.81482 to 43.72879, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00090: val_mae improved from 43.72879 to 43.66330, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00091: val_mae improved from 43.66330 to 43.59121, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00092: val_mae improved from 43.59121 to 43.51902, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00093: val_mae improved from 43.51902 to 43.46570, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00094: val_mae improved from 43.46570 to 43.39438, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00095: val_mae improved from 43.39438 to 43.33247, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00096: val_mae improved from 43.33247 to 43.26878, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00097: val_mae improved from 43.26878 to 43.20583, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00098: val_mae improved from 43.20583 to 43.13828, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00099: val_mae improved from 43.13828 to 43.09251, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00100: val_mae improved from 43.09251 to 43.02053, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_0.h5\n",
      "\n",
      "Lambda: 0.001 , Time: 0:00:52\n",
      "Train Error(all epochs): 43.877335 \n",
      " [46.909, 46.864, 46.831, 46.802, 46.776, 46.753, 46.734, 46.716, 46.699, 46.685, 46.671, 46.658, 46.645, 46.633, 46.62, 46.607, 46.593, 46.579, 46.565, 46.551, 46.537, 46.524, 46.509, 46.494, 46.479, 46.464, 46.449, 46.433, 46.418, 46.401, 46.383, 46.366, 46.35, 46.332, 46.314, 46.296, 46.277, 46.258, 46.239, 46.219, 46.199, 46.178, 46.157, 46.136, 46.115, 46.092, 46.068, 46.045, 46.021, 45.996, 45.97, 45.943, 45.917, 45.89, 45.863, 45.836, 45.808, 45.778, 45.747, 45.717, 45.686, 45.655, 45.623, 45.591, 45.557, 45.523, 45.488, 45.453, 45.416, 45.38, 45.341, 45.301, 45.262, 45.222, 45.181, 45.141, 45.1, 45.057, 45.013, 44.967, 44.92, 44.874, 44.827, 44.781, 44.734, 44.682, 44.63, 44.577, 44.523, 44.471, 44.416, 44.358, 44.306, 44.246, 44.188, 44.129, 44.067, 44.003, 43.941, 43.877]\n",
      "Train FP Error(all epochs): 0.0 \n",
      " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Val Error(all epochs): 43.02053451538086 \n",
      " [46.287, 46.29, 46.291, 46.288, 46.283, 46.276, 46.268, 46.258, 46.246, 46.233, 46.218, 46.201, 46.184, 46.167, 46.149, 46.13, 46.112, 46.094, 46.077, 46.061, 46.045, 46.03, 46.014, 45.999, 45.984, 45.968, 45.951, 45.935, 45.921, 45.908, 45.894, 45.881, 45.865, 45.848, 45.831, 45.813, 45.791, 45.77, 45.748, 45.725, 45.702, 45.68, 45.657, 45.63, 45.605, 45.576, 45.549, 45.52, 45.486, 45.449, 45.414, 45.38, 45.348, 45.318, 45.284, 45.253, 45.223, 45.197, 45.174, 45.144, 45.111, 45.078, 45.039, 44.993, 44.949, 44.909, 44.868, 44.827, 44.783, 44.747, 44.709, 44.669, 44.629, 44.583, 44.545, 44.498, 44.44, 44.382, 44.32, 44.269, 44.223, 44.159, 44.106, 44.049, 43.986, 43.923, 43.855, 43.815, 43.729, 43.663, 43.591, 43.519, 43.466, 43.394, 43.332, 43.269, 43.206, 43.138, 43.093, 43.021]\n",
      "Val FP Error(all epochs): 0.0 \n",
      " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "Epoch 00001: val_mae improved from inf to 46.21494, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00002: val_mae did not improve from 46.21494\n",
      "\n",
      "Epoch 00003: val_mae did not improve from 46.21494\n",
      "\n",
      "Epoch 00004: val_mae did not improve from 46.21494\n",
      "\n",
      "Epoch 00005: val_mae improved from 46.21494 to 46.20185, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00006: val_mae improved from 46.20185 to 46.18274, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00007: val_mae improved from 46.18274 to 46.16098, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00008: val_mae improved from 46.16098 to 46.13857, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00009: val_mae improved from 46.13857 to 46.11670, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00010: val_mae improved from 46.11670 to 46.09426, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00011: val_mae improved from 46.09426 to 46.07101, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00012: val_mae improved from 46.07101 to 46.04544, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00013: val_mae improved from 46.04544 to 46.01712, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_1.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00014: val_mae improved from 46.01712 to 45.98710, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00015: val_mae improved from 45.98710 to 45.95669, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00016: val_mae improved from 45.95669 to 45.92597, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00017: val_mae improved from 45.92597 to 45.89547, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00018: val_mae improved from 45.89547 to 45.86449, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00019: val_mae improved from 45.86449 to 45.83339, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00020: val_mae improved from 45.83339 to 45.80223, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00021: val_mae improved from 45.80223 to 45.77147, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00022: val_mae improved from 45.77147 to 45.74117, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00023: val_mae improved from 45.74117 to 45.71212, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00024: val_mae improved from 45.71212 to 45.68391, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00025: val_mae improved from 45.68391 to 45.65620, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00026: val_mae improved from 45.65620 to 45.62819, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00027: val_mae improved from 45.62819 to 45.59967, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00028: val_mae improved from 45.59967 to 45.57081, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00029: val_mae improved from 45.57081 to 45.53996, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00030: val_mae improved from 45.53996 to 45.50626, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00031: val_mae improved from 45.50626 to 45.47080, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00032: val_mae improved from 45.47080 to 45.43416, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00033: val_mae improved from 45.43416 to 45.39781, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00034: val_mae improved from 45.39781 to 45.36096, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00035: val_mae improved from 45.36096 to 45.32338, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00036: val_mae improved from 45.32338 to 45.28490, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00037: val_mae improved from 45.28490 to 45.24392, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00038: val_mae improved from 45.24392 to 45.20303, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00039: val_mae improved from 45.20303 to 45.16211, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00040: val_mae improved from 45.16211 to 45.12059, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00041: val_mae improved from 45.12059 to 45.08005, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00042: val_mae improved from 45.08005 to 45.03877, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00043: val_mae improved from 45.03877 to 44.99744, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00044: val_mae improved from 44.99744 to 44.95628, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00045: val_mae improved from 44.95628 to 44.91231, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00046: val_mae improved from 44.91231 to 44.86688, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00047: val_mae improved from 44.86688 to 44.82029, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00048: val_mae improved from 44.82029 to 44.77148, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00049: val_mae improved from 44.77148 to 44.72070, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00050: val_mae improved from 44.72070 to 44.67001, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00051: val_mae improved from 44.67001 to 44.62188, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00052: val_mae improved from 44.62188 to 44.57457, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00053: val_mae improved from 44.57457 to 44.52573, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00054: val_mae improved from 44.52573 to 44.47075, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_1.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00055: val_mae improved from 44.47075 to 44.41019, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00056: val_mae improved from 44.41019 to 44.34877, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00057: val_mae improved from 44.34877 to 44.28619, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00058: val_mae improved from 44.28619 to 44.22268, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00059: val_mae improved from 44.22268 to 44.16056, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00060: val_mae improved from 44.16056 to 44.10350, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00061: val_mae improved from 44.10350 to 44.05203, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00062: val_mae improved from 44.05203 to 43.99049, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00063: val_mae improved from 43.99049 to 43.92432, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00064: val_mae improved from 43.92432 to 43.86679, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00065: val_mae improved from 43.86679 to 43.81043, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00066: val_mae improved from 43.81043 to 43.75010, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00067: val_mae improved from 43.75010 to 43.69203, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00068: val_mae improved from 43.69203 to 43.63713, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00069: val_mae improved from 43.63713 to 43.57356, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00070: val_mae improved from 43.57356 to 43.51480, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00071: val_mae improved from 43.51480 to 43.45427, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00072: val_mae improved from 43.45427 to 43.38544, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00073: val_mae improved from 43.38544 to 43.30931, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00074: val_mae improved from 43.30931 to 43.24570, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00075: val_mae improved from 43.24570 to 43.16707, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00076: val_mae improved from 43.16707 to 43.10148, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00077: val_mae improved from 43.10148 to 43.03541, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00078: val_mae improved from 43.03541 to 42.97311, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00079: val_mae improved from 42.97311 to 42.90332, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00080: val_mae improved from 42.90332 to 42.83380, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00081: val_mae improved from 42.83380 to 42.76413, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00082: val_mae improved from 42.76413 to 42.69420, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00083: val_mae improved from 42.69420 to 42.61779, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00084: val_mae improved from 42.61779 to 42.54069, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00085: val_mae improved from 42.54069 to 42.46344, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00086: val_mae improved from 42.46344 to 42.39133, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00087: val_mae improved from 42.39133 to 42.31665, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00088: val_mae improved from 42.31665 to 42.25792, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00089: val_mae improved from 42.25792 to 42.20906, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00090: val_mae improved from 42.20906 to 42.13781, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00091: val_mae improved from 42.13781 to 42.06544, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00092: val_mae improved from 42.06544 to 42.00610, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00093: val_mae improved from 42.00610 to 41.92093, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00094: val_mae improved from 41.92093 to 41.82814, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00095: val_mae improved from 41.82814 to 41.74796, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_1.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00096: val_mae improved from 41.74796 to 41.67865, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00097: val_mae improved from 41.67865 to 41.62597, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00098: val_mae improved from 41.62597 to 41.56853, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00099: val_mae improved from 41.56853 to 41.51544, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00100: val_mae improved from 41.51544 to 41.42311, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_1.h5\n",
      "\n",
      "Lambda: 0.01 , Time: 0:00:52\n",
      "Train Error(all epochs): 43.995598 \n",
      " [46.896, 46.858, 46.83, 46.809, 46.79, 46.772, 46.755, 46.742, 46.73, 46.717, 46.705, 46.693, 46.683, 46.671, 46.66, 46.649, 46.637, 46.625, 46.613, 46.601, 46.588, 46.575, 46.562, 46.549, 46.537, 46.523, 46.509, 46.495, 46.48, 46.465, 46.448, 46.432, 46.415, 46.398, 46.38, 46.363, 46.345, 46.327, 46.309, 46.29, 46.271, 46.251, 46.231, 46.21, 46.189, 46.167, 46.145, 46.124, 46.102, 46.078, 46.052, 46.026, 46.002, 45.976, 45.949, 45.921, 45.893, 45.865, 45.836, 45.806, 45.776, 45.745, 45.712, 45.679, 45.645, 45.613, 45.58, 45.544, 45.509, 45.471, 45.435, 45.395, 45.356, 45.317, 45.272, 45.233, 45.191, 45.147, 45.104, 45.06, 45.013, 44.969, 44.924, 44.875, 44.828, 44.782, 44.732, 44.679, 44.63, 44.576, 44.525, 44.477, 44.415, 44.357, 44.307, 44.246, 44.184, 44.122, 44.066, 43.996]\n",
      "Train FP Error(all epochs): 0.0 \n",
      " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Val Error(all epochs): 41.42311096191406 \n",
      " [46.215, 46.225, 46.224, 46.216, 46.202, 46.183, 46.161, 46.139, 46.117, 46.094, 46.071, 46.045, 46.017, 45.987, 45.957, 45.926, 45.895, 45.864, 45.833, 45.802, 45.771, 45.741, 45.712, 45.684, 45.656, 45.628, 45.6, 45.571, 45.54, 45.506, 45.471, 45.434, 45.398, 45.361, 45.323, 45.285, 45.244, 45.203, 45.162, 45.121, 45.08, 45.039, 44.997, 44.956, 44.912, 44.867, 44.82, 44.771, 44.721, 44.67, 44.622, 44.575, 44.526, 44.471, 44.41, 44.349, 44.286, 44.223, 44.161, 44.104, 44.052, 43.99, 43.924, 43.867, 43.81, 43.75, 43.692, 43.637, 43.574, 43.515, 43.454, 43.385, 43.309, 43.246, 43.167, 43.101, 43.035, 42.973, 42.903, 42.834, 42.764, 42.694, 42.618, 42.541, 42.463, 42.391, 42.317, 42.258, 42.209, 42.138, 42.065, 42.006, 41.921, 41.828, 41.748, 41.679, 41.626, 41.569, 41.515, 41.423]\n",
      "Val FP Error(all epochs): 0.0 \n",
      " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "Epoch 00001: val_mae improved from inf to 46.19901, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00002: val_mae did not improve from 46.19901\n",
      "\n",
      "Epoch 00003: val_mae did not improve from 46.19901\n",
      "\n",
      "Epoch 00004: val_mae improved from 46.19901 to 46.19714, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00005: val_mae improved from 46.19714 to 46.18808, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00006: val_mae improved from 46.18808 to 46.17856, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00007: val_mae improved from 46.17856 to 46.16727, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00008: val_mae improved from 46.16727 to 46.15233, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00009: val_mae improved from 46.15233 to 46.13359, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00010: val_mae improved from 46.13359 to 46.11152, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00011: val_mae improved from 46.11152 to 46.08705, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00012: val_mae improved from 46.08705 to 46.06129, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00013: val_mae improved from 46.06129 to 46.03502, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00014: val_mae improved from 46.03502 to 46.00881, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00015: val_mae improved from 46.00881 to 45.98303, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00016: val_mae improved from 45.98303 to 45.95761, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00017: val_mae improved from 45.95761 to 45.93187, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00018: val_mae improved from 45.93187 to 45.90509, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00019: val_mae improved from 45.90509 to 45.87642, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00020: val_mae improved from 45.87642 to 45.84661, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00021: val_mae improved from 45.84661 to 45.81649, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00022: val_mae improved from 45.81649 to 45.78624, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00023: val_mae improved from 45.78624 to 45.75616, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00024: val_mae improved from 45.75616 to 45.72635, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_2.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00025: val_mae improved from 45.72635 to 45.69659, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00026: val_mae improved from 45.69659 to 45.66781, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00027: val_mae improved from 45.66781 to 45.64004, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00028: val_mae improved from 45.64004 to 45.61335, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00029: val_mae improved from 45.61335 to 45.58689, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00030: val_mae improved from 45.58689 to 45.55898, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00031: val_mae improved from 45.55898 to 45.52929, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00032: val_mae improved from 45.52929 to 45.49744, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00033: val_mae improved from 45.49744 to 45.46399, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00034: val_mae improved from 45.46399 to 45.42989, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00035: val_mae improved from 45.42989 to 45.39484, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00036: val_mae improved from 45.39484 to 45.35822, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00037: val_mae improved from 45.35822 to 45.31985, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00038: val_mae improved from 45.31985 to 45.28088, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00039: val_mae improved from 45.28088 to 45.24252, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00040: val_mae improved from 45.24252 to 45.20505, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00041: val_mae improved from 45.20505 to 45.16853, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00042: val_mae improved from 45.16853 to 45.13288, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00043: val_mae improved from 45.13288 to 45.09688, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00044: val_mae improved from 45.09688 to 45.05928, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00045: val_mae improved from 45.05928 to 45.01966, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00046: val_mae improved from 45.01966 to 44.97717, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00047: val_mae improved from 44.97717 to 44.93329, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00048: val_mae improved from 44.93329 to 44.88726, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00049: val_mae improved from 44.88726 to 44.83805, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00050: val_mae improved from 44.83805 to 44.78781, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00051: val_mae improved from 44.78781 to 44.73545, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00052: val_mae improved from 44.73545 to 44.68536, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00053: val_mae improved from 44.68536 to 44.63965, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00054: val_mae improved from 44.63965 to 44.59259, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00055: val_mae improved from 44.59259 to 44.54197, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00056: val_mae improved from 44.54197 to 44.48971, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00057: val_mae improved from 44.48971 to 44.43639, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00058: val_mae improved from 44.43639 to 44.38483, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00059: val_mae improved from 44.38483 to 44.33743, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00060: val_mae improved from 44.33743 to 44.27972, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00061: val_mae improved from 44.27972 to 44.21752, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00062: val_mae improved from 44.21752 to 44.15242, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00063: val_mae improved from 44.15242 to 44.08245, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00064: val_mae improved from 44.08245 to 44.01434, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00065: val_mae improved from 44.01434 to 43.95804, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_2.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00066: val_mae improved from 43.95804 to 43.90354, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00067: val_mae improved from 43.90354 to 43.84131, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00068: val_mae improved from 43.84131 to 43.77964, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00069: val_mae improved from 43.77964 to 43.71812, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00070: val_mae improved from 43.71812 to 43.66087, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00071: val_mae improved from 43.66087 to 43.60065, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00072: val_mae improved from 43.60065 to 43.55951, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00073: val_mae improved from 43.55951 to 43.48169, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00074: val_mae improved from 43.48169 to 43.43940, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00075: val_mae improved from 43.43940 to 43.38715, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00076: val_mae improved from 43.38715 to 43.33382, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00077: val_mae improved from 43.33382 to 43.26851, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00078: val_mae improved from 43.26851 to 43.20135, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00079: val_mae improved from 43.20135 to 43.14482, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00080: val_mae improved from 43.14482 to 43.07254, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00081: val_mae improved from 43.07254 to 43.04221, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00082: val_mae improved from 43.04221 to 42.96138, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00083: val_mae improved from 42.96138 to 42.92547, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00084: val_mae improved from 42.92547 to 42.86260, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00085: val_mae improved from 42.86260 to 42.82635, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00086: val_mae improved from 42.82635 to 42.75404, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00087: val_mae improved from 42.75404 to 42.72666, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00088: val_mae improved from 42.72666 to 42.62544, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00089: val_mae improved from 42.62544 to 42.58614, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00090: val_mae improved from 42.58614 to 42.48495, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00091: val_mae improved from 42.48495 to 42.45615, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00092: val_mae improved from 42.45615 to 42.38701, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00093: val_mae improved from 42.38701 to 42.32910, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00094: val_mae improved from 42.32910 to 42.23404, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00095: val_mae improved from 42.23404 to 42.18894, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00096: val_mae improved from 42.18894 to 42.11134, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00097: val_mae improved from 42.11134 to 42.08540, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00098: val_mae improved from 42.08540 to 42.04225, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00099: val_mae improved from 42.04225 to 41.99996, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00100: val_mae improved from 41.99996 to 41.96026, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_2.h5\n",
      "\n",
      "Lambda: 0.1 , Time: 0:00:53\n",
      "Train Error(all epochs): 44.214745 \n",
      " [46.916, 46.866, 46.851, 46.834, 46.824, 46.811, 46.798, 46.785, 46.773, 46.764, 46.753, 46.744, 46.734, 46.725, 46.715, 46.706, 46.696, 46.686, 46.677, 46.667, 46.657, 46.646, 46.636, 46.624, 46.613, 46.601, 46.589, 46.577, 46.564, 46.55, 46.536, 46.522, 46.508, 46.493, 46.478, 46.462, 46.446, 46.429, 46.413, 46.395, 46.377, 46.358, 46.338, 46.318, 46.297, 46.276, 46.254, 46.232, 46.21, 46.187, 46.163, 46.138, 46.115, 46.09, 46.063, 46.037, 46.011, 45.984, 45.957, 45.93, 45.901, 45.872, 45.844, 45.815, 45.784, 45.754, 45.721, 45.689, 45.656, 45.621, 45.585, 45.55, 45.516, 45.478, 45.438, 45.401, 45.362, 45.322, 45.284, 45.24, 45.196, 45.156, 45.116, 45.065, 45.025, 44.974, 44.924, 44.875, 44.826, 44.77, 44.731, 44.673, 44.621, 44.563, 44.506, 44.452, 44.394, 44.334, 44.281, 44.215]\n",
      "Train FP Error(all epochs): 0.0 \n",
      " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Val Error(all epochs): 41.960262298583984 \n",
      " [46.199, 46.206, 46.204, 46.197, 46.188, 46.179, 46.167, 46.152, 46.134, 46.112, 46.087, 46.061, 46.035, 46.009, 45.983, 45.958, 45.932, 45.905, 45.876, 45.847, 45.816, 45.786, 45.756, 45.726, 45.697, 45.668, 45.64, 45.613, 45.587, 45.559, 45.529, 45.497, 45.464, 45.43, 45.395, 45.358, 45.32, 45.281, 45.243, 45.205, 45.169, 45.133, 45.097, 45.059, 45.02, 44.977, 44.933, 44.887, 44.838, 44.788, 44.735, 44.685, 44.64, 44.593, 44.542, 44.49, 44.436, 44.385, 44.337, 44.28, 44.218, 44.152, 44.082, 44.014, 43.958, 43.904, 43.841, 43.78, 43.718, 43.661, 43.601, 43.56, 43.482, 43.439, 43.387, 43.334, 43.269, 43.201, 43.145, 43.073, 43.042, 42.961, 42.925, 42.863, 42.826, 42.754, 42.727, 42.625, 42.586, 42.485, 42.456, 42.387, 42.329, 42.234, 42.189, 42.111, 42.085, 42.042, 42.0, 41.96]\n",
      "Val FP Error(all epochs): 0.0 \n",
      " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_mae improved from inf to 46.25190, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00002: val_mae improved from 46.25190 to 46.25064, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00003: val_mae improved from 46.25064 to 46.24504, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00004: val_mae improved from 46.24504 to 46.23862, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00005: val_mae improved from 46.23862 to 46.23043, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00006: val_mae improved from 46.23043 to 46.22059, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00007: val_mae improved from 46.22059 to 46.20892, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00008: val_mae improved from 46.20892 to 46.19558, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00009: val_mae improved from 46.19558 to 46.18091, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00010: val_mae improved from 46.18091 to 46.16499, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00011: val_mae improved from 46.16499 to 46.14810, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00012: val_mae improved from 46.14810 to 46.13084, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00013: val_mae improved from 46.13084 to 46.11379, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00014: val_mae improved from 46.11379 to 46.09734, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00015: val_mae improved from 46.09734 to 46.08120, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00016: val_mae improved from 46.08120 to 46.06489, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00017: val_mae improved from 46.06489 to 46.04830, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00018: val_mae improved from 46.04830 to 46.03220, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00019: val_mae improved from 46.03220 to 46.01661, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00020: val_mae improved from 46.01661 to 46.00179, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00021: val_mae improved from 46.00179 to 45.98796, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00022: val_mae improved from 45.98796 to 45.97377, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00023: val_mae improved from 45.97377 to 45.95836, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00024: val_mae improved from 45.95836 to 45.94239, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00025: val_mae improved from 45.94239 to 45.92681, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00026: val_mae improved from 45.92681 to 45.91139, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00027: val_mae improved from 45.91139 to 45.89529, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00028: val_mae improved from 45.89529 to 45.87745, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00029: val_mae improved from 45.87745 to 45.85798, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00030: val_mae improved from 45.85798 to 45.83864, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00031: val_mae improved from 45.83864 to 45.82000, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00032: val_mae improved from 45.82000 to 45.80095, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00033: val_mae improved from 45.80095 to 45.77966, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00034: val_mae improved from 45.77966 to 45.75596, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00035: val_mae improved from 45.75596 to 45.73143, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00036: val_mae improved from 45.73143 to 45.70613, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00037: val_mae improved from 45.70613 to 45.68184, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00038: val_mae improved from 45.68184 to 45.66365, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00039: val_mae improved from 45.66365 to 45.64988, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00040: val_mae improved from 45.64988 to 45.63322, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00041: val_mae improved from 45.63322 to 45.61332, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_3.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00042: val_mae improved from 45.61332 to 45.58946, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00043: val_mae improved from 45.58946 to 45.56245, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00044: val_mae improved from 45.56245 to 45.53114, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00045: val_mae improved from 45.53114 to 45.50298, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00046: val_mae improved from 45.50298 to 45.48055, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00047: val_mae improved from 45.48055 to 45.45886, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00048: val_mae improved from 45.45886 to 45.43256, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00049: val_mae improved from 45.43256 to 45.42266, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00050: val_mae improved from 45.42266 to 45.38727, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00051: val_mae improved from 45.38727 to 45.36462, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00052: val_mae improved from 45.36462 to 45.34455, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00053: val_mae improved from 45.34455 to 45.31620, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00054: val_mae improved from 45.31620 to 45.29521, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00055: val_mae improved from 45.29521 to 45.27321, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00056: val_mae improved from 45.27321 to 45.24302, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00057: val_mae improved from 45.24302 to 45.22095, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00058: val_mae improved from 45.22095 to 45.18723, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00059: val_mae improved from 45.18723 to 45.12580, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00060: val_mae improved from 45.12580 to 45.08286, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00061: val_mae improved from 45.08286 to 45.05069, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00062: val_mae improved from 45.05069 to 45.00367, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00063: val_mae improved from 45.00367 to 44.97473, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00064: val_mae improved from 44.97473 to 44.96729, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00065: val_mae improved from 44.96729 to 44.94643, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00066: val_mae improved from 44.94643 to 44.90391, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00067: val_mae improved from 44.90391 to 44.85157, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00068: val_mae improved from 44.85157 to 44.82891, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00069: val_mae improved from 44.82891 to 44.81845, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00070: val_mae improved from 44.81845 to 44.75209, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00071: val_mae improved from 44.75209 to 44.73280, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00072: val_mae improved from 44.73280 to 44.68354, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00073: val_mae improved from 44.68354 to 44.64375, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00074: val_mae improved from 44.64375 to 44.59986, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00075: val_mae improved from 44.59986 to 44.56259, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00076: val_mae improved from 44.56259 to 44.53796, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00077: val_mae improved from 44.53796 to 44.49963, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00078: val_mae improved from 44.49963 to 44.46534, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00079: val_mae improved from 44.46534 to 44.41870, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00080: val_mae improved from 44.41870 to 44.36018, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00081: val_mae improved from 44.36018 to 44.30911, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00082: val_mae improved from 44.30911 to 44.26693, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_3.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00083: val_mae improved from 44.26693 to 44.25412, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00084: val_mae improved from 44.25412 to 44.15137, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00085: val_mae did not improve from 44.15137\n",
      "\n",
      "Epoch 00086: val_mae improved from 44.15137 to 44.07607, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00087: val_mae improved from 44.07607 to 43.97056, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00088: val_mae did not improve from 43.97056\n",
      "\n",
      "Epoch 00089: val_mae improved from 43.97056 to 43.94885, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00090: val_mae improved from 43.94885 to 43.86874, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00091: val_mae improved from 43.86874 to 43.81947, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00092: val_mae improved from 43.81947 to 43.76189, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00093: val_mae improved from 43.76189 to 43.68703, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00094: val_mae did not improve from 43.68703\n",
      "\n",
      "Epoch 00095: val_mae improved from 43.68703 to 43.67766, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00096: val_mae improved from 43.67766 to 43.61646, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00097: val_mae improved from 43.61646 to 43.56749, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00098: val_mae improved from 43.56749 to 43.51035, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00099: val_mae improved from 43.51035 to 43.40321, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00100: val_mae improved from 43.40321 to 43.32411, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/60/best_model_lambda_3.h5\n",
      "\n",
      "Lambda: 1 , Time: 0:00:57\n",
      "Train Error(all epochs): 44.473404 \n",
      " [46.897, 46.871, 46.858, 46.842, 46.83, 46.82, 46.81, 46.801, 46.792, 46.782, 46.773, 46.764, 46.755, 46.746, 46.737, 46.728, 46.719, 46.71, 46.701, 46.691, 46.681, 46.67, 46.66, 46.65, 46.64, 46.63, 46.619, 46.607, 46.595, 46.583, 46.57, 46.556, 46.542, 46.527, 46.513, 46.498, 46.484, 46.468, 46.452, 46.434, 46.418, 46.402, 46.384, 46.367, 46.348, 46.329, 46.308, 46.289, 46.271, 46.249, 46.229, 46.204, 46.18, 46.161, 46.139, 46.116, 46.098, 46.072, 46.041, 46.021, 45.99, 45.965, 45.935, 45.91, 45.877, 45.852, 45.82, 45.787, 45.757, 45.729, 45.702, 45.665, 45.636, 45.6, 45.565, 45.53, 45.493, 45.463, 45.423, 45.385, 45.349, 45.313, 45.274, 45.238, 45.21, 45.148, 45.114, 45.076, 45.025, 44.978, 44.939, 44.889, 44.839, 44.794, 44.737, 44.684, 44.635, 44.575, 44.525, 44.473]\n",
      "Train FP Error(all epochs): 0.0 \n",
      " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Val Error(all epochs): 43.3241081237793 \n",
      " [46.252, 46.251, 46.245, 46.239, 46.23, 46.221, 46.209, 46.196, 46.181, 46.165, 46.148, 46.131, 46.114, 46.097, 46.081, 46.065, 46.048, 46.032, 46.017, 46.002, 45.988, 45.974, 45.958, 45.942, 45.927, 45.911, 45.895, 45.877, 45.858, 45.839, 45.82, 45.801, 45.78, 45.756, 45.731, 45.706, 45.682, 45.664, 45.65, 45.633, 45.613, 45.589, 45.562, 45.531, 45.503, 45.481, 45.459, 45.433, 45.423, 45.387, 45.365, 45.345, 45.316, 45.295, 45.273, 45.243, 45.221, 45.187, 45.126, 45.083, 45.051, 45.004, 44.975, 44.967, 44.946, 44.904, 44.852, 44.829, 44.818, 44.752, 44.733, 44.684, 44.644, 44.6, 44.563, 44.538, 44.5, 44.465, 44.419, 44.36, 44.309, 44.267, 44.254, 44.151, 44.171, 44.076, 43.971, 43.975, 43.949, 43.869, 43.819, 43.762, 43.687, 43.689, 43.678, 43.616, 43.567, 43.51, 43.403, 43.324]\n",
      "Val FP Error(all epochs): 0.0 \n",
      " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "Trainig set size: 60 , Time: 0:03:36 , best_lambda: 0.01 , min_  error: 41.423\n",
      "Test starts:  72 , ends:  298\n",
      "1/1 [==============================] - 1s 695ms/step\n",
      "average_error:  42.759 , fp_average_error:  0.0\n",
      "\n",
      "\n",
      "\n",
      "number_samples: 90 , New samples: 90\n",
      "Validation size: 18 , starts: 90 , ends: 107\n",
      "\n",
      "Epoch 00001: val_mae improved from inf to 48.64233, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00002: val_mae did not improve from 48.64233\n",
      "\n",
      "Epoch 00003: val_mae did not improve from 48.64233\n",
      "\n",
      "Epoch 00004: val_mae did not improve from 48.64233\n",
      "\n",
      "Epoch 00005: val_mae improved from 48.64233 to 48.64129, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00006: val_mae improved from 48.64129 to 48.63359, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00007: val_mae improved from 48.63359 to 48.62581, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00008: val_mae improved from 48.62581 to 48.61826, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00009: val_mae improved from 48.61826 to 48.60985, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00010: val_mae improved from 48.60985 to 48.59966, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00011: val_mae improved from 48.59966 to 48.58831, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00012: val_mae improved from 48.58831 to 48.57589, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_0.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00013: val_mae improved from 48.57589 to 48.56250, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00014: val_mae improved from 48.56250 to 48.54829, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00015: val_mae improved from 48.54829 to 48.53269, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00016: val_mae improved from 48.53269 to 48.51643, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00017: val_mae improved from 48.51643 to 48.50001, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00018: val_mae improved from 48.50001 to 48.48408, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00019: val_mae improved from 48.48408 to 48.46822, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00020: val_mae improved from 48.46822 to 48.45117, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00021: val_mae improved from 48.45117 to 48.43292, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00022: val_mae improved from 48.43292 to 48.41446, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00023: val_mae improved from 48.41446 to 48.39530, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00024: val_mae improved from 48.39530 to 48.37498, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00025: val_mae improved from 48.37498 to 48.35405, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00026: val_mae improved from 48.35405 to 48.33214, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00027: val_mae improved from 48.33214 to 48.30962, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00028: val_mae improved from 48.30962 to 48.28658, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00029: val_mae improved from 48.28658 to 48.26198, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00030: val_mae improved from 48.26198 to 48.23638, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00031: val_mae improved from 48.23638 to 48.20875, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00032: val_mae improved from 48.20875 to 48.18054, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00033: val_mae improved from 48.18054 to 48.15211, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00034: val_mae improved from 48.15211 to 48.12370, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00035: val_mae improved from 48.12370 to 48.09450, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00036: val_mae improved from 48.09450 to 48.06564, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00037: val_mae improved from 48.06564 to 48.03636, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00038: val_mae improved from 48.03636 to 48.00854, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00039: val_mae improved from 48.00854 to 47.98228, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00040: val_mae improved from 47.98228 to 47.95390, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00041: val_mae improved from 47.95390 to 47.92573, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00042: val_mae improved from 47.92573 to 47.89574, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00043: val_mae improved from 47.89574 to 47.86425, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00044: val_mae improved from 47.86425 to 47.83300, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00045: val_mae improved from 47.83300 to 47.80412, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00046: val_mae improved from 47.80412 to 47.77627, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00047: val_mae improved from 47.77627 to 47.74875, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00048: val_mae improved from 47.74875 to 47.71895, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00049: val_mae improved from 47.71895 to 47.68983, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00050: val_mae improved from 47.68983 to 47.66079, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00051: val_mae improved from 47.66079 to 47.62231, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00052: val_mae improved from 47.62231 to 47.58367, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00053: val_mae improved from 47.58367 to 47.54273, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_0.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00054: val_mae improved from 47.54273 to 47.50091, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00055: val_mae improved from 47.50091 to 47.46825, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00056: val_mae improved from 47.46825 to 47.43246, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00057: val_mae improved from 47.43246 to 47.38932, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00058: val_mae improved from 47.38932 to 47.34529, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00059: val_mae improved from 47.34529 to 47.30994, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00060: val_mae improved from 47.30994 to 47.27163, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00061: val_mae improved from 47.27163 to 47.22621, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00062: val_mae improved from 47.22621 to 47.17654, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00063: val_mae improved from 47.17654 to 47.11953, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00064: val_mae improved from 47.11953 to 47.05209, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00065: val_mae improved from 47.05209 to 46.98158, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00066: val_mae improved from 46.98158 to 46.93140, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00067: val_mae improved from 46.93140 to 46.87470, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00068: val_mae improved from 46.87470 to 46.78760, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00069: val_mae improved from 46.78760 to 46.70977, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00070: val_mae improved from 46.70977 to 46.63596, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00071: val_mae improved from 46.63596 to 46.56384, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00072: val_mae improved from 46.56384 to 46.48056, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00073: val_mae improved from 46.48056 to 46.38042, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00074: val_mae improved from 46.38042 to 46.27868, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00075: val_mae improved from 46.27868 to 46.17377, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00076: val_mae improved from 46.17377 to 46.09858, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00077: val_mae improved from 46.09858 to 46.00020, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00078: val_mae improved from 46.00020 to 45.91049, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00079: val_mae improved from 45.91049 to 45.84878, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00080: val_mae improved from 45.84878 to 45.75082, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00081: val_mae improved from 45.75082 to 45.64109, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00082: val_mae improved from 45.64109 to 45.55650, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00083: val_mae improved from 45.55650 to 45.48214, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00084: val_mae improved from 45.48214 to 45.42179, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00085: val_mae improved from 45.42179 to 45.30317, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00086: val_mae improved from 45.30317 to 45.19164, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00087: val_mae improved from 45.19164 to 45.12173, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00088: val_mae improved from 45.12173 to 45.03275, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00089: val_mae improved from 45.03275 to 44.91449, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00090: val_mae improved from 44.91449 to 44.81598, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00091: val_mae improved from 44.81598 to 44.73048, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00092: val_mae improved from 44.73048 to 44.64078, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00093: val_mae improved from 44.64078 to 44.54441, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00094: val_mae improved from 44.54441 to 44.39275, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_0.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00095: val_mae improved from 44.39275 to 44.24224, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00096: val_mae improved from 44.24224 to 44.10061, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00097: val_mae improved from 44.10061 to 43.90789, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00098: val_mae improved from 43.90789 to 43.70450, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00099: val_mae improved from 43.70450 to 43.46864, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00100: val_mae improved from 43.46864 to 43.30357, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_0.h5\n",
      "\n",
      "Lambda: 0.001 , Time: 0:01:16\n",
      "Train Error(all epochs): 42.960472 \n",
      " [46.122, 46.082, 46.049, 46.022, 46.0, 45.981, 45.966, 45.952, 45.94, 45.928, 45.916, 45.905, 45.893, 45.881, 45.869, 45.857, 45.846, 45.834, 45.822, 45.809, 45.797, 45.783, 45.77, 45.756, 45.743, 45.728, 45.714, 45.7, 45.685, 45.67, 45.654, 45.638, 45.621, 45.604, 45.586, 45.568, 45.55, 45.532, 45.513, 45.494, 45.475, 45.456, 45.435, 45.413, 45.39, 45.367, 45.344, 45.32, 45.297, 45.274, 45.249, 45.221, 45.194, 45.167, 45.139, 45.111, 45.081, 45.052, 45.021, 44.989, 44.956, 44.924, 44.891, 44.856, 44.82, 44.783, 44.748, 44.711, 44.673, 44.632, 44.593, 44.553, 44.51, 44.467, 44.423, 44.38, 44.335, 44.288, 44.24, 44.192, 44.141, 44.09, 44.039, 43.989, 43.935, 43.879, 43.822, 43.768, 43.709, 43.646, 43.582, 43.518, 43.451, 43.384, 43.317, 43.251, 43.183, 43.111, 43.035, 42.96]\n",
      "Train FP Error(all epochs): 0.0 \n",
      " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Val Error(all epochs): 43.30357360839844 \n",
      " [48.642, 48.649, 48.65, 48.647, 48.641, 48.634, 48.626, 48.618, 48.61, 48.6, 48.588, 48.576, 48.562, 48.548, 48.533, 48.516, 48.5, 48.484, 48.468, 48.451, 48.433, 48.414, 48.395, 48.375, 48.354, 48.332, 48.31, 48.287, 48.262, 48.236, 48.209, 48.181, 48.152, 48.124, 48.095, 48.066, 48.036, 48.009, 47.982, 47.954, 47.926, 47.896, 47.864, 47.833, 47.804, 47.776, 47.749, 47.719, 47.69, 47.661, 47.622, 47.584, 47.543, 47.501, 47.468, 47.432, 47.389, 47.345, 47.31, 47.272, 47.226, 47.177, 47.12, 47.052, 46.982, 46.931, 46.875, 46.788, 46.71, 46.636, 46.564, 46.481, 46.38, 46.279, 46.174, 46.099, 46.0, 45.91, 45.849, 45.751, 45.641, 45.556, 45.482, 45.422, 45.303, 45.192, 45.122, 45.033, 44.914, 44.816, 44.73, 44.641, 44.544, 44.393, 44.242, 44.101, 43.908, 43.704, 43.469, 43.304]\n",
      "Val FP Error(all epochs): 0.0 \n",
      " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "Epoch 00001: val_mae improved from inf to 48.56631, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00002: val_mae improved from 48.56631 to 48.55652, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00003: val_mae improved from 48.55652 to 48.55128, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00004: val_mae improved from 48.55128 to 48.54885, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00005: val_mae did not improve from 48.54885\n",
      "\n",
      "Epoch 00006: val_mae did not improve from 48.54885\n",
      "\n",
      "Epoch 00007: val_mae did not improve from 48.54885\n",
      "\n",
      "Epoch 00008: val_mae did not improve from 48.54885\n",
      "\n",
      "Epoch 00009: val_mae did not improve from 48.54885\n",
      "\n",
      "Epoch 00010: val_mae did not improve from 48.54885\n",
      "\n",
      "Epoch 00011: val_mae did not improve from 48.54885\n",
      "\n",
      "Epoch 00012: val_mae did not improve from 48.54885\n",
      "\n",
      "Epoch 00013: val_mae did not improve from 48.54885\n",
      "\n",
      "Epoch 00014: val_mae did not improve from 48.54885\n",
      "\n",
      "Epoch 00015: val_mae did not improve from 48.54885\n",
      "\n",
      "Epoch 00016: val_mae did not improve from 48.54885\n",
      "\n",
      "Epoch 00017: val_mae did not improve from 48.54885\n",
      "\n",
      "Epoch 00018: val_mae did not improve from 48.54885\n",
      "\n",
      "Epoch 00019: val_mae did not improve from 48.54885\n",
      "\n",
      "Epoch 00020: val_mae did not improve from 48.54885\n",
      "\n",
      "Epoch 00021: val_mae did not improve from 48.54885\n",
      "\n",
      "Epoch 00022: val_mae did not improve from 48.54885\n",
      "\n",
      "Epoch 00023: val_mae did not improve from 48.54885\n",
      "\n",
      "Epoch 00024: val_mae did not improve from 48.54885\n",
      "\n",
      "Epoch 00025: val_mae did not improve from 48.54885\n",
      "\n",
      "Epoch 00026: val_mae did not improve from 48.54885\n",
      "\n",
      "Epoch 00027: val_mae did not improve from 48.54885\n",
      "\n",
      "Epoch 00028: val_mae did not improve from 48.54885\n",
      "\n",
      "Epoch 00029: val_mae did not improve from 48.54885\n",
      "\n",
      "Epoch 00030: val_mae improved from 48.54885 to 48.54514, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00031: val_mae improved from 48.54514 to 48.52545, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00032: val_mae improved from 48.52545 to 48.50742, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00033: val_mae improved from 48.50742 to 48.49467, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00034: val_mae improved from 48.49467 to 48.47956, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00035: val_mae improved from 48.47956 to 48.46273, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00036: val_mae improved from 48.46273 to 48.45103, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00037: val_mae improved from 48.45103 to 48.44191, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00038: val_mae improved from 48.44191 to 48.43408, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00039: val_mae improved from 48.43408 to 48.42071, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00040: val_mae improved from 48.42071 to 48.41028, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_1.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00041: val_mae improved from 48.41028 to 48.39270, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00042: val_mae improved from 48.39270 to 48.36386, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00043: val_mae improved from 48.36386 to 48.33662, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00044: val_mae improved from 48.33662 to 48.31356, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00045: val_mae improved from 48.31356 to 48.28927, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00046: val_mae improved from 48.28927 to 48.28687, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00047: val_mae improved from 48.28687 to 48.25657, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00048: val_mae improved from 48.25657 to 48.21004, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00049: val_mae improved from 48.21004 to 48.17354, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00050: val_mae improved from 48.17354 to 48.13759, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00051: val_mae improved from 48.13759 to 48.11259, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00052: val_mae improved from 48.11259 to 48.06626, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00053: val_mae improved from 48.06626 to 48.03427, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00054: val_mae improved from 48.03427 to 47.98706, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00055: val_mae improved from 47.98706 to 47.97076, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00056: val_mae improved from 47.97076 to 47.93224, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00057: val_mae improved from 47.93224 to 47.89270, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00058: val_mae improved from 47.89270 to 47.85238, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00059: val_mae improved from 47.85238 to 47.77332, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00060: val_mae improved from 47.77332 to 47.74308, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00061: val_mae improved from 47.74308 to 47.66542, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00062: val_mae improved from 47.66542 to 47.59303, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00063: val_mae improved from 47.59303 to 47.51557, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00064: val_mae improved from 47.51557 to 47.47487, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00065: val_mae improved from 47.47487 to 47.42368, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00066: val_mae improved from 47.42368 to 47.39037, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00067: val_mae improved from 47.39037 to 47.35160, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00068: val_mae improved from 47.35160 to 47.21000, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00069: val_mae did not improve from 47.21000\n",
      "\n",
      "Epoch 00070: val_mae improved from 47.21000 to 47.15121, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00071: val_mae improved from 47.15121 to 47.10216, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00072: val_mae improved from 47.10216 to 47.06866, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00073: val_mae improved from 47.06866 to 46.94789, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00074: val_mae improved from 46.94789 to 46.89256, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00075: val_mae improved from 46.89256 to 46.80959, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00076: val_mae improved from 46.80959 to 46.63942, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00077: val_mae improved from 46.63942 to 46.54329, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00078: val_mae improved from 46.54329 to 46.48478, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00079: val_mae improved from 46.48478 to 46.26258, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00080: val_mae improved from 46.26258 to 46.11066, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00081: val_mae improved from 46.11066 to 46.04646, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00082: val_mae improved from 46.04646 to 45.85562, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_1.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00083: val_mae improved from 45.85562 to 45.73280, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00084: val_mae improved from 45.73280 to 45.66197, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00085: val_mae did not improve from 45.66197\n",
      "\n",
      "Epoch 00086: val_mae improved from 45.66197 to 45.63707, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00087: val_mae improved from 45.63707 to 45.60358, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00088: val_mae improved from 45.60358 to 45.52837, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00089: val_mae improved from 45.52837 to 45.42522, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00090: val_mae did not improve from 45.42522\n",
      "\n",
      "Epoch 00091: val_mae improved from 45.42522 to 45.34974, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00092: val_mae improved from 45.34974 to 45.28147, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00093: val_mae improved from 45.28147 to 45.09203, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00094: val_mae improved from 45.09203 to 45.08359, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00095: val_mae improved from 45.08359 to 44.96817, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00096: val_mae improved from 44.96817 to 44.76396, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00097: val_mae improved from 44.76396 to 44.71884, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00098: val_mae improved from 44.71884 to 44.54176, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00099: val_mae improved from 44.54176 to 44.50668, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00100: val_mae improved from 44.50668 to 44.27445, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_1.h5\n",
      "\n",
      "Lambda: 0.01 , Time: 0:01:13\n",
      "Train Error(all epochs): 41.900883 \n",
      " [46.103, 46.057, 46.005, 45.966, 45.936, 45.912, 45.893, 45.876, 45.862, 45.848, 45.835, 45.822, 45.809, 45.796, 45.784, 45.77, 45.756, 45.742, 45.727, 45.711, 45.695, 45.678, 45.662, 45.645, 45.629, 45.612, 45.594, 45.575, 45.557, 45.538, 45.519, 45.497, 45.476, 45.455, 45.433, 45.41, 45.387, 45.364, 45.341, 45.316, 45.291, 45.265, 45.237, 45.209, 45.182, 45.151, 45.123, 45.09, 45.055, 45.022, 44.987, 44.954, 44.917, 44.882, 44.841, 44.804, 44.763, 44.723, 44.683, 44.636, 44.596, 44.547, 44.501, 44.454, 44.411, 44.362, 44.31, 44.263, 44.202, 44.159, 44.091, 44.036, 43.988, 43.923, 43.868, 43.81, 43.736, 43.678, 43.622, 43.533, 43.461, 43.396, 43.305, 43.225, 43.143, 43.08, 43.014, 42.927, 42.837, 42.75, 42.683, 42.591, 42.518, 42.424, 42.348, 42.264, 42.165, 42.082, 41.984, 41.901]\n",
      "Train FP Error(all epochs): 0.0 \n",
      " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Val Error(all epochs): 44.27444839477539 \n",
      " [48.566, 48.557, 48.551, 48.549, 48.551, 48.556, 48.562, 48.566, 48.567, 48.568, 48.57, 48.573, 48.578, 48.583, 48.588, 48.593, 48.596, 48.596, 48.596, 48.593, 48.588, 48.586, 48.589, 48.591, 48.589, 48.583, 48.574, 48.566, 48.557, 48.545, 48.525, 48.507, 48.495, 48.48, 48.463, 48.451, 48.442, 48.434, 48.421, 48.41, 48.393, 48.364, 48.337, 48.314, 48.289, 48.287, 48.257, 48.21, 48.174, 48.138, 48.113, 48.066, 48.034, 47.987, 47.971, 47.932, 47.893, 47.852, 47.773, 47.743, 47.665, 47.593, 47.516, 47.475, 47.424, 47.39, 47.352, 47.21, 47.235, 47.151, 47.102, 47.069, 46.948, 46.893, 46.81, 46.639, 46.543, 46.485, 46.263, 46.111, 46.046, 45.856, 45.733, 45.662, 45.685, 45.637, 45.604, 45.528, 45.425, 45.477, 45.35, 45.281, 45.092, 45.084, 44.968, 44.764, 44.719, 44.542, 44.507, 44.274]\n",
      "Val FP Error(all epochs): 0.0 \n",
      " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "Epoch 00001: val_mae improved from inf to 48.64024, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00002: val_mae did not improve from 48.64024\n",
      "\n",
      "Epoch 00003: val_mae did not improve from 48.64024\n",
      "\n",
      "Epoch 00004: val_mae did not improve from 48.64024\n",
      "\n",
      "Epoch 00005: val_mae did not improve from 48.64024\n",
      "\n",
      "Epoch 00006: val_mae did not improve from 48.64024\n",
      "\n",
      "Epoch 00007: val_mae did not improve from 48.64024\n",
      "\n",
      "Epoch 00008: val_mae did not improve from 48.64024\n",
      "\n",
      "Epoch 00009: val_mae did not improve from 48.64024\n",
      "\n",
      "Epoch 00010: val_mae did not improve from 48.64024\n",
      "\n",
      "Epoch 00011: val_mae improved from 48.64024 to 48.63901, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00012: val_mae improved from 48.63901 to 48.63173, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00013: val_mae improved from 48.63173 to 48.62400, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00014: val_mae improved from 48.62400 to 48.61612, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00015: val_mae improved from 48.61612 to 48.60826, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00016: val_mae improved from 48.60826 to 48.60025, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00017: val_mae improved from 48.60025 to 48.59216, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00018: val_mae improved from 48.59216 to 48.58270, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_2.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00019: val_mae improved from 48.58270 to 48.57143, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00020: val_mae improved from 48.57143 to 48.55941, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00021: val_mae improved from 48.55941 to 48.54674, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00022: val_mae improved from 48.54674 to 48.53271, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00023: val_mae improved from 48.53271 to 48.51677, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00024: val_mae improved from 48.51677 to 48.49930, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00025: val_mae improved from 48.49930 to 48.48016, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00026: val_mae improved from 48.48016 to 48.46091, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00027: val_mae improved from 48.46091 to 48.44191, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00028: val_mae improved from 48.44191 to 48.42316, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00029: val_mae improved from 48.42316 to 48.40527, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00030: val_mae improved from 48.40527 to 48.38551, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00031: val_mae improved from 48.38551 to 48.36330, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00032: val_mae improved from 48.36330 to 48.33769, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00033: val_mae improved from 48.33769 to 48.30941, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00034: val_mae improved from 48.30941 to 48.28169, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00035: val_mae improved from 48.28169 to 48.25434, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00036: val_mae improved from 48.25434 to 48.22625, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00037: val_mae improved from 48.22625 to 48.19666, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00038: val_mae improved from 48.19666 to 48.16570, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00039: val_mae improved from 48.16570 to 48.13823, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00040: val_mae improved from 48.13823 to 48.11514, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00041: val_mae improved from 48.11514 to 48.08781, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00042: val_mae improved from 48.08781 to 48.05684, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00043: val_mae improved from 48.05684 to 48.02615, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00044: val_mae improved from 48.02615 to 47.99752, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00045: val_mae improved from 47.99752 to 47.97182, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00046: val_mae improved from 47.97182 to 47.95041, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00047: val_mae improved from 47.95041 to 47.92763, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00048: val_mae improved from 47.92763 to 47.89524, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00049: val_mae improved from 47.89524 to 47.86645, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00050: val_mae improved from 47.86645 to 47.84502, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00051: val_mae improved from 47.84502 to 47.82826, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00052: val_mae improved from 47.82826 to 47.80827, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00053: val_mae improved from 47.80827 to 47.78571, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00054: val_mae improved from 47.78571 to 47.75951, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00055: val_mae improved from 47.75951 to 47.72792, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00056: val_mae improved from 47.72792 to 47.69678, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00057: val_mae improved from 47.69678 to 47.66936, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00058: val_mae improved from 47.66936 to 47.63561, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00059: val_mae improved from 47.63561 to 47.59861, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_2.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00060: val_mae improved from 47.59861 to 47.57187, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00061: val_mae improved from 47.57187 to 47.54295, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00062: val_mae improved from 47.54295 to 47.48529, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00063: val_mae improved from 47.48529 to 47.43934, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00064: val_mae improved from 47.43934 to 47.39248, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00065: val_mae improved from 47.39248 to 47.32584, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00066: val_mae improved from 47.32584 to 47.27236, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00067: val_mae improved from 47.27236 to 47.21638, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00068: val_mae improved from 47.21638 to 47.15686, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00069: val_mae improved from 47.15686 to 47.10564, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00070: val_mae improved from 47.10564 to 47.04903, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00071: val_mae improved from 47.04903 to 47.00587, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00072: val_mae improved from 47.00587 to 46.94625, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00073: val_mae improved from 46.94625 to 46.87910, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00074: val_mae improved from 46.87910 to 46.81877, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00075: val_mae improved from 46.81877 to 46.72878, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00076: val_mae improved from 46.72878 to 46.65254, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00077: val_mae improved from 46.65254 to 46.58121, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00078: val_mae improved from 46.58121 to 46.49406, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00079: val_mae improved from 46.49406 to 46.40508, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00080: val_mae improved from 46.40508 to 46.30487, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00081: val_mae improved from 46.30487 to 46.24069, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00082: val_mae improved from 46.24069 to 46.17006, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00083: val_mae improved from 46.17006 to 46.10013, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00084: val_mae improved from 46.10013 to 46.07235, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00085: val_mae improved from 46.07235 to 46.01789, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00086: val_mae improved from 46.01789 to 46.01385, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00087: val_mae improved from 46.01385 to 45.93592, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00088: val_mae improved from 45.93592 to 45.91902, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00089: val_mae improved from 45.91902 to 45.85441, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00090: val_mae improved from 45.85441 to 45.75774, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00091: val_mae improved from 45.75774 to 45.71245, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00092: val_mae improved from 45.71245 to 45.67879, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00093: val_mae improved from 45.67879 to 45.59427, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00094: val_mae improved from 45.59427 to 45.50804, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00095: val_mae improved from 45.50804 to 45.43645, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00096: val_mae improved from 45.43645 to 45.35246, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00097: val_mae improved from 45.35246 to 45.30397, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00098: val_mae improved from 45.30397 to 45.27532, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00099: val_mae improved from 45.27532 to 45.19374, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00100: val_mae improved from 45.19374 to 45.13771, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_2.h5\n",
      "\n",
      "Lambda: 0.1 , Time: 0:01:14\n",
      "Train Error(all epochs): 42.88309 \n",
      " [46.104, 46.063, 46.023, 45.998, 45.978, 45.961, 45.948, 45.934, 45.921, 45.909, 45.897, 45.885, 45.873, 45.861, 45.85, 45.838, 45.826, 45.813, 45.8, 45.787, 45.773, 45.759, 45.745, 45.731, 45.717, 45.703, 45.689, 45.674, 45.659, 45.644, 45.628, 45.612, 45.595, 45.578, 45.561, 45.543, 45.525, 45.507, 45.488, 45.469, 45.449, 45.429, 45.407, 45.386, 45.364, 45.341, 45.317, 45.293, 45.267, 45.242, 45.215, 45.187, 45.16, 45.132, 45.103, 45.074, 45.043, 45.012, 44.98, 44.948, 44.916, 44.884, 44.85, 44.814, 44.777, 44.738, 44.701, 44.661, 44.622, 44.583, 44.541, 44.498, 44.453, 44.407, 44.362, 44.312, 44.264, 44.216, 44.165, 44.115, 44.062, 44.011, 43.958, 43.902, 43.849, 43.791, 43.74, 43.676, 43.619, 43.56, 43.489, 43.426, 43.37, 43.301, 43.233, 43.169, 43.098, 43.032, 42.962, 42.883]\n",
      "Train FP Error(all epochs): 0.0 \n",
      " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Val Error(all epochs): 45.13771438598633 \n",
      " [48.64, 48.655, 48.664, 48.67, 48.672, 48.67, 48.666, 48.66, 48.653, 48.646, 48.639, 48.632, 48.624, 48.616, 48.608, 48.6, 48.592, 48.583, 48.571, 48.559, 48.547, 48.533, 48.517, 48.499, 48.48, 48.461, 48.442, 48.423, 48.405, 48.386, 48.363, 48.338, 48.309, 48.282, 48.254, 48.226, 48.197, 48.166, 48.138, 48.115, 48.088, 48.057, 48.026, 47.998, 47.972, 47.95, 47.928, 47.895, 47.866, 47.845, 47.828, 47.808, 47.786, 47.76, 47.728, 47.697, 47.669, 47.636, 47.599, 47.572, 47.543, 47.485, 47.439, 47.392, 47.326, 47.272, 47.216, 47.157, 47.106, 47.049, 47.006, 46.946, 46.879, 46.819, 46.729, 46.653, 46.581, 46.494, 46.405, 46.305, 46.241, 46.17, 46.1, 46.072, 46.018, 46.014, 45.936, 45.919, 45.854, 45.758, 45.712, 45.679, 45.594, 45.508, 45.436, 45.352, 45.304, 45.275, 45.194, 45.138]\n",
      "Val FP Error(all epochs): 0.0 \n",
      " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_mae improved from inf to 48.70609, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00002: val_mae did not improve from 48.70609\n",
      "\n",
      "Epoch 00003: val_mae did not improve from 48.70609\n",
      "\n",
      "Epoch 00004: val_mae did not improve from 48.70609\n",
      "\n",
      "Epoch 00005: val_mae improved from 48.70609 to 48.70558, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00006: val_mae improved from 48.70558 to 48.69772, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00007: val_mae improved from 48.69772 to 48.68950, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00008: val_mae improved from 48.68950 to 48.68131, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00009: val_mae improved from 48.68131 to 48.67289, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00010: val_mae improved from 48.67289 to 48.66396, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00011: val_mae improved from 48.66396 to 48.65428, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00012: val_mae improved from 48.65428 to 48.64398, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00013: val_mae improved from 48.64398 to 48.63280, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00014: val_mae improved from 48.63280 to 48.62003, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00015: val_mae improved from 48.62003 to 48.60682, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00016: val_mae improved from 48.60682 to 48.59306, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00017: val_mae improved from 48.59306 to 48.57972, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00018: val_mae improved from 48.57972 to 48.56754, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00019: val_mae improved from 48.56754 to 48.55635, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00020: val_mae improved from 48.55635 to 48.54556, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00021: val_mae improved from 48.54556 to 48.53461, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00022: val_mae improved from 48.53461 to 48.52263, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00023: val_mae improved from 48.52263 to 48.50925, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00024: val_mae improved from 48.50925 to 48.49378, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00025: val_mae improved from 48.49378 to 48.47592, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00026: val_mae improved from 48.47592 to 48.45554, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00027: val_mae improved from 48.45554 to 48.43262, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00028: val_mae improved from 48.43262 to 48.40735, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00029: val_mae improved from 48.40735 to 48.38011, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00030: val_mae improved from 48.38011 to 48.35356, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00031: val_mae improved from 48.35356 to 48.32830, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00032: val_mae improved from 48.32830 to 48.30511, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00033: val_mae improved from 48.30511 to 48.28291, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00034: val_mae improved from 48.28291 to 48.26215, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00035: val_mae improved from 48.26215 to 48.24268, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00036: val_mae improved from 48.24268 to 48.22144, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00037: val_mae improved from 48.22144 to 48.19929, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00038: val_mae improved from 48.19929 to 48.17572, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00039: val_mae improved from 48.17572 to 48.15154, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00040: val_mae improved from 48.15154 to 48.12833, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00041: val_mae improved from 48.12833 to 48.10527, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00042: val_mae improved from 48.10527 to 48.07760, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00043: val_mae improved from 48.07760 to 48.04896, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_3.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00044: val_mae improved from 48.04896 to 48.01808, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00045: val_mae improved from 48.01808 to 47.98925, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00046: val_mae improved from 47.98925 to 47.96496, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00047: val_mae improved from 47.96496 to 47.94117, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00048: val_mae improved from 47.94117 to 47.90913, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00049: val_mae improved from 47.90913 to 47.88463, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00050: val_mae improved from 47.88463 to 47.85978, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00051: val_mae improved from 47.85978 to 47.83588, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00052: val_mae improved from 47.83588 to 47.81191, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00053: val_mae improved from 47.81191 to 47.78046, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00054: val_mae improved from 47.78046 to 47.74657, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00055: val_mae improved from 47.74657 to 47.72303, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00056: val_mae improved from 47.72303 to 47.69735, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00057: val_mae improved from 47.69735 to 47.66230, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00058: val_mae improved from 47.66230 to 47.62193, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00059: val_mae improved from 47.62193 to 47.57115, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00060: val_mae improved from 47.57115 to 47.55458, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00061: val_mae improved from 47.55458 to 47.52073, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00062: val_mae improved from 47.52073 to 47.47414, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00063: val_mae improved from 47.47414 to 47.44808, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00064: val_mae improved from 47.44808 to 47.40573, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00065: val_mae improved from 47.40573 to 47.36028, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00066: val_mae improved from 47.36028 to 47.30221, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00067: val_mae improved from 47.30221 to 47.22832, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00068: val_mae improved from 47.22832 to 47.16826, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00069: val_mae improved from 47.16826 to 47.12348, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00070: val_mae improved from 47.12348 to 47.07725, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00071: val_mae improved from 47.07725 to 47.05042, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00072: val_mae improved from 47.05042 to 46.99368, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00073: val_mae improved from 46.99368 to 46.92827, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00074: val_mae improved from 46.92827 to 46.88448, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00075: val_mae improved from 46.88448 to 46.82449, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00076: val_mae improved from 46.82449 to 46.77230, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00077: val_mae improved from 46.77230 to 46.72079, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00078: val_mae improved from 46.72079 to 46.66812, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00079: val_mae improved from 46.66812 to 46.61158, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00080: val_mae improved from 46.61158 to 46.57036, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00081: val_mae improved from 46.57036 to 46.50680, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00082: val_mae improved from 46.50680 to 46.40296, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00083: val_mae improved from 46.40296 to 46.32848, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00084: val_mae improved from 46.32848 to 46.25151, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_3.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00085: val_mae improved from 46.25151 to 46.18552, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00086: val_mae improved from 46.18552 to 46.10498, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00087: val_mae improved from 46.10498 to 46.05798, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00088: val_mae improved from 46.05798 to 46.01403, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00089: val_mae improved from 46.01403 to 45.96597, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00090: val_mae improved from 45.96597 to 45.93129, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00091: val_mae improved from 45.93129 to 45.92617, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00092: val_mae improved from 45.92617 to 45.91998, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00093: val_mae improved from 45.91998 to 45.85968, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00094: val_mae improved from 45.85968 to 45.83826, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00095: val_mae improved from 45.83826 to 45.73873, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00096: val_mae improved from 45.73873 to 45.62863, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00097: val_mae improved from 45.62863 to 45.55849, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00098: val_mae improved from 45.55849 to 45.42539, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00099: val_mae improved from 45.42539 to 45.31557, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00100: val_mae improved from 45.31557 to 45.28029, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/90/best_model_lambda_3.h5\n",
      "\n",
      "Lambda: 1 , Time: 0:01:14\n",
      "Train Error(all epochs): 43.11773 \n",
      " [46.103, 46.046, 46.003, 45.969, 45.945, 45.926, 45.91, 45.895, 45.881, 45.869, 45.857, 45.846, 45.835, 45.824, 45.812, 45.8, 45.789, 45.777, 45.765, 45.753, 45.741, 45.728, 45.716, 45.704, 45.691, 45.679, 45.667, 45.654, 45.641, 45.626, 45.612, 45.597, 45.582, 45.566, 45.551, 45.536, 45.52, 45.504, 45.487, 45.47, 45.453, 45.435, 45.416, 45.397, 45.377, 45.358, 45.338, 45.317, 45.295, 45.27, 45.25, 45.227, 45.203, 45.177, 45.153, 45.127, 45.099, 45.073, 45.042, 45.021, 44.986, 44.957, 44.93, 44.896, 44.868, 44.839, 44.804, 44.767, 44.733, 44.698, 44.663, 44.615, 44.583, 44.542, 44.501, 44.457, 44.417, 44.383, 44.332, 44.282, 44.235, 44.192, 44.14, 44.083, 44.036, 43.973, 43.923, 43.863, 43.807, 43.752, 43.69, 43.639, 43.571, 43.535, 43.446, 43.381, 43.334, 43.253, 43.181, 43.118]\n",
      "Train FP Error(all epochs): 0.0 \n",
      " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Val Error(all epochs): 45.28028869628906 \n",
      " [48.706, 48.712, 48.714, 48.711, 48.706, 48.698, 48.689, 48.681, 48.673, 48.664, 48.654, 48.644, 48.633, 48.62, 48.607, 48.593, 48.58, 48.568, 48.556, 48.546, 48.535, 48.523, 48.509, 48.494, 48.476, 48.456, 48.433, 48.407, 48.38, 48.354, 48.328, 48.305, 48.283, 48.262, 48.243, 48.221, 48.199, 48.176, 48.152, 48.128, 48.105, 48.078, 48.049, 48.018, 47.989, 47.965, 47.941, 47.909, 47.885, 47.86, 47.836, 47.812, 47.78, 47.747, 47.723, 47.697, 47.662, 47.622, 47.571, 47.555, 47.521, 47.474, 47.448, 47.406, 47.36, 47.302, 47.228, 47.168, 47.123, 47.077, 47.05, 46.994, 46.928, 46.884, 46.824, 46.772, 46.721, 46.668, 46.612, 46.57, 46.507, 46.403, 46.328, 46.252, 46.186, 46.105, 46.058, 46.014, 45.966, 45.931, 45.926, 45.92, 45.86, 45.838, 45.739, 45.629, 45.558, 45.425, 45.316, 45.28]\n",
      "Val FP Error(all epochs): 0.0 \n",
      " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "Trainig set size: 90 , Time: 0:04:59 , best_lambda: 0.001 , min_  error: 43.304\n",
      "Test starts:  108 , ends:  298\n",
      "1/1 [==============================] - 1s 612ms/step\n",
      "average_error:  41.626 , fp_average_error:  0.0\n",
      "\n",
      "\n",
      "\n",
      "number_samples: 120 , New samples: 120\n",
      "Validation size: 24 , starts: 120 , ends: 143\n",
      "\n",
      "Epoch 00001: val_mae improved from inf to 44.34563, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00002: val_mae did not improve from 44.34563\n",
      "\n",
      "Epoch 00003: val_mae did not improve from 44.34563\n",
      "\n",
      "Epoch 00004: val_mae did not improve from 44.34563\n",
      "\n",
      "Epoch 00005: val_mae did not improve from 44.34563\n",
      "\n",
      "Epoch 00006: val_mae did not improve from 44.34563\n",
      "\n",
      "Epoch 00007: val_mae did not improve from 44.34563\n",
      "\n",
      "Epoch 00008: val_mae did not improve from 44.34563\n",
      "\n",
      "Epoch 00009: val_mae did not improve from 44.34563\n",
      "\n",
      "Epoch 00010: val_mae did not improve from 44.34563\n",
      "\n",
      "Epoch 00011: val_mae did not improve from 44.34563\n",
      "\n",
      "Epoch 00012: val_mae did not improve from 44.34563\n",
      "\n",
      "Epoch 00013: val_mae did not improve from 44.34563\n",
      "\n",
      "Epoch 00014: val_mae did not improve from 44.34563\n",
      "\n",
      "Epoch 00015: val_mae did not improve from 44.34563\n",
      "\n",
      "Epoch 00016: val_mae did not improve from 44.34563\n",
      "\n",
      "Epoch 00017: val_mae did not improve from 44.34563\n",
      "\n",
      "Epoch 00018: val_mae did not improve from 44.34563\n",
      "\n",
      "Epoch 00019: val_mae did not improve from 44.34563\n",
      "\n",
      "Epoch 00020: val_mae did not improve from 44.34563\n",
      "\n",
      "Epoch 00021: val_mae did not improve from 44.34563\n",
      "\n",
      "Epoch 00022: val_mae did not improve from 44.34563\n",
      "\n",
      "Epoch 00023: val_mae did not improve from 44.34563\n",
      "\n",
      "Epoch 00024: val_mae did not improve from 44.34563\n",
      "\n",
      "Epoch 00025: val_mae did not improve from 44.34563\n",
      "\n",
      "Epoch 00026: val_mae did not improve from 44.34563\n",
      "\n",
      "Epoch 00027: val_mae did not improve from 44.34563\n",
      "\n",
      "Epoch 00028: val_mae did not improve from 44.34563\n",
      "\n",
      "Epoch 00029: val_mae did not improve from 44.34563\n",
      "\n",
      "Epoch 00030: val_mae did not improve from 44.34563\n",
      "\n",
      "Epoch 00031: val_mae did not improve from 44.34563\n",
      "\n",
      "Epoch 00032: val_mae did not improve from 44.34563\n",
      "\n",
      "Epoch 00033: val_mae did not improve from 44.34563\n",
      "\n",
      "Epoch 00034: val_mae did not improve from 44.34563\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00035: val_mae did not improve from 44.34563\n",
      "\n",
      "Epoch 00036: val_mae did not improve from 44.34563\n",
      "\n",
      "Epoch 00037: val_mae did not improve from 44.34563\n",
      "\n",
      "Epoch 00038: val_mae did not improve from 44.34563\n",
      "\n",
      "Epoch 00039: val_mae did not improve from 44.34563\n",
      "\n",
      "Epoch 00040: val_mae improved from 44.34563 to 44.34542, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00041: val_mae improved from 44.34542 to 44.33828, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00042: val_mae improved from 44.33828 to 44.32483, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00043: val_mae improved from 44.32483 to 44.31905, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00044: val_mae improved from 44.31905 to 44.30067, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00045: val_mae improved from 44.30067 to 44.27404, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00046: val_mae did not improve from 44.27404\n",
      "\n",
      "Epoch 00047: val_mae improved from 44.27404 to 44.22548, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00048: val_mae did not improve from 44.22548\n",
      "\n",
      "Epoch 00049: val_mae improved from 44.22548 to 44.19924, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00050: val_mae improved from 44.19924 to 44.16078, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00051: val_mae did not improve from 44.16078\n",
      "\n",
      "Epoch 00052: val_mae improved from 44.16078 to 44.12173, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00053: val_mae improved from 44.12173 to 44.09703, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00054: val_mae improved from 44.09703 to 44.09574, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00055: val_mae improved from 44.09574 to 44.00724, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00056: val_mae did not improve from 44.00724\n",
      "\n",
      "Epoch 00057: val_mae improved from 44.00724 to 43.96351, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00058: val_mae improved from 43.96351 to 43.90064, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00059: val_mae did not improve from 43.90064\n",
      "\n",
      "Epoch 00060: val_mae improved from 43.90064 to 43.79896, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00061: val_mae did not improve from 43.79896\n",
      "\n",
      "Epoch 00062: val_mae improved from 43.79896 to 43.78444, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00063: val_mae improved from 43.78444 to 43.70082, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00064: val_mae did not improve from 43.70082\n",
      "\n",
      "Epoch 00065: val_mae improved from 43.70082 to 43.64100, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00066: val_mae did not improve from 43.64100\n",
      "\n",
      "Epoch 00067: val_mae improved from 43.64100 to 43.59053, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00068: val_mae improved from 43.59053 to 43.52753, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00069: val_mae did not improve from 43.52753\n",
      "\n",
      "Epoch 00070: val_mae improved from 43.52753 to 43.49382, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00071: val_mae improved from 43.49382 to 43.46275, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00072: val_mae improved from 43.46275 to 43.46170, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00073: val_mae improved from 43.46170 to 43.39656, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00074: val_mae improved from 43.39656 to 43.35404, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00075: val_mae improved from 43.35404 to 43.31884, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00076: val_mae improved from 43.31884 to 43.28290, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00077: val_mae improved from 43.28290 to 43.14977, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00078: val_mae did not improve from 43.14977\n",
      "\n",
      "Epoch 00079: val_mae improved from 43.14977 to 43.06950, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00080: val_mae improved from 43.06950 to 43.05843, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00081: val_mae improved from 43.05843 to 43.00950, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00082: val_mae improved from 43.00950 to 42.91078, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00083: val_mae did not improve from 42.91078\n",
      "\n",
      "Epoch 00084: val_mae improved from 42.91078 to 42.82718, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00085: val_mae improved from 42.82718 to 42.78639, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00086: val_mae did not improve from 42.78639\n",
      "\n",
      "Epoch 00087: val_mae improved from 42.78639 to 42.63594, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00088: val_mae did not improve from 42.63594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00089: val_mae improved from 42.63594 to 42.63269, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00090: val_mae improved from 42.63269 to 42.50632, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00091: val_mae did not improve from 42.50632\n",
      "\n",
      "Epoch 00092: val_mae improved from 42.50632 to 42.41885, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00093: val_mae improved from 42.41885 to 42.35178, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00094: val_mae improved from 42.35178 to 42.30304, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00095: val_mae improved from 42.30304 to 42.21292, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00096: val_mae did not improve from 42.21292\n",
      "\n",
      "Epoch 00097: val_mae improved from 42.21292 to 42.11900, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00098: val_mae improved from 42.11900 to 42.07605, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00099: val_mae improved from 42.07605 to 42.03928, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00100: val_mae improved from 42.03928 to 41.93248, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_0.h5\n",
      "\n",
      "Lambda: 0.001 , Time: 0:01:35\n",
      "Train Error(all epochs): 43.404125 \n",
      " [46.3, 46.269, 46.249, 46.232, 46.218, 46.206, 46.194, 46.183, 46.173, 46.162, 46.152, 46.14, 46.129, 46.118, 46.106, 46.095, 46.084, 46.073, 46.062, 46.051, 46.039, 46.027, 46.014, 46.002, 45.989, 45.976, 45.962, 45.948, 45.934, 45.919, 45.903, 45.888, 45.871, 45.855, 45.838, 45.821, 45.804, 45.786, 45.769, 45.75, 45.73, 45.71, 45.689, 45.668, 45.646, 45.623, 45.602, 45.576, 45.554, 45.528, 45.502, 45.48, 45.453, 45.426, 45.4, 45.37, 45.343, 45.313, 45.283, 45.256, 45.221, 45.19, 45.156, 45.122, 45.092, 45.054, 45.019, 44.984, 44.945, 44.91, 44.87, 44.833, 44.795, 44.755, 44.713, 44.67, 44.629, 44.583, 44.543, 44.492, 44.448, 44.405, 44.352, 44.307, 44.257, 44.206, 44.158, 44.102, 44.05, 43.998, 43.943, 43.888, 43.829, 43.773, 43.711, 43.651, 43.598, 43.534, 43.467, 43.404]\n",
      "Train FP Error(all epochs): 0.0 \n",
      " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Val Error(all epochs): 41.93247604370117 \n",
      " [44.346, 44.374, 44.394, 44.409, 44.422, 44.432, 44.441, 44.447, 44.451, 44.454, 44.459, 44.465, 44.47, 44.474, 44.476, 44.476, 44.478, 44.478, 44.476, 44.469, 44.46, 44.454, 44.453, 44.453, 44.446, 44.44, 44.442, 44.442, 44.434, 44.425, 44.421, 44.411, 44.401, 44.399, 44.395, 44.388, 44.383, 44.374, 44.359, 44.345, 44.338, 44.325, 44.319, 44.301, 44.274, 44.278, 44.225, 44.243, 44.199, 44.161, 44.183, 44.122, 44.097, 44.096, 44.007, 44.029, 43.964, 43.901, 43.916, 43.799, 43.816, 43.784, 43.701, 43.716, 43.641, 43.651, 43.591, 43.528, 43.582, 43.494, 43.463, 43.462, 43.397, 43.354, 43.319, 43.283, 43.15, 43.219, 43.07, 43.058, 43.01, 42.911, 42.969, 42.827, 42.786, 42.818, 42.636, 42.676, 42.633, 42.506, 42.539, 42.419, 42.352, 42.303, 42.213, 42.215, 42.119, 42.076, 42.039, 41.932]\n",
      "Val FP Error(all epochs): 0.0 \n",
      " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "Epoch 00001: val_mae improved from inf to 44.33433, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00002: val_mae did not improve from 44.33433\n",
      "\n",
      "Epoch 00003: val_mae did not improve from 44.33433\n",
      "\n",
      "Epoch 00004: val_mae did not improve from 44.33433\n",
      "\n",
      "Epoch 00005: val_mae did not improve from 44.33433\n",
      "\n",
      "Epoch 00006: val_mae did not improve from 44.33433\n",
      "\n",
      "Epoch 00007: val_mae did not improve from 44.33433\n",
      "\n",
      "Epoch 00008: val_mae did not improve from 44.33433\n",
      "\n",
      "Epoch 00009: val_mae did not improve from 44.33433\n",
      "\n",
      "Epoch 00010: val_mae did not improve from 44.33433\n",
      "\n",
      "Epoch 00011: val_mae did not improve from 44.33433\n",
      "\n",
      "Epoch 00012: val_mae did not improve from 44.33433\n",
      "\n",
      "Epoch 00013: val_mae did not improve from 44.33433\n",
      "\n",
      "Epoch 00014: val_mae did not improve from 44.33433\n",
      "\n",
      "Epoch 00015: val_mae did not improve from 44.33433\n",
      "\n",
      "Epoch 00016: val_mae did not improve from 44.33433\n",
      "\n",
      "Epoch 00017: val_mae did not improve from 44.33433\n",
      "\n",
      "Epoch 00018: val_mae did not improve from 44.33433\n",
      "\n",
      "Epoch 00019: val_mae did not improve from 44.33433\n",
      "\n",
      "Epoch 00020: val_mae did not improve from 44.33433\n",
      "\n",
      "Epoch 00021: val_mae did not improve from 44.33433\n",
      "\n",
      "Epoch 00022: val_mae did not improve from 44.33433\n",
      "\n",
      "Epoch 00023: val_mae did not improve from 44.33433\n",
      "\n",
      "Epoch 00024: val_mae did not improve from 44.33433\n",
      "\n",
      "Epoch 00025: val_mae did not improve from 44.33433\n",
      "\n",
      "Epoch 00026: val_mae did not improve from 44.33433\n",
      "\n",
      "Epoch 00027: val_mae improved from 44.33433 to 44.32743, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00028: val_mae improved from 44.32743 to 44.31675, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00029: val_mae improved from 44.31675 to 44.30799, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00030: val_mae improved from 44.30799 to 44.29864, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00031: val_mae improved from 44.29864 to 44.28888, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00032: val_mae improved from 44.28888 to 44.27824, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00033: val_mae improved from 44.27824 to 44.26772, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00034: val_mae improved from 44.26772 to 44.25606, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00035: val_mae improved from 44.25606 to 44.24368, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_1.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00036: val_mae improved from 44.24368 to 44.23320, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00037: val_mae improved from 44.23320 to 44.22413, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00038: val_mae improved from 44.22413 to 44.21297, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00039: val_mae improved from 44.21297 to 44.19785, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00040: val_mae improved from 44.19785 to 44.17887, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00041: val_mae improved from 44.17887 to 44.16190, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00042: val_mae improved from 44.16190 to 44.14241, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00043: val_mae improved from 44.14241 to 44.12634, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00044: val_mae improved from 44.12634 to 44.09831, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00045: val_mae improved from 44.09831 to 44.06609, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00046: val_mae improved from 44.06609 to 44.05367, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00047: val_mae improved from 44.05367 to 44.03789, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00048: val_mae improved from 44.03789 to 44.01332, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00049: val_mae improved from 44.01332 to 43.98906, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00050: val_mae improved from 43.98906 to 43.95735, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00051: val_mae improved from 43.95735 to 43.92186, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00052: val_mae improved from 43.92186 to 43.88639, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00053: val_mae improved from 43.88639 to 43.85845, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00054: val_mae improved from 43.85845 to 43.83528, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00055: val_mae improved from 43.83528 to 43.80934, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00056: val_mae improved from 43.80934 to 43.76081, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00057: val_mae improved from 43.76081 to 43.72867, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00058: val_mae improved from 43.72867 to 43.70842, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00059: val_mae improved from 43.70842 to 43.68052, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00060: val_mae improved from 43.68052 to 43.66600, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00061: val_mae improved from 43.66600 to 43.62710, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00062: val_mae improved from 43.62710 to 43.56256, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00063: val_mae did not improve from 43.56256\n",
      "\n",
      "Epoch 00064: val_mae improved from 43.56256 to 43.53431, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00065: val_mae improved from 43.53431 to 43.48928, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00066: val_mae improved from 43.48928 to 43.46316, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00067: val_mae improved from 43.46316 to 43.42999, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00068: val_mae improved from 43.42999 to 43.39678, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00069: val_mae improved from 43.39678 to 43.38177, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00070: val_mae improved from 43.38177 to 43.31351, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00071: val_mae improved from 43.31351 to 43.24449, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00072: val_mae improved from 43.24449 to 43.19406, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00073: val_mae improved from 43.19406 to 43.15724, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00074: val_mae improved from 43.15724 to 43.08060, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00075: val_mae improved from 43.08060 to 42.99547, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00076: val_mae improved from 42.99547 to 42.94136, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00077: val_mae improved from 42.94136 to 42.85079, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_1.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00078: val_mae improved from 42.85079 to 42.78389, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00079: val_mae improved from 42.78389 to 42.73237, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00080: val_mae improved from 42.73237 to 42.69252, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00081: val_mae improved from 42.69252 to 42.59681, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00082: val_mae improved from 42.59681 to 42.55846, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00083: val_mae improved from 42.55846 to 42.46642, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00084: val_mae improved from 42.46642 to 42.45379, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00085: val_mae improved from 42.45379 to 42.27309, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00086: val_mae did not improve from 42.27309\n",
      "\n",
      "Epoch 00087: val_mae improved from 42.27309 to 42.18957, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00088: val_mae improved from 42.18957 to 42.09020, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00089: val_mae did not improve from 42.09020\n",
      "\n",
      "Epoch 00090: val_mae improved from 42.09020 to 42.04757, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00091: val_mae improved from 42.04757 to 41.96523, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00092: val_mae did not improve from 41.96523\n",
      "\n",
      "Epoch 00093: val_mae did not improve from 41.96523\n",
      "\n",
      "Epoch 00094: val_mae improved from 41.96523 to 41.87224, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00095: val_mae did not improve from 41.87224\n",
      "\n",
      "Epoch 00096: val_mae improved from 41.87224 to 41.83821, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00097: val_mae improved from 41.83821 to 41.70785, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00098: val_mae improved from 41.70785 to 41.70284, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00099: val_mae improved from 41.70284 to 41.65889, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00100: val_mae improved from 41.65889 to 41.56253, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_1.h5\n",
      "\n",
      "Lambda: 0.01 , Time: 0:01:34\n",
      "Train Error(all epochs): 42.726334 \n",
      " [46.285, 46.221, 46.177, 46.147, 46.124, 46.105, 46.089, 46.074, 46.06, 46.047, 46.035, 46.022, 46.009, 45.996, 45.983, 45.971, 45.958, 45.945, 45.932, 45.918, 45.904, 45.89, 45.875, 45.861, 45.846, 45.83, 45.814, 45.798, 45.781, 45.764, 45.746, 45.728, 45.709, 45.689, 45.67, 45.651, 45.632, 45.612, 45.591, 45.569, 45.547, 45.525, 45.501, 45.478, 45.454, 45.43, 45.406, 45.379, 45.352, 45.324, 45.296, 45.267, 45.237, 45.206, 45.174, 45.141, 45.107, 45.073, 45.036, 45.001, 44.967, 44.932, 44.894, 44.856, 44.816, 44.775, 44.732, 44.691, 44.647, 44.602, 44.554, 44.505, 44.455, 44.406, 44.355, 44.301, 44.246, 44.187, 44.134, 44.078, 44.021, 43.962, 43.903, 43.843, 43.786, 43.724, 43.658, 43.588, 43.525, 43.454, 43.382, 43.319, 43.252, 43.173, 43.103, 43.038, 42.956, 42.88, 42.805, 42.726]\n",
      "Train FP Error(all epochs): 0.0 \n",
      " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Val Error(all epochs): 41.56253433227539 \n",
      " [44.334, 44.356, 44.376, 44.389, 44.399, 44.406, 44.41, 44.412, 44.413, 44.412, 44.411, 44.409, 44.409, 44.408, 44.406, 44.403, 44.399, 44.394, 44.389, 44.383, 44.377, 44.371, 44.365, 44.358, 44.349, 44.338, 44.327, 44.317, 44.308, 44.299, 44.289, 44.278, 44.268, 44.256, 44.244, 44.233, 44.224, 44.213, 44.198, 44.179, 44.162, 44.142, 44.126, 44.098, 44.066, 44.054, 44.038, 44.013, 43.989, 43.957, 43.922, 43.886, 43.858, 43.835, 43.809, 43.761, 43.729, 43.708, 43.681, 43.666, 43.627, 43.563, 43.566, 43.534, 43.489, 43.463, 43.43, 43.397, 43.382, 43.314, 43.244, 43.194, 43.157, 43.081, 42.995, 42.941, 42.851, 42.784, 42.732, 42.693, 42.597, 42.558, 42.466, 42.454, 42.273, 42.319, 42.19, 42.09, 42.165, 42.048, 41.965, 42.077, 41.994, 41.872, 41.891, 41.838, 41.708, 41.703, 41.659, 41.563]\n",
      "Val FP Error(all epochs): 0.0 \n",
      " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "Epoch 00001: val_mae improved from inf to 44.30039, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00002: val_mae did not improve from 44.30039\n",
      "\n",
      "Epoch 00003: val_mae did not improve from 44.30039\n",
      "\n",
      "Epoch 00004: val_mae did not improve from 44.30039\n",
      "\n",
      "Epoch 00005: val_mae did not improve from 44.30039\n",
      "\n",
      "Epoch 00006: val_mae improved from 44.30039 to 44.28752, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00007: val_mae improved from 44.28752 to 44.27514, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00008: val_mae improved from 44.27514 to 44.26551, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00009: val_mae improved from 44.26551 to 44.25975, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00010: val_mae improved from 44.25975 to 44.25604, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00011: val_mae improved from 44.25604 to 44.25106, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_2.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00012: val_mae improved from 44.25106 to 44.24416, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00013: val_mae improved from 44.24416 to 44.23516, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00014: val_mae improved from 44.23516 to 44.22688, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00015: val_mae improved from 44.22688 to 44.22124, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00016: val_mae improved from 44.22124 to 44.21861, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00017: val_mae did not improve from 44.21861\n",
      "\n",
      "Epoch 00018: val_mae did not improve from 44.21861\n",
      "\n",
      "Epoch 00019: val_mae improved from 44.21861 to 44.21344, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00020: val_mae improved from 44.21344 to 44.19983, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00021: val_mae improved from 44.19983 to 44.17975, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00022: val_mae improved from 44.17975 to 44.16200, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00023: val_mae improved from 44.16200 to 44.15181, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00024: val_mae improved from 44.15181 to 44.14964, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00025: val_mae did not improve from 44.14964\n",
      "\n",
      "Epoch 00026: val_mae improved from 44.14964 to 44.14738, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00027: val_mae improved from 44.14738 to 44.12843, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00028: val_mae improved from 44.12843 to 44.10556, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00029: val_mae improved from 44.10556 to 44.09201, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00030: val_mae improved from 44.09201 to 44.08745, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00031: val_mae improved from 44.08745 to 44.07706, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00032: val_mae improved from 44.07706 to 44.04869, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00033: val_mae improved from 44.04869 to 44.00360, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00034: val_mae improved from 44.00360 to 43.95911, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00035: val_mae improved from 43.95911 to 43.92785, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00036: val_mae improved from 43.92785 to 43.90703, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00037: val_mae improved from 43.90703 to 43.87512, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00038: val_mae improved from 43.87512 to 43.83452, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00039: val_mae improved from 43.83452 to 43.79853, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00040: val_mae improved from 43.79853 to 43.77089, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00041: val_mae improved from 43.77089 to 43.73234, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00042: val_mae improved from 43.73234 to 43.68486, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00043: val_mae improved from 43.68486 to 43.64801, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00044: val_mae improved from 43.64801 to 43.62079, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00045: val_mae improved from 43.62079 to 43.58723, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00046: val_mae improved from 43.58723 to 43.54559, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00047: val_mae improved from 43.54559 to 43.51218, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00048: val_mae improved from 43.51218 to 43.48422, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00049: val_mae improved from 43.48422 to 43.44011, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00050: val_mae improved from 43.44011 to 43.38967, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00051: val_mae improved from 43.38967 to 43.36717, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00052: val_mae improved from 43.36717 to 43.33997, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00053: val_mae improved from 43.33997 to 43.30173, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00054: val_mae improved from 43.30173 to 43.26796, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_2.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00055: val_mae improved from 43.26796 to 43.24097, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00056: val_mae improved from 43.24097 to 43.18391, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00057: val_mae improved from 43.18391 to 43.16809, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00058: val_mae improved from 43.16809 to 43.13317, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00059: val_mae improved from 43.13317 to 43.09226, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00060: val_mae improved from 43.09226 to 43.05258, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00061: val_mae improved from 43.05258 to 42.97734, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00062: val_mae improved from 42.97734 to 42.95572, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00063: val_mae improved from 42.95572 to 42.84630, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00064: val_mae did not improve from 42.84630\n",
      "\n",
      "Epoch 00065: val_mae improved from 42.84630 to 42.66846, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00066: val_mae did not improve from 42.66846\n",
      "\n",
      "Epoch 00067: val_mae improved from 42.66846 to 42.60999, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00068: val_mae improved from 42.60999 to 42.47135, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00069: val_mae did not improve from 42.47135\n",
      "\n",
      "Epoch 00070: val_mae improved from 42.47135 to 42.44306, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00071: val_mae improved from 42.44306 to 42.24713, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00072: val_mae improved from 42.24713 to 42.23742, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00073: val_mae improved from 42.23742 to 42.13327, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00074: val_mae improved from 42.13327 to 41.98793, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00075: val_mae did not improve from 41.98793\n",
      "\n",
      "Epoch 00076: val_mae improved from 41.98793 to 41.94206, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00077: val_mae improved from 41.94206 to 41.76428, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00078: val_mae improved from 41.76428 to 41.75197, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00079: val_mae improved from 41.75197 to 41.69431, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00080: val_mae improved from 41.69431 to 41.66017, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00081: val_mae improved from 41.66017 to 41.62281, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00082: val_mae improved from 41.62281 to 41.44373, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00083: val_mae did not improve from 41.44373\n",
      "\n",
      "Epoch 00084: val_mae improved from 41.44373 to 41.37617, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00085: val_mae improved from 41.37617 to 41.34747, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00086: val_mae improved from 41.34747 to 41.33556, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00087: val_mae improved from 41.33556 to 41.22997, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00088: val_mae improved from 41.22997 to 41.21638, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00089: val_mae improved from 41.21638 to 41.13485, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00090: val_mae did not improve from 41.13485\n",
      "\n",
      "Epoch 00091: val_mae improved from 41.13485 to 40.86139, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00092: val_mae did not improve from 40.86139\n",
      "\n",
      "Epoch 00093: val_mae improved from 40.86139 to 40.74416, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00094: val_mae improved from 40.74416 to 40.73198, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00095: val_mae did not improve from 40.73198\n",
      "\n",
      "Epoch 00096: val_mae improved from 40.73198 to 40.60190, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00097: val_mae improved from 40.60190 to 40.50460, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00098: val_mae did not improve from 40.50460\n",
      "\n",
      "Epoch 00099: val_mae improved from 40.50460 to 40.40784, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00100: val_mae improved from 40.40784 to 40.24306, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_2.h5\n",
      "\n",
      "Lambda: 0.1 , Time: 0:01:35\n",
      "Train Error(all epochs): 42.694458 \n",
      " [46.286, 46.187, 46.102, 46.038, 45.99, 45.956, 45.93, 45.91, 45.892, 45.876, 45.861, 45.846, 45.832, 45.817, 45.803, 45.788, 45.773, 45.758, 45.743, 45.727, 45.712, 45.695, 45.679, 45.662, 45.644, 45.626, 45.608, 45.589, 45.569, 45.55, 45.53, 45.51, 45.489, 45.468, 45.446, 45.424, 45.402, 45.379, 45.356, 45.331, 45.307, 45.282, 45.256, 45.231, 45.205, 45.179, 45.153, 45.126, 45.099, 45.071, 45.043, 45.015, 44.985, 44.955, 44.924, 44.891, 44.858, 44.825, 44.79, 44.756, 44.72, 44.685, 44.65, 44.612, 44.575, 44.54, 44.499, 44.457, 44.419, 44.375, 44.336, 44.299, 44.253, 44.207, 44.163, 44.114, 44.066, 44.02, 43.97, 43.919, 43.87, 43.813, 43.755, 43.702, 43.645, 43.587, 43.531, 43.47, 43.409, 43.351, 43.29, 43.234, 43.17, 43.103, 43.035, 42.972, 42.902, 42.837, 42.769, 42.694]\n",
      "Train FP Error(all epochs): 0.0 \n",
      " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Val Error(all epochs): 40.24306106567383 \n",
      " [44.3, 44.311, 44.315, 44.31, 44.301, 44.288, 44.275, 44.266, 44.26, 44.256, 44.251, 44.244, 44.235, 44.227, 44.221, 44.219, 44.219, 44.219, 44.213, 44.2, 44.18, 44.162, 44.152, 44.15, 44.154, 44.147, 44.128, 44.106, 44.092, 44.087, 44.077, 44.049, 44.004, 43.959, 43.928, 43.907, 43.875, 43.835, 43.799, 43.771, 43.732, 43.685, 43.648, 43.621, 43.587, 43.546, 43.512, 43.484, 43.44, 43.39, 43.367, 43.34, 43.302, 43.268, 43.241, 43.184, 43.168, 43.133, 43.092, 43.053, 42.977, 42.956, 42.846, 42.879, 42.668, 42.748, 42.61, 42.471, 42.513, 42.443, 42.247, 42.237, 42.133, 41.988, 42.006, 41.942, 41.764, 41.752, 41.694, 41.66, 41.623, 41.444, 41.453, 41.376, 41.347, 41.336, 41.23, 41.216, 41.135, 41.197, 40.861, 41.173, 40.744, 40.732, 40.895, 40.602, 40.505, 40.62, 40.408, 40.243]\n",
      "Val FP Error(all epochs): 0.0 \n",
      " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_mae improved from inf to 44.34179, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00002: val_mae did not improve from 44.34179\n",
      "\n",
      "Epoch 00003: val_mae did not improve from 44.34179\n",
      "\n",
      "Epoch 00004: val_mae did not improve from 44.34179\n",
      "\n",
      "Epoch 00005: val_mae did not improve from 44.34179\n",
      "\n",
      "Epoch 00006: val_mae did not improve from 44.34179\n",
      "\n",
      "Epoch 00007: val_mae did not improve from 44.34179\n",
      "\n",
      "Epoch 00008: val_mae did not improve from 44.34179\n",
      "\n",
      "Epoch 00009: val_mae improved from 44.34179 to 44.33949, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00010: val_mae improved from 44.33949 to 44.33149, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00011: val_mae improved from 44.33149 to 44.32298, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00012: val_mae improved from 44.32298 to 44.31370, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00013: val_mae improved from 44.31370 to 44.30352, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00014: val_mae improved from 44.30352 to 44.29214, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00015: val_mae improved from 44.29214 to 44.27929, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00016: val_mae improved from 44.27929 to 44.26486, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00017: val_mae improved from 44.26486 to 44.24834, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00018: val_mae improved from 44.24834 to 44.23030, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00019: val_mae improved from 44.23030 to 44.21093, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00020: val_mae improved from 44.21093 to 44.19115, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00021: val_mae improved from 44.19115 to 44.17101, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00022: val_mae improved from 44.17101 to 44.15007, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00023: val_mae improved from 44.15007 to 44.12853, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00024: val_mae improved from 44.12853 to 44.10659, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00025: val_mae improved from 44.10659 to 44.08545, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00026: val_mae improved from 44.08545 to 44.06435, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00027: val_mae improved from 44.06435 to 44.04213, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00028: val_mae improved from 44.04213 to 44.01741, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00029: val_mae improved from 44.01741 to 43.99112, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00030: val_mae improved from 43.99112 to 43.96524, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00031: val_mae improved from 43.96524 to 43.94051, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00032: val_mae improved from 43.94051 to 43.91611, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00033: val_mae improved from 43.91611 to 43.89188, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00034: val_mae improved from 43.89188 to 43.86894, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00035: val_mae improved from 43.86894 to 43.84642, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00036: val_mae improved from 43.84642 to 43.82402, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00037: val_mae improved from 43.82402 to 43.79974, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00038: val_mae improved from 43.79974 to 43.77458, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00039: val_mae improved from 43.77458 to 43.75073, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00040: val_mae improved from 43.75073 to 43.72624, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00041: val_mae improved from 43.72624 to 43.70028, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00042: val_mae improved from 43.70028 to 43.67634, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00043: val_mae improved from 43.67634 to 43.65572, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00044: val_mae improved from 43.65572 to 43.63919, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00045: val_mae improved from 43.63919 to 43.61420, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00046: val_mae improved from 43.61420 to 43.58879, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_3.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00047: val_mae improved from 43.58879 to 43.56083, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00048: val_mae improved from 43.56083 to 43.53531, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00049: val_mae improved from 43.53531 to 43.49974, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00050: val_mae improved from 43.49974 to 43.46686, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00051: val_mae improved from 43.46686 to 43.44438, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00052: val_mae improved from 43.44438 to 43.41724, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00053: val_mae improved from 43.41724 to 43.39230, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00054: val_mae improved from 43.39230 to 43.36139, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00055: val_mae improved from 43.36139 to 43.33362, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00056: val_mae improved from 43.33362 to 43.29788, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00057: val_mae improved from 43.29788 to 43.25515, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00058: val_mae improved from 43.25515 to 43.21808, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00059: val_mae improved from 43.21808 to 43.18634, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00060: val_mae improved from 43.18634 to 43.15522, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00061: val_mae improved from 43.15522 to 43.12020, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00062: val_mae improved from 43.12020 to 43.08110, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00063: val_mae improved from 43.08110 to 43.03846, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00064: val_mae improved from 43.03846 to 43.00611, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00065: val_mae improved from 43.00611 to 42.95958, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00066: val_mae improved from 42.95958 to 42.91489, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00067: val_mae improved from 42.91489 to 42.87964, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00068: val_mae improved from 42.87964 to 42.81481, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00069: val_mae improved from 42.81481 to 42.76377, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00070: val_mae improved from 42.76377 to 42.70259, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00071: val_mae improved from 42.70259 to 42.66400, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00072: val_mae improved from 42.66400 to 42.57684, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00073: val_mae improved from 42.57684 to 42.49217, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00074: val_mae improved from 42.49217 to 42.42318, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00075: val_mae improved from 42.42318 to 42.34237, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00076: val_mae improved from 42.34237 to 42.26575, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00077: val_mae improved from 42.26575 to 42.19911, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00078: val_mae improved from 42.19911 to 42.11724, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00079: val_mae improved from 42.11724 to 42.03749, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00080: val_mae improved from 42.03749 to 41.98154, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00081: val_mae improved from 41.98154 to 41.91800, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00082: val_mae improved from 41.91800 to 41.82028, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00083: val_mae improved from 41.82028 to 41.73746, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00084: val_mae improved from 41.73746 to 41.67495, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00085: val_mae improved from 41.67495 to 41.61654, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00086: val_mae improved from 41.61654 to 41.53186, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00087: val_mae improved from 41.53186 to 41.46128, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_3.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00088: val_mae improved from 41.46128 to 41.39981, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00089: val_mae improved from 41.39981 to 41.33532, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00090: val_mae improved from 41.33532 to 41.23357, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00091: val_mae improved from 41.23357 to 41.18879, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00092: val_mae improved from 41.18879 to 41.13854, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00093: val_mae improved from 41.13854 to 41.10004, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00094: val_mae improved from 41.10004 to 41.07047, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00095: val_mae did not improve from 41.07047\n",
      "\n",
      "Epoch 00096: val_mae improved from 41.07047 to 40.98230, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00097: val_mae improved from 40.98230 to 40.92442, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00098: val_mae improved from 40.92442 to 40.85785, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00099: val_mae improved from 40.85785 to 40.77616, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00100: val_mae improved from 40.77616 to 40.72250, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/120/best_model_lambda_3.h5\n",
      "\n",
      "Lambda: 1 , Time: 0:01:37\n",
      "Train Error(all epochs): 43.339764 \n",
      " [46.31, 46.264, 46.236, 46.213, 46.196, 46.18, 46.165, 46.152, 46.141, 46.129, 46.117, 46.106, 46.095, 46.084, 46.073, 46.061, 46.05, 46.039, 46.028, 46.017, 46.005, 45.993, 45.982, 45.97, 45.957, 45.945, 45.932, 45.92, 45.906, 45.891, 45.876, 45.861, 45.846, 45.83, 45.814, 45.797, 45.779, 45.761, 45.744, 45.726, 45.707, 45.687, 45.664, 45.643, 45.62, 45.599, 45.575, 45.557, 45.529, 45.508, 45.482, 45.455, 45.431, 45.407, 45.384, 45.351, 45.335, 45.294, 45.267, 45.245, 45.208, 45.177, 45.148, 45.112, 45.081, 45.045, 45.005, 44.972, 44.934, 44.893, 44.867, 44.828, 44.772, 44.749, 44.703, 44.652, 44.613, 44.562, 44.518, 44.476, 44.433, 44.377, 44.328, 44.27, 44.229, 44.173, 44.116, 44.059, 44.014, 43.948, 43.891, 43.83, 43.78, 43.706, 43.654, 43.576, 43.535, 43.441, 43.38, 43.34]\n",
      "Train FP Error(all epochs): 0.0 \n",
      " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Val Error(all epochs): 40.722503662109375 \n",
      " [44.342, 44.357, 44.364, 44.366, 44.363, 44.358, 44.353, 44.347, 44.339, 44.331, 44.323, 44.314, 44.304, 44.292, 44.279, 44.265, 44.248, 44.23, 44.211, 44.191, 44.171, 44.15, 44.129, 44.107, 44.085, 44.064, 44.042, 44.017, 43.991, 43.965, 43.941, 43.916, 43.892, 43.869, 43.846, 43.824, 43.8, 43.775, 43.751, 43.726, 43.7, 43.676, 43.656, 43.639, 43.614, 43.589, 43.561, 43.535, 43.5, 43.467, 43.444, 43.417, 43.392, 43.361, 43.334, 43.298, 43.255, 43.218, 43.186, 43.155, 43.12, 43.081, 43.038, 43.006, 42.96, 42.915, 42.88, 42.815, 42.764, 42.703, 42.664, 42.577, 42.492, 42.423, 42.342, 42.266, 42.199, 42.117, 42.037, 41.982, 41.918, 41.82, 41.737, 41.675, 41.617, 41.532, 41.461, 41.4, 41.335, 41.234, 41.189, 41.139, 41.1, 41.07, 41.075, 40.982, 40.924, 40.858, 40.776, 40.723]\n",
      "Val FP Error(all epochs): 0.0 \n",
      " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "Trainig set size: 120 , Time: 0:06:23 , best_lambda: 0.1 , min_  error: 40.243\n",
      "Test starts:  144 , ends:  298\n",
      "1/1 [==============================] - 1s 532ms/step\n",
      "average_error:  43.522 , fp_average_error:  0.0\n",
      "\n",
      "\n",
      "\n",
      "number_samples: 150 , New samples: 150\n",
      "Validation size: 30 , starts: 150 , ends: 179\n",
      "\n",
      "Epoch 00001: val_mae improved from inf to 49.07766, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00002: val_mae did not improve from 49.07766\n",
      "\n",
      "Epoch 00003: val_mae did not improve from 49.07766\n",
      "\n",
      "Epoch 00004: val_mae did not improve from 49.07766\n",
      "\n",
      "Epoch 00005: val_mae did not improve from 49.07766\n",
      "\n",
      "Epoch 00006: val_mae did not improve from 49.07766\n",
      "\n",
      "Epoch 00007: val_mae did not improve from 49.07766\n",
      "\n",
      "Epoch 00008: val_mae did not improve from 49.07766\n",
      "\n",
      "Epoch 00009: val_mae did not improve from 49.07766\n",
      "\n",
      "Epoch 00010: val_mae improved from 49.07766 to 49.07374, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00011: val_mae improved from 49.07374 to 49.05884, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00012: val_mae improved from 49.05884 to 49.04156, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00013: val_mae improved from 49.04156 to 49.02223, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00014: val_mae improved from 49.02223 to 48.99969, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00015: val_mae improved from 48.99969 to 48.97538, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00016: val_mae improved from 48.97538 to 48.94938, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00017: val_mae improved from 48.94938 to 48.92317, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00018: val_mae improved from 48.92317 to 48.89811, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00019: val_mae improved from 48.89811 to 48.87395, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00020: val_mae improved from 48.87395 to 48.84942, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_0.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00021: val_mae improved from 48.84942 to 48.82231, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00022: val_mae improved from 48.82231 to 48.79167, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00023: val_mae improved from 48.79167 to 48.75811, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00024: val_mae improved from 48.75811 to 48.72309, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00025: val_mae improved from 48.72309 to 48.68811, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00026: val_mae improved from 48.68811 to 48.65310, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00027: val_mae improved from 48.65310 to 48.61935, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00028: val_mae improved from 48.61935 to 48.58220, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00029: val_mae improved from 48.58220 to 48.54338, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00030: val_mae improved from 48.54338 to 48.50901, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00031: val_mae improved from 48.50901 to 48.47644, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00032: val_mae improved from 48.47644 to 48.44066, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00033: val_mae improved from 48.44066 to 48.40208, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00034: val_mae improved from 48.40208 to 48.35966, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00035: val_mae improved from 48.35966 to 48.31428, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00036: val_mae improved from 48.31428 to 48.26261, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00037: val_mae improved from 48.26261 to 48.21125, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00038: val_mae improved from 48.21125 to 48.15850, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00039: val_mae improved from 48.15850 to 48.10273, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00040: val_mae improved from 48.10273 to 48.04812, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00041: val_mae improved from 48.04812 to 47.98384, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00042: val_mae improved from 47.98384 to 47.92208, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00043: val_mae improved from 47.92208 to 47.86128, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00044: val_mae improved from 47.86128 to 47.80289, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00045: val_mae improved from 47.80289 to 47.75779, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00046: val_mae improved from 47.75779 to 47.72076, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00047: val_mae improved from 47.72076 to 47.67131, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00048: val_mae improved from 47.67131 to 47.63586, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00049: val_mae improved from 47.63586 to 47.59825, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00050: val_mae improved from 47.59825 to 47.58254, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00051: val_mae improved from 47.58254 to 47.56111, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00052: val_mae improved from 47.56111 to 47.53188, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00053: val_mae improved from 47.53188 to 47.50519, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00054: val_mae improved from 47.50519 to 47.46149, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00055: val_mae improved from 47.46149 to 47.43983, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00056: val_mae improved from 47.43983 to 47.39862, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00057: val_mae improved from 47.39862 to 47.39626, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00058: val_mae improved from 47.39626 to 47.31054, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00059: val_mae did not improve from 47.31054\n",
      "\n",
      "Epoch 00060: val_mae improved from 47.31054 to 47.30700, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00061: val_mae improved from 47.30700 to 47.27886, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00062: val_mae did not improve from 47.27886\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00063: val_mae did not improve from 47.27886\n",
      "\n",
      "Epoch 00064: val_mae did not improve from 47.27886\n",
      "\n",
      "Epoch 00065: val_mae did not improve from 47.27886\n",
      "\n",
      "Epoch 00066: val_mae did not improve from 47.27886\n",
      "\n",
      "Epoch 00067: val_mae did not improve from 47.27886\n",
      "\n",
      "Epoch 00068: val_mae did not improve from 47.27886\n",
      "\n",
      "Epoch 00069: val_mae did not improve from 47.27886\n",
      "\n",
      "Epoch 00070: val_mae did not improve from 47.27886\n",
      "\n",
      "Epoch 00071: val_mae did not improve from 47.27886\n",
      "\n",
      "Epoch 00072: val_mae did not improve from 47.27886\n",
      "\n",
      "Epoch 00073: val_mae did not improve from 47.27886\n",
      "\n",
      "Epoch 00074: val_mae did not improve from 47.27886\n",
      "\n",
      "Epoch 00075: val_mae did not improve from 47.27886\n",
      "\n",
      "Epoch 00076: val_mae did not improve from 47.27886\n",
      "\n",
      "Epoch 00077: val_mae did not improve from 47.27886\n",
      "\n",
      "Epoch 00078: val_mae did not improve from 47.27886\n",
      "\n",
      "Epoch 00079: val_mae did not improve from 47.27886\n",
      "\n",
      "Epoch 00080: val_mae did not improve from 47.27886\n",
      "\n",
      "Epoch 00081: val_mae did not improve from 47.27886\n",
      "\n",
      "Epoch 00082: val_mae did not improve from 47.27886\n",
      "\n",
      "Epoch 00083: val_mae did not improve from 47.27886\n",
      "\n",
      "Epoch 00084: val_mae did not improve from 47.27886\n",
      "\n",
      "Epoch 00085: val_mae did not improve from 47.27886\n",
      "\n",
      "Epoch 00086: val_mae did not improve from 47.27886\n",
      "\n",
      "Epoch 00087: val_mae did not improve from 47.27886\n",
      "\n",
      "Epoch 00088: val_mae did not improve from 47.27886\n",
      "\n",
      "Epoch 00089: val_mae did not improve from 47.27886\n",
      "\n",
      "Epoch 00090: val_mae did not improve from 47.27886\n",
      "\n",
      "Epoch 00091: val_mae did not improve from 47.27886\n",
      "\n",
      "Epoch 00092: val_mae did not improve from 47.27886\n",
      "\n",
      "Epoch 00093: val_mae did not improve from 47.27886\n",
      "\n",
      "Epoch 00094: val_mae did not improve from 47.27886\n",
      "\n",
      "Epoch 00095: val_mae did not improve from 47.27886\n",
      "\n",
      "Epoch 00096: val_mae did not improve from 47.27886\n",
      "\n",
      "Epoch 00097: val_mae did not improve from 47.27886\n",
      "\n",
      "Epoch 00098: val_mae did not improve from 47.27886\n",
      "\n",
      "Epoch 00099: val_mae did not improve from 47.27886\n",
      "\n",
      "Epoch 00100: val_mae did not improve from 47.27886\n",
      "\n",
      "Lambda: 0.001 , Time: 0:01:58\n",
      "Train Error(all epochs): 41.61837 \n",
      " [45.713, 45.665, 45.628, 45.601, 45.584, 45.57, 45.559, 45.547, 45.536, 45.525, 45.514, 45.503, 45.493, 45.482, 45.47, 45.458, 45.446, 45.434, 45.421, 45.408, 45.395, 45.382, 45.368, 45.354, 45.339, 45.324, 45.309, 45.294, 45.278, 45.261, 45.244, 45.227, 45.208, 45.188, 45.167, 45.146, 45.124, 45.101, 45.078, 45.054, 45.03, 45.005, 44.98, 44.954, 44.927, 44.898, 44.868, 44.837, 44.806, 44.773, 44.741, 44.709, 44.675, 44.639, 44.599, 44.559, 44.517, 44.477, 44.434, 44.393, 44.349, 44.304, 44.257, 44.209, 44.161, 44.107, 44.06, 44.005, 43.955, 43.898, 43.841, 43.788, 43.728, 43.664, 43.607, 43.545, 43.484, 43.416, 43.354, 43.288, 43.211, 43.14, 43.071, 42.989, 42.913, 42.85, 42.758, 42.695, 42.599, 42.52, 42.447, 42.346, 42.262, 42.196, 42.09, 41.995, 41.916, 41.828, 41.716, 41.618]\n",
      "Train FP Error(all epochs): 0.0 \n",
      " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Val Error(all epochs): 47.27885818481445 \n",
      " [49.078, 49.095, 49.106, 49.111, 49.113, 49.112, 49.107, 49.099, 49.087, 49.074, 49.059, 49.042, 49.022, 49.0, 48.975, 48.949, 48.923, 48.898, 48.874, 48.849, 48.822, 48.792, 48.758, 48.723, 48.688, 48.653, 48.619, 48.582, 48.543, 48.509, 48.476, 48.441, 48.402, 48.36, 48.314, 48.263, 48.211, 48.159, 48.103, 48.048, 47.984, 47.922, 47.861, 47.803, 47.758, 47.721, 47.671, 47.636, 47.598, 47.583, 47.561, 47.532, 47.505, 47.461, 47.44, 47.399, 47.396, 47.311, 47.314, 47.307, 47.279, 47.287, 47.287, 47.316, 47.311, 47.381, 47.314, 47.401, 47.389, 47.385, 47.451, 47.406, 47.379, 47.434, 47.37, 47.395, 47.402, 47.374, 47.313, 47.364, 47.346, 47.326, 47.422, 47.428, 47.522, 47.341, 47.704, 47.351, 47.335, 47.652, 47.549, 47.413, 47.507, 47.497, 47.489, 47.558, 47.511, 47.434, 47.51, 47.565]\n",
      "Val FP Error(all epochs): 0.0 \n",
      " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "Epoch 00001: val_mae improved from inf to 49.05128, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00002: val_mae did not improve from 49.05128\n",
      "\n",
      "Epoch 00003: val_mae did not improve from 49.05128\n",
      "\n",
      "Epoch 00004: val_mae did not improve from 49.05128\n",
      "\n",
      "Epoch 00005: val_mae did not improve from 49.05128\n",
      "\n",
      "Epoch 00006: val_mae did not improve from 49.05128\n",
      "\n",
      "Epoch 00007: val_mae improved from 49.05128 to 49.04708, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00008: val_mae improved from 49.04708 to 49.03283, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00009: val_mae improved from 49.03283 to 49.01722, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00010: val_mae improved from 49.01722 to 49.00133, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00011: val_mae improved from 49.00133 to 48.98791, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00012: val_mae improved from 48.98791 to 48.97618, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00013: val_mae improved from 48.97618 to 48.96635, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00014: val_mae improved from 48.96635 to 48.95881, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00015: val_mae improved from 48.95881 to 48.95317, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00016: val_mae improved from 48.95317 to 48.94812, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00017: val_mae improved from 48.94812 to 48.94263, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00018: val_mae improved from 48.94263 to 48.93637, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00019: val_mae improved from 48.93637 to 48.92833, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00020: val_mae improved from 48.92833 to 48.91832, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00021: val_mae improved from 48.91832 to 48.90728, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_1.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00022: val_mae improved from 48.90728 to 48.89539, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00023: val_mae improved from 48.89539 to 48.88325, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00024: val_mae improved from 48.88325 to 48.87135, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00025: val_mae improved from 48.87135 to 48.85795, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00026: val_mae improved from 48.85795 to 48.84350, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00027: val_mae improved from 48.84350 to 48.82740, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00028: val_mae improved from 48.82740 to 48.81130, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00029: val_mae improved from 48.81130 to 48.79493, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00030: val_mae improved from 48.79493 to 48.77735, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00031: val_mae improved from 48.77735 to 48.75929, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00032: val_mae improved from 48.75929 to 48.74133, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00033: val_mae improved from 48.74133 to 48.72112, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00034: val_mae improved from 48.72112 to 48.70420, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00035: val_mae improved from 48.70420 to 48.68970, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00036: val_mae improved from 48.68970 to 48.67808, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00037: val_mae improved from 48.67808 to 48.67443, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00038: val_mae did not improve from 48.67443\n",
      "\n",
      "Epoch 00039: val_mae did not improve from 48.67443\n",
      "\n",
      "Epoch 00040: val_mae improved from 48.67443 to 48.67382, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00041: val_mae improved from 48.67382 to 48.67044, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00042: val_mae did not improve from 48.67044\n",
      "\n",
      "Epoch 00043: val_mae did not improve from 48.67044\n",
      "\n",
      "Epoch 00044: val_mae did not improve from 48.67044\n",
      "\n",
      "Epoch 00045: val_mae improved from 48.67044 to 48.66674, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00046: val_mae improved from 48.66674 to 48.64928, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00047: val_mae improved from 48.64928 to 48.61647, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00048: val_mae improved from 48.61647 to 48.56185, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00049: val_mae improved from 48.56185 to 48.49375, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00050: val_mae improved from 48.49375 to 48.41329, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00051: val_mae improved from 48.41329 to 48.31679, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00052: val_mae improved from 48.31679 to 48.21761, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00053: val_mae improved from 48.21761 to 48.14708, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00054: val_mae improved from 48.14708 to 48.07016, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00055: val_mae improved from 48.07016 to 47.98570, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00056: val_mae improved from 47.98570 to 47.91648, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00057: val_mae improved from 47.91648 to 47.85209, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00058: val_mae improved from 47.85209 to 47.75984, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00059: val_mae improved from 47.75984 to 47.67454, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00060: val_mae improved from 47.67454 to 47.60218, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00061: val_mae improved from 47.60218 to 47.50471, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00062: val_mae improved from 47.50471 to 47.43267, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00063: val_mae improved from 47.43267 to 47.32992, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00064: val_mae improved from 47.32992 to 47.21879, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00065: val_mae improved from 47.21879 to 47.09575, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00066: val_mae improved from 47.09575 to 46.95150, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_1.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00067: val_mae improved from 46.95150 to 46.85069, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00068: val_mae improved from 46.85069 to 46.61944, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00069: val_mae improved from 46.61944 to 46.55245, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00070: val_mae improved from 46.55245 to 46.46552, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00071: val_mae improved from 46.46552 to 46.30861, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00072: val_mae improved from 46.30861 to 46.21135, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00073: val_mae improved from 46.21135 to 46.11884, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00074: val_mae improved from 46.11884 to 46.05297, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00075: val_mae improved from 46.05297 to 45.99541, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00076: val_mae improved from 45.99541 to 45.86493, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00077: val_mae improved from 45.86493 to 45.73861, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00078: val_mae improved from 45.73861 to 45.69881, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00079: val_mae improved from 45.69881 to 45.62785, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00080: val_mae improved from 45.62785 to 45.51279, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00081: val_mae improved from 45.51279 to 45.43678, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00082: val_mae improved from 45.43678 to 45.35808, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00083: val_mae improved from 45.35808 to 45.31224, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00084: val_mae improved from 45.31224 to 45.13507, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00085: val_mae improved from 45.13507 to 45.09085, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00086: val_mae improved from 45.09085 to 44.98182, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00087: val_mae improved from 44.98182 to 44.85572, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00088: val_mae improved from 44.85572 to 44.76802, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00089: val_mae improved from 44.76802 to 44.69888, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00090: val_mae improved from 44.69888 to 44.66451, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00091: val_mae improved from 44.66451 to 44.58881, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00092: val_mae improved from 44.58881 to 44.38020, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00093: val_mae improved from 44.38020 to 44.36520, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00094: val_mae improved from 44.36520 to 44.22091, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00095: val_mae improved from 44.22091 to 44.13440, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00096: val_mae improved from 44.13440 to 43.98951, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00097: val_mae improved from 43.98951 to 43.94994, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00098: val_mae improved from 43.94994 to 43.79959, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00099: val_mae did not improve from 43.79959\n",
      "\n",
      "Epoch 00100: val_mae did not improve from 43.79959\n",
      "\n",
      "Lambda: 0.01 , Time: 0:02:00\n",
      "Train Error(all epochs): 42.33748 \n",
      " [45.695, 45.648, 45.61, 45.581, 45.56, 45.54, 45.522, 45.505, 45.489, 45.475, 45.461, 45.449, 45.436, 45.424, 45.411, 45.399, 45.386, 45.373, 45.36, 45.346, 45.333, 45.319, 45.305, 45.29, 45.275, 45.26, 45.245, 45.229, 45.214, 45.198, 45.182, 45.165, 45.147, 45.13, 45.111, 45.092, 45.072, 45.052, 45.032, 45.01, 44.988, 44.966, 44.943, 44.919, 44.894, 44.87, 44.844, 44.816, 44.788, 44.758, 44.729, 44.699, 44.668, 44.639, 44.608, 44.577, 44.545, 44.512, 44.476, 44.441, 44.404, 44.368, 44.336, 44.295, 44.258, 44.222, 44.178, 44.142, 44.092, 44.052, 44.007, 43.96, 43.921, 43.871, 43.826, 43.785, 43.731, 43.683, 43.637, 43.582, 43.529, 43.481, 43.424, 43.373, 43.307, 43.258, 43.198, 43.138, 43.083, 43.012, 42.953, 42.896, 42.824, 42.764, 42.694, 42.625, 42.557, 42.483, 42.406, 42.337]\n",
      "Train FP Error(all epochs): 0.0 \n",
      " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Val Error(all epochs): 43.79959487915039 \n",
      " [49.051, 49.064, 49.072, 49.074, 49.069, 49.059, 49.047, 49.033, 49.017, 49.001, 48.988, 48.976, 48.966, 48.959, 48.953, 48.948, 48.943, 48.936, 48.928, 48.918, 48.907, 48.895, 48.883, 48.871, 48.858, 48.844, 48.827, 48.811, 48.795, 48.777, 48.759, 48.741, 48.721, 48.704, 48.69, 48.678, 48.674, 48.675, 48.675, 48.674, 48.67, 48.672, 48.682, 48.674, 48.667, 48.649, 48.616, 48.562, 48.494, 48.413, 48.317, 48.218, 48.147, 48.07, 47.986, 47.916, 47.852, 47.76, 47.675, 47.602, 47.505, 47.433, 47.33, 47.219, 47.096, 46.951, 46.851, 46.619, 46.552, 46.466, 46.309, 46.211, 46.119, 46.053, 45.995, 45.865, 45.739, 45.699, 45.628, 45.513, 45.437, 45.358, 45.312, 45.135, 45.091, 44.982, 44.856, 44.768, 44.699, 44.665, 44.589, 44.38, 44.365, 44.221, 44.134, 43.99, 43.95, 43.8, 43.943, 43.839]\n",
      "Val FP Error(all epochs): 0.0 \n",
      " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_mae improved from inf to 48.96317, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00002: val_mae did not improve from 48.96317\n",
      "\n",
      "Epoch 00003: val_mae did not improve from 48.96317\n",
      "\n",
      "Epoch 00004: val_mae did not improve from 48.96317\n",
      "\n",
      "Epoch 00005: val_mae did not improve from 48.96317\n",
      "\n",
      "Epoch 00006: val_mae did not improve from 48.96317\n",
      "\n",
      "Epoch 00007: val_mae improved from 48.96317 to 48.96239, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00008: val_mae improved from 48.96239 to 48.95522, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00009: val_mae improved from 48.95522 to 48.94535, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00010: val_mae improved from 48.94535 to 48.93365, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00011: val_mae improved from 48.93365 to 48.91985, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00012: val_mae improved from 48.91985 to 48.90325, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00013: val_mae improved from 48.90325 to 48.88446, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00014: val_mae improved from 48.88446 to 48.86339, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00015: val_mae improved from 48.86339 to 48.83989, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00016: val_mae improved from 48.83989 to 48.81492, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00017: val_mae improved from 48.81492 to 48.78920, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00018: val_mae improved from 48.78920 to 48.76385, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00019: val_mae improved from 48.76385 to 48.73744, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00020: val_mae improved from 48.73744 to 48.71019, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00021: val_mae improved from 48.71019 to 48.68163, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00022: val_mae improved from 48.68163 to 48.65133, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00023: val_mae improved from 48.65133 to 48.61846, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00024: val_mae improved from 48.61846 to 48.58248, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00025: val_mae improved from 48.58248 to 48.54517, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00026: val_mae improved from 48.54517 to 48.50813, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00027: val_mae improved from 48.50813 to 48.47139, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00028: val_mae improved from 48.47139 to 48.43521, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00029: val_mae improved from 48.43521 to 48.40011, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00030: val_mae improved from 48.40011 to 48.36544, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00031: val_mae improved from 48.36544 to 48.33099, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00032: val_mae improved from 48.33099 to 48.29765, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00033: val_mae improved from 48.29765 to 48.26394, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00034: val_mae improved from 48.26394 to 48.22887, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00035: val_mae improved from 48.22887 to 48.19086, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00036: val_mae improved from 48.19086 to 48.14983, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00037: val_mae improved from 48.14983 to 48.11217, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00038: val_mae improved from 48.11217 to 48.07861, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00039: val_mae improved from 48.07861 to 48.04168, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00040: val_mae improved from 48.04168 to 47.99833, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00041: val_mae improved from 47.99833 to 47.96433, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00042: val_mae improved from 47.96433 to 47.93284, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00043: val_mae improved from 47.93284 to 47.89885, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00044: val_mae improved from 47.89885 to 47.86715, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00045: val_mae improved from 47.86715 to 47.83397, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_2.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00046: val_mae improved from 47.83397 to 47.79332, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00047: val_mae improved from 47.79332 to 47.75552, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00048: val_mae improved from 47.75552 to 47.72022, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00049: val_mae improved from 47.72022 to 47.67981, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00050: val_mae improved from 47.67981 to 47.65544, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00051: val_mae improved from 47.65544 to 47.61937, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00052: val_mae improved from 47.61937 to 47.58457, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00053: val_mae improved from 47.58457 to 47.55721, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00054: val_mae improved from 47.55721 to 47.52020, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00055: val_mae improved from 47.52020 to 47.50275, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00056: val_mae improved from 47.50275 to 47.41428, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00057: val_mae did not improve from 47.41428\n",
      "\n",
      "Epoch 00058: val_mae improved from 47.41428 to 47.36357, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00059: val_mae improved from 47.36357 to 47.29797, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00060: val_mae improved from 47.29797 to 47.27143, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00061: val_mae improved from 47.27143 to 47.19190, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00062: val_mae improved from 47.19190 to 47.15471, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00063: val_mae improved from 47.15471 to 47.10329, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00064: val_mae improved from 47.10329 to 47.03750, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00065: val_mae improved from 47.03750 to 47.02480, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00066: val_mae improved from 47.02480 to 46.93548, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00067: val_mae improved from 46.93548 to 46.91435, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00068: val_mae improved from 46.91435 to 46.85097, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00069: val_mae improved from 46.85097 to 46.81857, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00070: val_mae improved from 46.81857 to 46.78725, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00071: val_mae improved from 46.78725 to 46.69979, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00072: val_mae did not improve from 46.69979\n",
      "\n",
      "Epoch 00073: val_mae improved from 46.69979 to 46.62497, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00074: val_mae improved from 46.62497 to 46.58873, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00075: val_mae improved from 46.58873 to 46.57505, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00076: val_mae improved from 46.57505 to 46.49533, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00077: val_mae improved from 46.49533 to 46.46208, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00078: val_mae improved from 46.46208 to 46.43396, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00079: val_mae improved from 46.43396 to 46.37096, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00080: val_mae improved from 46.37096 to 46.30679, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00081: val_mae improved from 46.30679 to 46.23597, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00082: val_mae improved from 46.23597 to 46.16129, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00083: val_mae improved from 46.16129 to 46.10404, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00084: val_mae improved from 46.10404 to 46.02918, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00085: val_mae improved from 46.02918 to 45.98794, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00086: val_mae improved from 45.98794 to 45.91154, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00087: val_mae improved from 45.91154 to 45.87944, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_2.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00088: val_mae improved from 45.87944 to 45.79966, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00089: val_mae improved from 45.79966 to 45.78804, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00090: val_mae improved from 45.78804 to 45.65168, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00091: val_mae improved from 45.65168 to 45.57811, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00092: val_mae improved from 45.57811 to 45.54009, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00093: val_mae improved from 45.54009 to 45.43668, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00094: val_mae improved from 45.43668 to 45.38045, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00095: val_mae improved from 45.38045 to 45.33636, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00096: val_mae improved from 45.33636 to 45.25757, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00097: val_mae improved from 45.25757 to 45.20343, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00098: val_mae improved from 45.20343 to 45.13431, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00099: val_mae improved from 45.13431 to 45.04892, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00100: val_mae improved from 45.04892 to 45.01833, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_2.h5\n",
      "\n",
      "Lambda: 0.1 , Time: 0:02:06\n",
      "Train Error(all epochs): 42.555458 \n",
      " [45.699, 45.652, 45.62, 45.595, 45.577, 45.561, 45.547, 45.534, 45.522, 45.51, 45.499, 45.487, 45.476, 45.464, 45.452, 45.44, 45.428, 45.415, 45.402, 45.388, 45.374, 45.361, 45.346, 45.332, 45.317, 45.302, 45.287, 45.271, 45.255, 45.239, 45.222, 45.205, 45.187, 45.17, 45.152, 45.134, 45.115, 45.096, 45.076, 45.055, 45.033, 45.012, 44.99, 44.966, 44.943, 44.919, 44.895, 44.871, 44.845, 44.817, 44.791, 44.763, 44.735, 44.707, 44.679, 44.651, 44.616, 44.588, 44.551, 44.517, 44.488, 44.453, 44.416, 44.381, 44.343, 44.308, 44.269, 44.234, 44.188, 44.148, 44.108, 44.063, 44.024, 43.974, 43.928, 43.887, 43.838, 43.79, 43.745, 43.698, 43.645, 43.596, 43.549, 43.497, 43.44, 43.387, 43.332, 43.286, 43.226, 43.178, 43.112, 43.055, 43.001, 42.934, 42.872, 42.815, 42.751, 42.686, 42.626, 42.555]\n",
      "Train FP Error(all epochs): 0.0 \n",
      " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Val Error(all epochs): 45.01832962036133 \n",
      " [48.963, 48.966, 48.97, 48.971, 48.97, 48.967, 48.962, 48.955, 48.945, 48.934, 48.92, 48.903, 48.884, 48.863, 48.84, 48.815, 48.789, 48.764, 48.737, 48.71, 48.682, 48.651, 48.618, 48.582, 48.545, 48.508, 48.471, 48.435, 48.4, 48.365, 48.331, 48.298, 48.264, 48.229, 48.191, 48.15, 48.112, 48.079, 48.042, 47.998, 47.964, 47.933, 47.899, 47.867, 47.834, 47.793, 47.756, 47.72, 47.68, 47.655, 47.619, 47.585, 47.557, 47.52, 47.503, 47.414, 47.421, 47.364, 47.298, 47.271, 47.192, 47.155, 47.103, 47.038, 47.025, 46.935, 46.914, 46.851, 46.819, 46.787, 46.7, 46.7, 46.625, 46.589, 46.575, 46.495, 46.462, 46.434, 46.371, 46.307, 46.236, 46.161, 46.104, 46.029, 45.988, 45.912, 45.879, 45.8, 45.788, 45.652, 45.578, 45.54, 45.437, 45.38, 45.336, 45.258, 45.203, 45.134, 45.049, 45.018]\n",
      "Val FP Error(all epochs): 0.0 \n",
      " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "Epoch 00001: val_mae improved from inf to 48.98358, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00002: val_mae did not improve from 48.98358\n",
      "\n",
      "Epoch 00003: val_mae did not improve from 48.98358\n",
      "\n",
      "Epoch 00004: val_mae did not improve from 48.98358\n",
      "\n",
      "Epoch 00005: val_mae did not improve from 48.98358\n",
      "\n",
      "Epoch 00006: val_mae improved from 48.98358 to 48.97720, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00007: val_mae improved from 48.97720 to 48.96926, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00008: val_mae improved from 48.96926 to 48.95870, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00009: val_mae improved from 48.95870 to 48.94562, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00010: val_mae improved from 48.94562 to 48.93078, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00011: val_mae improved from 48.93078 to 48.91467, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00012: val_mae improved from 48.91467 to 48.89844, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00013: val_mae improved from 48.89844 to 48.88198, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00014: val_mae improved from 48.88198 to 48.86462, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00015: val_mae improved from 48.86462 to 48.84611, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00016: val_mae improved from 48.84611 to 48.82683, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00017: val_mae improved from 48.82683 to 48.80733, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_3.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00018: val_mae improved from 48.80733 to 48.78824, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00019: val_mae improved from 48.78824 to 48.77029, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00020: val_mae improved from 48.77029 to 48.75292, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00021: val_mae improved from 48.75292 to 48.73534, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00022: val_mae improved from 48.73534 to 48.71687, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00023: val_mae improved from 48.71687 to 48.69814, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00024: val_mae improved from 48.69814 to 48.67891, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00025: val_mae improved from 48.67891 to 48.65860, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00026: val_mae improved from 48.65860 to 48.63808, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00027: val_mae improved from 48.63808 to 48.61744, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00028: val_mae improved from 48.61744 to 48.59579, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00029: val_mae improved from 48.59579 to 48.57373, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00030: val_mae improved from 48.57373 to 48.55152, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00031: val_mae improved from 48.55152 to 48.53058, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00032: val_mae improved from 48.53058 to 48.51017, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00033: val_mae improved from 48.51017 to 48.48966, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00034: val_mae improved from 48.48966 to 48.46819, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00035: val_mae improved from 48.46819 to 48.44625, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00036: val_mae improved from 48.44625 to 48.42524, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00037: val_mae improved from 48.42524 to 48.40306, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00038: val_mae improved from 48.40306 to 48.37943, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00039: val_mae improved from 48.37943 to 48.35688, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00040: val_mae improved from 48.35688 to 48.33599, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00041: val_mae improved from 48.33599 to 48.31120, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00042: val_mae improved from 48.31120 to 48.28659, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00043: val_mae improved from 48.28659 to 48.25660, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00044: val_mae improved from 48.25660 to 48.22959, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00045: val_mae improved from 48.22959 to 48.19435, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00046: val_mae improved from 48.19435 to 48.16223, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00047: val_mae improved from 48.16223 to 48.12445, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00048: val_mae improved from 48.12445 to 48.08626, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00049: val_mae improved from 48.08626 to 48.04799, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00050: val_mae improved from 48.04799 to 48.01802, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00051: val_mae improved from 48.01802 to 47.95637, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00052: val_mae improved from 47.95637 to 47.92656, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00053: val_mae improved from 47.92656 to 47.89727, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00054: val_mae improved from 47.89727 to 47.84825, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00055: val_mae improved from 47.84825 to 47.81672, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00056: val_mae improved from 47.81672 to 47.79856, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00057: val_mae improved from 47.79856 to 47.75528, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00058: val_mae improved from 47.75528 to 47.71009, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_3.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00059: val_mae improved from 47.71009 to 47.68520, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00060: val_mae improved from 47.68520 to 47.64613, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00061: val_mae improved from 47.64613 to 47.60231, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00062: val_mae improved from 47.60231 to 47.57162, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00063: val_mae improved from 47.57162 to 47.53180, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00064: val_mae improved from 47.53180 to 47.49067, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00065: val_mae improved from 47.49067 to 47.44817, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00066: val_mae improved from 47.44817 to 47.41128, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00067: val_mae improved from 47.41128 to 47.35865, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00068: val_mae improved from 47.35865 to 47.32119, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00069: val_mae improved from 47.32119 to 47.26722, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00070: val_mae improved from 47.26722 to 47.20311, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00071: val_mae improved from 47.20311 to 47.16291, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00072: val_mae improved from 47.16291 to 47.10417, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00073: val_mae improved from 47.10417 to 47.04977, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00074: val_mae improved from 47.04977 to 47.01342, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00075: val_mae improved from 47.01342 to 46.94673, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00076: val_mae improved from 46.94673 to 46.87501, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00077: val_mae improved from 46.87501 to 46.84088, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00078: val_mae improved from 46.84088 to 46.78382, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00079: val_mae improved from 46.78382 to 46.70596, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00080: val_mae improved from 46.70596 to 46.68740, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00081: val_mae improved from 46.68740 to 46.62917, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00082: val_mae improved from 46.62917 to 46.55534, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00083: val_mae improved from 46.55534 to 46.50319, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00084: val_mae improved from 46.50319 to 46.47990, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00085: val_mae improved from 46.47990 to 46.43045, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00086: val_mae improved from 46.43045 to 46.34465, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00087: val_mae improved from 46.34465 to 46.28412, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00088: val_mae improved from 46.28412 to 46.24603, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00089: val_mae improved from 46.24603 to 46.20643, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00090: val_mae improved from 46.20643 to 46.12887, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00091: val_mae improved from 46.12887 to 46.06475, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00092: val_mae improved from 46.06475 to 46.01559, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00093: val_mae improved from 46.01559 to 45.94764, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00094: val_mae improved from 45.94764 to 45.88017, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00095: val_mae improved from 45.88017 to 45.79852, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00096: val_mae improved from 45.79852 to 45.74235, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00097: val_mae improved from 45.74235 to 45.65143, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00098: val_mae improved from 45.65143 to 45.63623, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00099: val_mae improved from 45.63623 to 45.59562, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_3.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00100: val_mae improved from 45.59562 to 45.46565, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/150/best_model_lambda_3.h5\n",
      "\n",
      "Lambda: 1 , Time: 0:02:03\n",
      "Train Error(all epochs): 42.881054 \n",
      " [45.708, 45.672, 45.653, 45.639, 45.624, 45.611, 45.598, 45.587, 45.576, 45.566, 45.556, 45.547, 45.537, 45.528, 45.519, 45.509, 45.5, 45.49, 45.481, 45.471, 45.46, 45.449, 45.437, 45.426, 45.413, 45.401, 45.388, 45.374, 45.36, 45.346, 45.331, 45.315, 45.3, 45.285, 45.269, 45.252, 45.235, 45.218, 45.2, 45.182, 45.163, 45.145, 45.126, 45.105, 45.084, 45.063, 45.041, 45.019, 44.999, 44.974, 44.956, 44.928, 44.898, 44.878, 44.847, 44.819, 44.796, 44.766, 44.735, 44.707, 44.681, 44.649, 44.619, 44.589, 44.556, 44.522, 44.486, 44.449, 44.419, 44.383, 44.347, 44.312, 44.262, 44.228, 44.184, 44.136, 44.099, 44.059, 44.015, 43.972, 43.927, 43.885, 43.823, 43.779, 43.743, 43.681, 43.624, 43.586, 43.528, 43.467, 43.418, 43.353, 43.302, 43.25, 43.186, 43.128, 43.075, 43.024, 42.946, 42.881]\n",
      "Train FP Error(all epochs): 0.0 \n",
      " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Val Error(all epochs): 45.46565246582031 \n",
      " [48.984, 48.99, 48.992, 48.989, 48.984, 48.977, 48.969, 48.959, 48.946, 48.931, 48.915, 48.898, 48.882, 48.865, 48.846, 48.827, 48.807, 48.788, 48.77, 48.753, 48.735, 48.717, 48.698, 48.679, 48.659, 48.638, 48.617, 48.596, 48.574, 48.552, 48.531, 48.51, 48.49, 48.468, 48.446, 48.425, 48.403, 48.379, 48.357, 48.336, 48.311, 48.287, 48.257, 48.23, 48.194, 48.162, 48.124, 48.086, 48.048, 48.018, 47.956, 47.927, 47.897, 47.848, 47.817, 47.799, 47.755, 47.71, 47.685, 47.646, 47.602, 47.572, 47.532, 47.491, 47.448, 47.411, 47.359, 47.321, 47.267, 47.203, 47.163, 47.104, 47.05, 47.013, 46.947, 46.875, 46.841, 46.784, 46.706, 46.687, 46.629, 46.555, 46.503, 46.48, 46.43, 46.345, 46.284, 46.246, 46.206, 46.129, 46.065, 46.016, 45.948, 45.88, 45.799, 45.742, 45.651, 45.636, 45.596, 45.466]\n",
      "Val FP Error(all epochs): 0.0 \n",
      " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "Trainig set size: 150 , Time: 0:08:08 , best_lambda: 0.01 , min_  error: 43.8\n",
      "Test starts:  180 , ends:  298\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "average_error:  42.646 , fp_average_error:  0.0\n",
      "\n",
      "\n",
      "\n",
      "number_samples: 180 , New samples: 180\n",
      "Validation size: 36 , starts: 180 , ends: 215\n",
      "\n",
      "Epoch 00001: val_mae improved from inf to 46.87897, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00002: val_mae did not improve from 46.87897\n",
      "\n",
      "Epoch 00003: val_mae did not improve from 46.87897\n",
      "\n",
      "Epoch 00004: val_mae did not improve from 46.87897\n",
      "\n",
      "Epoch 00005: val_mae did not improve from 46.87897\n",
      "\n",
      "Epoch 00006: val_mae did not improve from 46.87897\n",
      "\n",
      "Epoch 00007: val_mae did not improve from 46.87897\n",
      "\n",
      "Epoch 00008: val_mae did not improve from 46.87897\n",
      "\n",
      "Epoch 00009: val_mae improved from 46.87897 to 46.87074, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00010: val_mae improved from 46.87074 to 46.85765, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00011: val_mae improved from 46.85765 to 46.84235, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00012: val_mae improved from 46.84235 to 46.82582, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00013: val_mae improved from 46.82582 to 46.80896, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00014: val_mae improved from 46.80896 to 46.79136, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00015: val_mae improved from 46.79136 to 46.77289, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00016: val_mae improved from 46.77289 to 46.75329, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00017: val_mae improved from 46.75329 to 46.73267, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00018: val_mae improved from 46.73267 to 46.71152, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00019: val_mae improved from 46.71152 to 46.69054, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00020: val_mae improved from 46.69054 to 46.66923, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00021: val_mae improved from 46.66923 to 46.64664, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00022: val_mae improved from 46.64664 to 46.62303, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00023: val_mae improved from 46.62303 to 46.59856, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00024: val_mae improved from 46.59856 to 46.57284, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00025: val_mae improved from 46.57284 to 46.54653, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00026: val_mae improved from 46.54653 to 46.52047, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00027: val_mae improved from 46.52047 to 46.49545, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00028: val_mae improved from 46.49545 to 46.47105, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00029: val_mae improved from 46.47105 to 46.44783, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00030: val_mae improved from 46.44783 to 46.42361, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_0.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00031: val_mae improved from 46.42361 to 46.39733, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00032: val_mae improved from 46.39733 to 46.37085, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00033: val_mae improved from 46.37085 to 46.34408, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00034: val_mae improved from 46.34408 to 46.31711, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00035: val_mae improved from 46.31711 to 46.28624, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00036: val_mae improved from 46.28624 to 46.24921, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00037: val_mae improved from 46.24921 to 46.21039, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00038: val_mae improved from 46.21039 to 46.16975, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00039: val_mae improved from 46.16975 to 46.13261, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00040: val_mae improved from 46.13261 to 46.09401, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00041: val_mae improved from 46.09401 to 46.05777, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00042: val_mae improved from 46.05777 to 46.02552, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00043: val_mae improved from 46.02552 to 45.99834, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00044: val_mae improved from 45.99834 to 45.96703, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00045: val_mae improved from 45.96703 to 45.93763, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00046: val_mae improved from 45.93763 to 45.92165, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00047: val_mae improved from 45.92165 to 45.89543, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00048: val_mae improved from 45.89543 to 45.86195, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00049: val_mae improved from 45.86195 to 45.85619, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00050: val_mae improved from 45.85619 to 45.83280, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00051: val_mae improved from 45.83280 to 45.80097, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00052: val_mae did not improve from 45.80097\n",
      "\n",
      "Epoch 00053: val_mae improved from 45.80097 to 45.79074, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00054: val_mae did not improve from 45.79074\n",
      "\n",
      "Epoch 00055: val_mae did not improve from 45.79074\n",
      "\n",
      "Epoch 00056: val_mae did not improve from 45.79074\n",
      "\n",
      "Epoch 00057: val_mae did not improve from 45.79074\n",
      "\n",
      "Epoch 00058: val_mae did not improve from 45.79074\n",
      "\n",
      "Epoch 00059: val_mae improved from 45.79074 to 45.78742, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00060: val_mae improved from 45.78742 to 45.78634, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00061: val_mae improved from 45.78634 to 45.76498, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00062: val_mae did not improve from 45.76498\n",
      "\n",
      "Epoch 00063: val_mae improved from 45.76498 to 45.73406, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00064: val_mae improved from 45.73406 to 45.70655, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00065: val_mae improved from 45.70655 to 45.68341, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00066: val_mae improved from 45.68341 to 45.62137, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00067: val_mae improved from 45.62137 to 45.59550, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00068: val_mae improved from 45.59550 to 45.49612, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00069: val_mae improved from 45.49612 to 45.48352, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00070: val_mae improved from 45.48352 to 45.35213, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00071: val_mae improved from 45.35213 to 45.29176, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00072: val_mae improved from 45.29176 to 45.27841, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00073: val_mae improved from 45.27841 to 45.16419, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00074: val_mae improved from 45.16419 to 45.07796, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00075: val_mae improved from 45.07796 to 45.04029, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00076: val_mae improved from 45.04029 to 44.92920, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_0.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00077: val_mae improved from 44.92920 to 44.85581, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00078: val_mae improved from 44.85581 to 44.85102, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00079: val_mae improved from 44.85102 to 44.77538, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00080: val_mae improved from 44.77538 to 44.71380, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00081: val_mae improved from 44.71380 to 44.68435, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00082: val_mae improved from 44.68435 to 44.65811, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00083: val_mae improved from 44.65811 to 44.61916, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00084: val_mae improved from 44.61916 to 44.61066, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00085: val_mae did not improve from 44.61066\n",
      "\n",
      "Epoch 00086: val_mae improved from 44.61066 to 44.57582, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00087: val_mae improved from 44.57582 to 44.52391, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00088: val_mae improved from 44.52391 to 44.48311, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00089: val_mae improved from 44.48311 to 44.42800, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00090: val_mae improved from 44.42800 to 44.36649, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00091: val_mae improved from 44.36649 to 44.34309, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00092: val_mae improved from 44.34309 to 44.29375, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00093: val_mae improved from 44.29375 to 44.22902, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00094: val_mae improved from 44.22902 to 44.13996, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00095: val_mae improved from 44.13996 to 44.08271, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00096: val_mae improved from 44.08271 to 43.98431, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00097: val_mae improved from 43.98431 to 43.93219, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00098: val_mae improved from 43.93219 to 43.75806, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00099: val_mae did not improve from 43.75806\n",
      "\n",
      "Epoch 00100: val_mae improved from 43.75806 to 43.59039, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_0.h5\n",
      "\n",
      "Lambda: 0.001 , Time: 0:02:28\n",
      "Train Error(all epochs): 42.581863 \n",
      " [46.097, 46.073, 46.043, 46.02, 46.003, 45.99, 45.978, 45.966, 45.954, 45.942, 45.93, 45.918, 45.906, 45.894, 45.882, 45.869, 45.857, 45.844, 45.831, 45.818, 45.805, 45.791, 45.778, 45.764, 45.75, 45.736, 45.721, 45.706, 45.691, 45.675, 45.66, 45.644, 45.627, 45.61, 45.593, 45.576, 45.557, 45.537, 45.516, 45.495, 45.473, 45.45, 45.426, 45.402, 45.376, 45.35, 45.324, 45.297, 45.268, 45.242, 45.214, 45.183, 45.156, 45.124, 45.094, 45.062, 45.027, 44.998, 44.962, 44.927, 44.894, 44.856, 44.821, 44.781, 44.744, 44.707, 44.665, 44.629, 44.581, 44.545, 44.492, 44.443, 44.406, 44.348, 44.3, 44.26, 44.195, 44.14, 44.096, 44.032, 43.969, 43.911, 43.849, 43.784, 43.721, 43.66, 43.586, 43.518, 43.45, 43.374, 43.299, 43.227, 43.15, 43.075, 42.997, 42.915, 42.829, 42.749, 42.66, 42.582]\n",
      "Train FP Error(all epochs): 0.0 \n",
      " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Val Error(all epochs): 43.59038543701172 \n",
      " [46.879, 46.891, 46.897, 46.901, 46.901, 46.898, 46.891, 46.882, 46.871, 46.858, 46.842, 46.826, 46.809, 46.791, 46.773, 46.753, 46.733, 46.712, 46.691, 46.669, 46.647, 46.623, 46.599, 46.573, 46.547, 46.52, 46.495, 46.471, 46.448, 46.424, 46.397, 46.371, 46.344, 46.317, 46.286, 46.249, 46.21, 46.17, 46.133, 46.094, 46.058, 46.026, 45.998, 45.967, 45.938, 45.922, 45.895, 45.862, 45.856, 45.833, 45.801, 45.81, 45.791, 45.804, 45.811, 45.798, 45.828, 45.791, 45.787, 45.786, 45.765, 45.781, 45.734, 45.707, 45.683, 45.621, 45.596, 45.496, 45.484, 45.352, 45.292, 45.278, 45.164, 45.078, 45.04, 44.929, 44.856, 44.851, 44.775, 44.714, 44.684, 44.658, 44.619, 44.611, 44.64, 44.576, 44.524, 44.483, 44.428, 44.366, 44.343, 44.294, 44.229, 44.14, 44.083, 43.984, 43.932, 43.758, 43.77, 43.59]\n",
      "Val FP Error(all epochs): 0.0 \n",
      " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "Epoch 00001: val_mae improved from inf to 46.81343, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00002: val_mae did not improve from 46.81343\n",
      "\n",
      "Epoch 00003: val_mae improved from 46.81343 to 46.80898, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00004: val_mae improved from 46.80898 to 46.80202, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00005: val_mae improved from 46.80202 to 46.79548, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00006: val_mae improved from 46.79548 to 46.78694, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_1.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00007: val_mae improved from 46.78694 to 46.77468, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00008: val_mae improved from 46.77468 to 46.75954, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00009: val_mae improved from 46.75954 to 46.74054, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00010: val_mae improved from 46.74054 to 46.71886, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00011: val_mae improved from 46.71886 to 46.69696, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00012: val_mae improved from 46.69696 to 46.67467, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00013: val_mae improved from 46.67467 to 46.65289, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00014: val_mae improved from 46.65289 to 46.63197, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00015: val_mae improved from 46.63197 to 46.61211, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00016: val_mae improved from 46.61211 to 46.59392, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00017: val_mae improved from 46.59392 to 46.57645, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00018: val_mae improved from 46.57645 to 46.55938, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00019: val_mae improved from 46.55938 to 46.54276, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00020: val_mae improved from 46.54276 to 46.52545, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00021: val_mae improved from 46.52545 to 46.50690, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00022: val_mae improved from 46.50690 to 46.48695, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00023: val_mae improved from 46.48695 to 46.46582, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00024: val_mae improved from 46.46582 to 46.44333, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00025: val_mae improved from 46.44333 to 46.42037, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00026: val_mae improved from 46.42037 to 46.39733, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00027: val_mae improved from 46.39733 to 46.37457, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00028: val_mae improved from 46.37457 to 46.35215, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00029: val_mae improved from 46.35215 to 46.32948, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00030: val_mae improved from 46.32948 to 46.30564, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00031: val_mae improved from 46.30564 to 46.27999, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00032: val_mae improved from 46.27999 to 46.25109, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00033: val_mae improved from 46.25109 to 46.21943, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00034: val_mae improved from 46.21943 to 46.18544, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00035: val_mae improved from 46.18544 to 46.14911, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00036: val_mae improved from 46.14911 to 46.11154, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00037: val_mae improved from 46.11154 to 46.07166, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00038: val_mae improved from 46.07166 to 46.02782, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00039: val_mae improved from 46.02782 to 45.98209, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00040: val_mae improved from 45.98209 to 45.93727, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00041: val_mae improved from 45.93727 to 45.89013, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00042: val_mae improved from 45.89013 to 45.83598, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00043: val_mae improved from 45.83598 to 45.77406, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00044: val_mae improved from 45.77406 to 45.70633, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00045: val_mae improved from 45.70633 to 45.63610, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00046: val_mae improved from 45.63610 to 45.56247, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00047: val_mae improved from 45.56247 to 45.49037, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_1.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00048: val_mae improved from 45.49037 to 45.42046, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00049: val_mae improved from 45.42046 to 45.34763, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00050: val_mae improved from 45.34763 to 45.27643, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00051: val_mae improved from 45.27643 to 45.20014, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00052: val_mae improved from 45.20014 to 45.13363, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00053: val_mae improved from 45.13363 to 45.08140, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00054: val_mae improved from 45.08140 to 45.02043, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00055: val_mae improved from 45.02043 to 44.96238, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00056: val_mae improved from 44.96238 to 44.91095, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00057: val_mae improved from 44.91095 to 44.86012, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00058: val_mae improved from 44.86012 to 44.79643, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00059: val_mae improved from 44.79643 to 44.74857, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00060: val_mae improved from 44.74857 to 44.68335, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00061: val_mae improved from 44.68335 to 44.63264, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00062: val_mae improved from 44.63264 to 44.56676, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00063: val_mae improved from 44.56676 to 44.49695, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00064: val_mae improved from 44.49695 to 44.39275, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00065: val_mae improved from 44.39275 to 44.36604, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00066: val_mae improved from 44.36604 to 44.19207, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00067: val_mae improved from 44.19207 to 44.15086, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00068: val_mae improved from 44.15086 to 44.05290, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00069: val_mae improved from 44.05290 to 43.93797, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00070: val_mae improved from 43.93797 to 43.84476, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00071: val_mae improved from 43.84476 to 43.70464, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00072: val_mae improved from 43.70464 to 43.60599, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00073: val_mae improved from 43.60599 to 43.45601, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00074: val_mae improved from 43.45601 to 43.33495, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00075: val_mae improved from 43.33495 to 43.22639, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00076: val_mae improved from 43.22639 to 43.11045, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00077: val_mae improved from 43.11045 to 43.01305, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00078: val_mae improved from 43.01305 to 42.91234, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00079: val_mae improved from 42.91234 to 42.79588, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00080: val_mae improved from 42.79588 to 42.66202, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00081: val_mae did not improve from 42.66202\n",
      "\n",
      "Epoch 00082: val_mae improved from 42.66202 to 42.39064, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00083: val_mae improved from 42.39064 to 42.33519, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00084: val_mae did not improve from 42.33519\n",
      "\n",
      "Epoch 00085: val_mae improved from 42.33519 to 42.17729, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00086: val_mae improved from 42.17729 to 41.97169, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00087: val_mae improved from 41.97169 to 41.97084, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00088: val_mae improved from 41.97084 to 41.95934, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00089: val_mae improved from 41.95934 to 41.75831, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_1.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00090: val_mae improved from 41.75831 to 41.58046, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00091: val_mae improved from 41.58046 to 41.54439, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00092: val_mae improved from 41.54439 to 41.51497, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00093: val_mae improved from 41.51497 to 41.38233, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00094: val_mae improved from 41.38233 to 41.25307, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00095: val_mae improved from 41.25307 to 41.20863, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00096: val_mae improved from 41.20863 to 41.19521, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00097: val_mae improved from 41.19521 to 41.05288, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00098: val_mae improved from 41.05288 to 40.91168, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_1.h5\n",
      "\n",
      "Epoch 00099: val_mae did not improve from 40.91168\n",
      "\n",
      "Epoch 00100: val_mae improved from 40.91168 to 40.89874, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_1.h5\n",
      "\n",
      "Lambda: 0.01 , Time: 0:02:29\n",
      "Train Error(all epochs): 42.524433 \n",
      " [46.09, 46.05, 46.012, 45.983, 45.961, 45.942, 45.926, 45.912, 45.899, 45.887, 45.874, 45.862, 45.849, 45.836, 45.824, 45.811, 45.798, 45.785, 45.772, 45.759, 45.746, 45.733, 45.719, 45.704, 45.69, 45.676, 45.661, 45.645, 45.63, 45.614, 45.597, 45.581, 45.564, 45.546, 45.529, 45.51, 45.491, 45.472, 45.452, 45.432, 45.411, 45.389, 45.367, 45.344, 45.32, 45.296, 45.271, 45.246, 45.22, 45.193, 45.165, 45.136, 45.107, 45.078, 45.047, 45.015, 44.981, 44.947, 44.91, 44.874, 44.834, 44.793, 44.751, 44.709, 44.661, 44.621, 44.57, 44.526, 44.476, 44.43, 44.383, 44.328, 44.283, 44.229, 44.177, 44.123, 44.071, 44.016, 43.957, 43.907, 43.838, 43.805, 43.716, 43.658, 43.621, 43.531, 43.466, 43.416, 43.345, 43.262, 43.205, 43.138, 43.058, 42.985, 42.92, 42.838, 42.763, 42.685, 42.608, 42.524]\n",
      "Train FP Error(all epochs): 0.0 \n",
      " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Val Error(all epochs): 40.89874267578125 \n",
      " [46.813, 46.816, 46.809, 46.802, 46.795, 46.787, 46.775, 46.76, 46.741, 46.719, 46.697, 46.675, 46.653, 46.632, 46.612, 46.594, 46.576, 46.559, 46.543, 46.525, 46.507, 46.487, 46.466, 46.443, 46.42, 46.397, 46.375, 46.352, 46.329, 46.306, 46.28, 46.251, 46.219, 46.185, 46.149, 46.112, 46.072, 46.028, 45.982, 45.937, 45.89, 45.836, 45.774, 45.706, 45.636, 45.562, 45.49, 45.42, 45.348, 45.276, 45.2, 45.134, 45.081, 45.02, 44.962, 44.911, 44.86, 44.796, 44.749, 44.683, 44.633, 44.567, 44.497, 44.393, 44.366, 44.192, 44.151, 44.053, 43.938, 43.845, 43.705, 43.606, 43.456, 43.335, 43.226, 43.11, 43.013, 42.912, 42.796, 42.662, 42.696, 42.391, 42.335, 42.38, 42.177, 41.972, 41.971, 41.959, 41.758, 41.58, 41.544, 41.515, 41.382, 41.253, 41.209, 41.195, 41.053, 40.912, 40.919, 40.899]\n",
      "Val FP Error(all epochs): 0.0 \n",
      " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "Epoch 00001: val_mae improved from inf to 46.79648, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00002: val_mae did not improve from 46.79648\n",
      "\n",
      "Epoch 00003: val_mae improved from 46.79648 to 46.79383, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00004: val_mae improved from 46.79383 to 46.78830, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00005: val_mae improved from 46.78830 to 46.78146, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00006: val_mae improved from 46.78146 to 46.77358, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00007: val_mae improved from 46.77358 to 46.76531, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00008: val_mae improved from 46.76531 to 46.75662, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00009: val_mae improved from 46.75662 to 46.74758, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00010: val_mae improved from 46.74758 to 46.73798, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00011: val_mae improved from 46.73798 to 46.72868, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00012: val_mae improved from 46.72868 to 46.71935, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00013: val_mae improved from 46.71935 to 46.71020, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00014: val_mae improved from 46.71020 to 46.70116, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00015: val_mae improved from 46.70116 to 46.69255, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00016: val_mae improved from 46.69255 to 46.68455, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00017: val_mae improved from 46.68455 to 46.67674, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00018: val_mae improved from 46.67674 to 46.66945, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_2.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00019: val_mae improved from 46.66945 to 46.66288, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00020: val_mae improved from 46.66288 to 46.65646, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00021: val_mae improved from 46.65646 to 46.65084, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00022: val_mae improved from 46.65084 to 46.64566, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00023: val_mae improved from 46.64566 to 46.64022, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00024: val_mae improved from 46.64022 to 46.63362, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00025: val_mae improved from 46.63362 to 46.62515, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00026: val_mae improved from 46.62515 to 46.61519, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00027: val_mae improved from 46.61519 to 46.60320, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00028: val_mae improved from 46.60320 to 46.59035, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00029: val_mae improved from 46.59035 to 46.57696, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00030: val_mae improved from 46.57696 to 46.56395, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00031: val_mae improved from 46.56395 to 46.55185, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00032: val_mae improved from 46.55185 to 46.54094, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00033: val_mae improved from 46.54094 to 46.53060, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00034: val_mae improved from 46.53060 to 46.51997, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00035: val_mae improved from 46.51997 to 46.50948, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00036: val_mae improved from 46.50948 to 46.49944, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00037: val_mae improved from 46.49944 to 46.48785, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00038: val_mae improved from 46.48785 to 46.47432, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00039: val_mae improved from 46.47432 to 46.46172, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00040: val_mae improved from 46.46172 to 46.44530, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00041: val_mae improved from 46.44530 to 46.42794, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00042: val_mae improved from 46.42794 to 46.41208, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00043: val_mae improved from 46.41208 to 46.39694, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00044: val_mae improved from 46.39694 to 46.37624, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00045: val_mae improved from 46.37624 to 46.35423, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00046: val_mae improved from 46.35423 to 46.33196, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00047: val_mae improved from 46.33196 to 46.30977, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00048: val_mae improved from 46.30977 to 46.28915, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00049: val_mae improved from 46.28915 to 46.27316, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00050: val_mae improved from 46.27316 to 46.25157, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00051: val_mae improved from 46.25157 to 46.22474, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00052: val_mae improved from 46.22474 to 46.20857, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00053: val_mae improved from 46.20857 to 46.19286, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00054: val_mae improved from 46.19286 to 46.17225, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00055: val_mae improved from 46.17225 to 46.14148, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00056: val_mae improved from 46.14148 to 46.09763, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00057: val_mae improved from 46.09763 to 46.06844, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00058: val_mae improved from 46.06844 to 46.02408, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00059: val_mae improved from 46.02408 to 45.97091, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_2.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00060: val_mae improved from 45.97091 to 45.92873, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00061: val_mae improved from 45.92873 to 45.87095, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00062: val_mae improved from 45.87095 to 45.84248, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00063: val_mae improved from 45.84248 to 45.79733, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00064: val_mae improved from 45.79733 to 45.73977, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00065: val_mae improved from 45.73977 to 45.68563, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00066: val_mae improved from 45.68563 to 45.66176, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00067: val_mae improved from 45.66176 to 45.59938, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00068: val_mae improved from 45.59938 to 45.54610, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00069: val_mae improved from 45.54610 to 45.52419, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00070: val_mae improved from 45.52419 to 45.46899, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00071: val_mae improved from 45.46899 to 45.42215, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00072: val_mae improved from 45.42215 to 45.38955, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00073: val_mae improved from 45.38955 to 45.36140, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00074: val_mae improved from 45.36140 to 45.29305, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00075: val_mae improved from 45.29305 to 45.28601, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00076: val_mae improved from 45.28601 to 45.22740, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00077: val_mae improved from 45.22740 to 45.15915, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00078: val_mae improved from 45.15915 to 45.10994, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00079: val_mae improved from 45.10994 to 45.03914, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00080: val_mae improved from 45.03914 to 44.99632, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00081: val_mae improved from 44.99632 to 44.94565, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00082: val_mae improved from 44.94565 to 44.90683, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00083: val_mae improved from 44.90683 to 44.85333, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00084: val_mae improved from 44.85333 to 44.78952, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00085: val_mae improved from 44.78952 to 44.74557, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00086: val_mae improved from 44.74557 to 44.65981, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00087: val_mae improved from 44.65981 to 44.63033, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00088: val_mae improved from 44.63033 to 44.54039, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00089: val_mae improved from 44.54039 to 44.42946, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00090: val_mae improved from 44.42946 to 44.40080, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00091: val_mae improved from 44.40080 to 44.35295, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00092: val_mae improved from 44.35295 to 44.28157, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00093: val_mae improved from 44.28157 to 44.22932, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00094: val_mae improved from 44.22932 to 44.14026, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00095: val_mae improved from 44.14026 to 44.06030, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00096: val_mae improved from 44.06030 to 43.97891, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00097: val_mae improved from 43.97891 to 43.93338, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00098: val_mae improved from 43.93338 to 43.87756, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00099: val_mae improved from 43.87756 to 43.84307, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_2.h5\n",
      "\n",
      "Epoch 00100: val_mae improved from 43.84307 to 43.74544, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_2.h5\n",
      "\n",
      "Lambda: 0.1 , Time: 0:02:28\n",
      "Train Error(all epochs): 43.233086 \n",
      " [46.094, 46.062, 46.045, 46.029, 46.013, 45.998, 45.984, 45.972, 45.96, 45.948, 45.938, 45.928, 45.918, 45.907, 45.897, 45.887, 45.877, 45.866, 45.855, 45.844, 45.833, 45.821, 45.809, 45.796, 45.783, 45.769, 45.755, 45.741, 45.726, 45.711, 45.697, 45.681, 45.666, 45.65, 45.634, 45.617, 45.6, 45.582, 45.565, 45.547, 45.528, 45.509, 45.49, 45.471, 45.451, 45.431, 45.41, 45.388, 45.366, 45.343, 45.32, 45.296, 45.272, 45.247, 45.222, 45.197, 45.169, 45.142, 45.114, 45.087, 45.058, 45.024, 44.995, 44.964, 44.934, 44.896, 44.866, 44.829, 44.795, 44.762, 44.721, 44.685, 44.645, 44.608, 44.561, 44.526, 44.479, 44.432, 44.394, 44.344, 44.3, 44.251, 44.202, 44.151, 44.097, 44.05, 43.99, 43.943, 43.888, 43.829, 43.778, 43.719, 43.666, 43.608, 43.55, 43.49, 43.424, 43.365, 43.295, 43.233]\n",
      "Train FP Error(all epochs): 0.0 \n",
      " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Val Error(all epochs): 43.74543762207031 \n",
      " [46.796, 46.797, 46.794, 46.788, 46.781, 46.774, 46.765, 46.757, 46.748, 46.738, 46.729, 46.719, 46.71, 46.701, 46.693, 46.685, 46.677, 46.669, 46.663, 46.656, 46.651, 46.646, 46.64, 46.634, 46.625, 46.615, 46.603, 46.59, 46.577, 46.564, 46.552, 46.541, 46.531, 46.52, 46.509, 46.499, 46.488, 46.474, 46.462, 46.445, 46.428, 46.412, 46.397, 46.376, 46.354, 46.332, 46.31, 46.289, 46.273, 46.252, 46.225, 46.209, 46.193, 46.172, 46.141, 46.098, 46.068, 46.024, 45.971, 45.929, 45.871, 45.842, 45.797, 45.74, 45.686, 45.662, 45.599, 45.546, 45.524, 45.469, 45.422, 45.39, 45.361, 45.293, 45.286, 45.227, 45.159, 45.11, 45.039, 44.996, 44.946, 44.907, 44.853, 44.79, 44.746, 44.66, 44.63, 44.54, 44.429, 44.401, 44.353, 44.282, 44.229, 44.14, 44.06, 43.979, 43.933, 43.878, 43.843, 43.745]\n",
      "Val FP Error(all epochs): 0.0 \n",
      " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_mae improved from inf to 46.80656, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00002: val_mae did not improve from 46.80656\n",
      "\n",
      "Epoch 00003: val_mae did not improve from 46.80656\n",
      "\n",
      "Epoch 00004: val_mae did not improve from 46.80656\n",
      "\n",
      "Epoch 00005: val_mae improved from 46.80656 to 46.80143, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00006: val_mae improved from 46.80143 to 46.78320, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00007: val_mae improved from 46.78320 to 46.76128, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00008: val_mae improved from 46.76128 to 46.73720, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00009: val_mae improved from 46.73720 to 46.71165, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00010: val_mae improved from 46.71165 to 46.68624, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00011: val_mae improved from 46.68624 to 46.66141, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00012: val_mae improved from 46.66141 to 46.63724, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00013: val_mae improved from 46.63724 to 46.61361, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00014: val_mae improved from 46.61361 to 46.59014, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00015: val_mae improved from 46.59014 to 46.56675, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00016: val_mae improved from 46.56675 to 46.54246, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00017: val_mae improved from 46.54246 to 46.51739, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00018: val_mae improved from 46.51739 to 46.49162, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00019: val_mae improved from 46.49162 to 46.46539, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00020: val_mae improved from 46.46539 to 46.43828, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00021: val_mae improved from 46.43828 to 46.40944, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00022: val_mae improved from 46.40944 to 46.37818, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00023: val_mae improved from 46.37818 to 46.34554, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00024: val_mae improved from 46.34554 to 46.31112, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00025: val_mae improved from 46.31112 to 46.27665, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00026: val_mae improved from 46.27665 to 46.24211, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00027: val_mae improved from 46.24211 to 46.20802, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00028: val_mae improved from 46.20802 to 46.17333, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00029: val_mae improved from 46.17333 to 46.13672, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00030: val_mae improved from 46.13672 to 46.09770, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00031: val_mae improved from 46.09770 to 46.05622, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00032: val_mae improved from 46.05622 to 46.01185, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00033: val_mae improved from 46.01185 to 45.96674, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00034: val_mae improved from 45.96674 to 45.92360, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00035: val_mae improved from 45.92360 to 45.88239, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00036: val_mae improved from 45.88239 to 45.84230, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00037: val_mae improved from 45.84230 to 45.80112, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00038: val_mae improved from 45.80112 to 45.75869, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00039: val_mae improved from 45.75869 to 45.71532, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00040: val_mae improved from 45.71532 to 45.66991, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00041: val_mae improved from 45.66991 to 45.62172, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00042: val_mae improved from 45.62172 to 45.57320, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00043: val_mae improved from 45.57320 to 45.52512, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_3.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00044: val_mae improved from 45.52512 to 45.47740, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00045: val_mae improved from 45.47740 to 45.43059, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00046: val_mae improved from 45.43059 to 45.38517, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00047: val_mae improved from 45.38517 to 45.34073, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00048: val_mae improved from 45.34073 to 45.29558, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00049: val_mae improved from 45.29558 to 45.25785, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00050: val_mae improved from 45.25785 to 45.22452, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00051: val_mae improved from 45.22452 to 45.18788, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00052: val_mae improved from 45.18788 to 45.15140, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00053: val_mae improved from 45.15140 to 45.11372, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00054: val_mae improved from 45.11372 to 45.07993, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00055: val_mae improved from 45.07993 to 45.04691, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00056: val_mae improved from 45.04691 to 45.01901, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00057: val_mae improved from 45.01901 to 44.98759, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00058: val_mae improved from 44.98759 to 44.95225, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00059: val_mae improved from 44.95225 to 44.93770, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00060: val_mae improved from 44.93770 to 44.91959, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00061: val_mae improved from 44.91959 to 44.89732, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00062: val_mae improved from 44.89732 to 44.83661, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00063: val_mae improved from 44.83661 to 44.82214, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00064: val_mae improved from 44.82214 to 44.79188, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00065: val_mae improved from 44.79188 to 44.74085, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00066: val_mae improved from 44.74085 to 44.69365, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00067: val_mae improved from 44.69365 to 44.66311, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00068: val_mae improved from 44.66311 to 44.63162, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00069: val_mae improved from 44.63162 to 44.59582, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00070: val_mae improved from 44.59582 to 44.55428, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00071: val_mae improved from 44.55428 to 44.53393, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00072: val_mae improved from 44.53393 to 44.49313, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00073: val_mae improved from 44.49313 to 44.44152, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00074: val_mae improved from 44.44152 to 44.42482, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00075: val_mae improved from 44.42482 to 44.39646, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00076: val_mae improved from 44.39646 to 44.34964, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00077: val_mae improved from 44.34964 to 44.33278, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00078: val_mae improved from 44.33278 to 44.31622, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00079: val_mae improved from 44.31622 to 44.28255, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00080: val_mae improved from 44.28255 to 44.23828, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00081: val_mae improved from 44.23828 to 44.21189, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00082: val_mae improved from 44.21189 to 44.14017, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00083: val_mae improved from 44.14017 to 44.11884, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00084: val_mae improved from 44.11884 to 44.09850, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_3.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00085: val_mae improved from 44.09850 to 44.04106, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00086: val_mae improved from 44.04106 to 44.00822, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00087: val_mae improved from 44.00822 to 44.00423, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00088: val_mae improved from 44.00423 to 43.93453, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00089: val_mae improved from 43.93453 to 43.86415, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00090: val_mae improved from 43.86415 to 43.82182, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00091: val_mae improved from 43.82182 to 43.80087, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00092: val_mae improved from 43.80087 to 43.74532, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00093: val_mae improved from 43.74532 to 43.70311, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00094: val_mae improved from 43.70311 to 43.70027, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00095: val_mae improved from 43.70027 to 43.67593, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00096: val_mae improved from 43.67593 to 43.63780, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00097: val_mae improved from 43.63780 to 43.57866, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00098: val_mae improved from 43.57866 to 43.53270, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00099: val_mae improved from 43.53270 to 43.41689, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_3.h5\n",
      "\n",
      "Epoch 00100: val_mae improved from 43.41689 to 43.37183, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/180/best_model_lambda_3.h5\n",
      "\n",
      "Lambda: 1 , Time: 0:02:53\n",
      "Train Error(all epochs): 42.03654 \n",
      " [46.087, 46.01, 45.953, 45.903, 45.863, 45.831, 45.802, 45.777, 45.755, 45.734, 45.714, 45.695, 45.676, 45.658, 45.64, 45.623, 45.605, 45.588, 45.57, 45.553, 45.535, 45.517, 45.497, 45.476, 45.454, 45.432, 45.411, 45.389, 45.368, 45.345, 45.323, 45.299, 45.275, 45.251, 45.225, 45.2, 45.174, 45.149, 45.124, 45.098, 45.071, 45.043, 45.015, 44.986, 44.955, 44.925, 44.894, 44.862, 44.831, 44.796, 44.763, 44.726, 44.693, 44.657, 44.621, 44.583, 44.544, 44.506, 44.463, 44.431, 44.38, 44.353, 44.304, 44.254, 44.218, 44.166, 44.111, 44.069, 44.032, 43.967, 43.919, 43.872, 43.829, 43.765, 43.712, 43.67, 43.607, 43.548, 43.496, 43.442, 43.384, 43.331, 43.232, 43.186, 43.135, 43.067, 42.993, 42.924, 42.872, 42.802, 42.72, 42.648, 42.581, 42.516, 42.44, 42.369, 42.269, 42.22, 42.127, 42.037]\n",
      "Train FP Error(all epochs): 0.0 \n",
      " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Val Error(all epochs): 43.371826171875 \n",
      " [46.807, 46.819, 46.821, 46.815, 46.801, 46.783, 46.761, 46.737, 46.712, 46.686, 46.661, 46.637, 46.614, 46.59, 46.567, 46.542, 46.517, 46.492, 46.465, 46.438, 46.409, 46.378, 46.346, 46.311, 46.277, 46.242, 46.208, 46.173, 46.137, 46.098, 46.056, 46.012, 45.967, 45.924, 45.882, 45.842, 45.801, 45.759, 45.715, 45.67, 45.622, 45.573, 45.525, 45.477, 45.431, 45.385, 45.341, 45.296, 45.258, 45.225, 45.188, 45.151, 45.114, 45.08, 45.047, 45.019, 44.988, 44.952, 44.938, 44.92, 44.897, 44.837, 44.822, 44.792, 44.741, 44.694, 44.663, 44.632, 44.596, 44.554, 44.534, 44.493, 44.442, 44.425, 44.396, 44.35, 44.333, 44.316, 44.283, 44.238, 44.212, 44.14, 44.119, 44.099, 44.041, 44.008, 44.004, 43.935, 43.864, 43.822, 43.801, 43.745, 43.703, 43.7, 43.676, 43.638, 43.579, 43.533, 43.417, 43.372]\n",
      "Val FP Error(all epochs): 0.0 \n",
      " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "Trainig set size: 180 , Time: 0:10:20 , best_lambda: 0.01 , min_  error: 40.899\n",
      "Test starts:  216 , ends:  298\n",
      "1/1 [==============================] - 1s 805ms/step\n",
      "average_error:  42.103 , fp_average_error:  0.0\n",
      "\n",
      "\n",
      "\n",
      "number_samples: 210 , New samples: 210\n",
      "Validation size: 42 , starts: 210 , ends: 251\n",
      "\n",
      "Epoch 00001: val_mae improved from inf to 48.65346, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/210/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00002: val_mae did not improve from 48.65346\n",
      "\n",
      "Epoch 00003: val_mae did not improve from 48.65346\n",
      "\n",
      "Epoch 00004: val_mae did not improve from 48.65346\n",
      "\n",
      "Epoch 00005: val_mae did not improve from 48.65346\n",
      "\n",
      "Epoch 00006: val_mae did not improve from 48.65346\n",
      "\n",
      "Epoch 00007: val_mae did not improve from 48.65346\n",
      "\n",
      "Epoch 00008: val_mae did not improve from 48.65346\n",
      "\n",
      "Epoch 00009: val_mae did not improve from 48.65346\n",
      "\n",
      "Epoch 00010: val_mae did not improve from 48.65346\n",
      "\n",
      "Epoch 00011: val_mae improved from 48.65346 to 48.65216, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/210/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00012: val_mae improved from 48.65216 to 48.63320, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/210/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00013: val_mae improved from 48.63320 to 48.61246, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/210/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00014: val_mae improved from 48.61246 to 48.59087, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/210/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00015: val_mae improved from 48.59087 to 48.56786, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/210/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00016: val_mae improved from 48.56786 to 48.54367, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/210/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00017: val_mae improved from 48.54367 to 48.51934, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/210/best_model_lambda_0.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00018: val_mae improved from 48.51934 to 48.49441, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/210/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00019: val_mae improved from 48.49441 to 48.46877, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/210/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00020: val_mae improved from 48.46877 to 48.44322, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/210/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00021: val_mae improved from 48.44322 to 48.41800, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/210/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00022: val_mae improved from 48.41800 to 48.39264, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/210/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00023: val_mae improved from 48.39264 to 48.36615, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/210/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00024: val_mae improved from 48.36615 to 48.33828, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/210/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00025: val_mae improved from 48.33828 to 48.31001, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/210/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00026: val_mae improved from 48.31001 to 48.28105, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/210/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00027: val_mae improved from 48.28105 to 48.25145, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/210/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00028: val_mae improved from 48.25145 to 48.22112, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/210/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00029: val_mae improved from 48.22112 to 48.18940, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/210/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00030: val_mae improved from 48.18940 to 48.15759, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/210/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00031: val_mae improved from 48.15759 to 48.12679, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/210/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00032: val_mae improved from 48.12679 to 48.09601, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/210/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00033: val_mae improved from 48.09601 to 48.06556, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/210/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00034: val_mae improved from 48.06556 to 48.03426, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/210/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00035: val_mae improved from 48.03426 to 47.99928, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/210/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00036: val_mae improved from 47.99928 to 47.95875, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/210/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00037: val_mae improved from 47.95875 to 47.91680, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/210/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00038: val_mae improved from 47.91680 to 47.87891, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/210/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00039: val_mae improved from 47.87891 to 47.84222, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/210/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00040: val_mae improved from 47.84222 to 47.80573, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/210/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00041: val_mae improved from 47.80573 to 47.77419, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/210/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00042: val_mae improved from 47.77419 to 47.74764, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/210/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00043: val_mae improved from 47.74764 to 47.71923, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/210/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00044: val_mae improved from 47.71923 to 47.69059, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/210/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00045: val_mae improved from 47.69059 to 47.66120, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/210/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00046: val_mae improved from 47.66120 to 47.62848, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/210/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00047: val_mae improved from 47.62848 to 47.59061, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/210/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00048: val_mae improved from 47.59061 to 47.55370, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/210/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00049: val_mae improved from 47.55370 to 47.52713, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/210/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00050: val_mae improved from 47.52713 to 47.48401, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/210/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00051: val_mae improved from 47.48401 to 47.46250, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/210/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00052: val_mae improved from 47.46250 to 47.43807, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/210/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00053: val_mae improved from 47.43807 to 47.42958, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/210/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00054: val_mae improved from 47.42958 to 47.40528, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/210/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00055: val_mae improved from 47.40528 to 47.39830, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/210/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00056: val_mae improved from 47.39830 to 47.35084, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/210/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00057: val_mae improved from 47.35084 to 47.34903, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/210/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00058: val_mae improved from 47.34903 to 47.32266, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/210/best_model_lambda_0.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00059: val_mae did not improve from 47.32266\n",
      "\n",
      "Epoch 00060: val_mae improved from 47.32266 to 47.29595, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/210/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00061: val_mae did not improve from 47.29595\n",
      "\n",
      "Epoch 00062: val_mae improved from 47.29595 to 47.24688, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/210/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00063: val_mae improved from 47.24688 to 47.21815, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/210/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00064: val_mae did not improve from 47.21815\n",
      "\n",
      "Epoch 00065: val_mae improved from 47.21815 to 47.13813, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/210/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00066: val_mae improved from 47.13813 to 47.11726, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/210/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00067: val_mae did not improve from 47.11726\n",
      "\n",
      "Epoch 00068: val_mae improved from 47.11726 to 47.05624, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/210/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00069: val_mae improved from 47.05624 to 47.01000, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/210/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00070: val_mae did not improve from 47.01000\n",
      "\n",
      "Epoch 00071: val_mae did not improve from 47.01000\n",
      "\n",
      "Epoch 00072: val_mae did not improve from 47.01000\n",
      "\n",
      "Epoch 00073: val_mae improved from 47.01000 to 46.95313, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/210/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00074: val_mae improved from 46.95313 to 46.94041, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/210/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00075: val_mae did not improve from 46.94041\n",
      "\n",
      "Epoch 00076: val_mae improved from 46.94041 to 46.89828, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/210/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00077: val_mae did not improve from 46.89828\n",
      "\n",
      "Epoch 00078: val_mae did not improve from 46.89828\n",
      "\n",
      "Epoch 00079: val_mae did not improve from 46.89828\n",
      "\n",
      "Epoch 00080: val_mae improved from 46.89828 to 46.88679, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/210/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00081: val_mae improved from 46.88679 to 46.82685, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/210/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00082: val_mae did not improve from 46.82685\n",
      "\n",
      "Epoch 00083: val_mae improved from 46.82685 to 46.76054, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/210/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00084: val_mae did not improve from 46.76054\n",
      "\n",
      "Epoch 00085: val_mae did not improve from 46.76054\n",
      "\n",
      "Epoch 00086: val_mae improved from 46.76054 to 46.71004, saving model to ML/data/pictures_100_100/testbed/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/pus/models/210/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00087: val_mae did not improve from 46.71004\n",
      "\n",
      "Epoch 00088: val_mae did not improve from 46.71004\n",
      "\n",
      "Epoch 00089: val_mae did not improve from 46.71004\n",
      "\n",
      "Epoch 00090: val_mae did not improve from 46.71004\n",
      "\n",
      "Epoch 00091: val_mae did not improve from 46.71004\n",
      "\n",
      "Epoch 00092: val_mae did not improve from 46.71004\n",
      "\n",
      "Epoch 00093: val_mae did not improve from 46.71004\n",
      "\n",
      "Epoch 00094: val_mae did not improve from 46.71004\n",
      "\n",
      "Epoch 00095: val_mae did not improve from 46.71004\n",
      "\n",
      "Epoch 00096: val_mae did not improve from 46.71004\n",
      "\n",
      "Epoch 00097: val_mae did not improve from 46.71004\n",
      "\n",
      "Epoch 00098: val_mae did not improve from 46.71004\n",
      "\n",
      "Epoch 00099: val_mae did not improve from 46.71004\n",
      "\n",
      "Epoch 00100: val_mae did not improve from 46.71004\n",
      "\n",
      "Lambda: 0.001 , Time: 0:02:58\n",
      "Train Error(all epochs): 42.638706 \n",
      " [46.089, 46.053, 46.018, 45.991, 45.969, 45.953, 45.941, 45.929, 45.918, 45.908, 45.898, 45.887, 45.876, 45.865, 45.854, 45.842, 45.831, 45.819, 45.807, 45.795, 45.783, 45.77, 45.757, 45.743, 45.729, 45.715, 45.7, 45.685, 45.67, 45.653, 45.637, 45.62, 45.602, 45.584, 45.565, 45.545, 45.524, 45.503, 45.482, 45.461, 45.439, 45.417, 45.394, 45.371, 45.346, 45.321, 45.296, 45.269, 45.242, 45.215, 45.186, 45.158, 45.128, 45.098, 45.067, 45.035, 45.002, 44.97, 44.935, 44.902, 44.867, 44.833, 44.793, 44.756, 44.721, 44.68, 44.641, 44.602, 44.56, 44.519, 44.477, 44.432, 44.389, 44.341, 44.294, 44.243, 44.19, 44.142, 44.084, 44.031, 43.971, 43.913, 43.857, 43.795, 43.732, 43.673, 43.604, 43.541, 43.473, 43.402, 43.336, 43.26, 43.189, 43.115, 43.045, 42.962, 42.883, 42.81, 42.723, 42.639]\n",
      "Train FP Error(all epochs): 0.0 \n",
      " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Val Error(all epochs): 46.710044860839844 \n",
      " [48.653, 48.681, 48.702, 48.713, 48.716, 48.713, 48.705, 48.696, 48.684, 48.669, 48.652, 48.633, 48.612, 48.591, 48.568, 48.544, 48.519, 48.494, 48.469, 48.443, 48.418, 48.393, 48.366, 48.338, 48.31, 48.281, 48.251, 48.221, 48.189, 48.158, 48.127, 48.096, 48.066, 48.034, 47.999, 47.959, 47.917, 47.879, 47.842, 47.806, 47.774, 47.748, 47.719, 47.691, 47.661, 47.628, 47.591, 47.554, 47.527, 47.484, 47.462, 47.438, 47.43, 47.405, 47.398, 47.351, 47.349, 47.323, 47.325, 47.296, 47.329, 47.247, 47.218, 47.236, 47.138, 47.117, 47.124, 47.056, 47.01, 47.015, 47.013, 47.046, 46.953, 46.94, 46.943, 46.898, 46.942, 46.91, 46.975, 46.887, 46.827, 46.853, 46.761, 46.779, 46.819, 46.71, 46.8, 46.792, 46.734, 46.894, 46.946, 46.981, 47.027, 47.107, 47.062, 47.058, 47.117, 47.123, 47.054, 46.959]\n",
      "Val FP Error(all epochs): 0.0 \n",
      " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "# CNN: support batching\n",
    "TEST, CONSERVE = True, True\n",
    "mini_batch = 16 if max(max_x, max_y) == 1000 else 256\n",
    "epochs = 35 if max(max_x, max_y) == 1000 else 100\n",
    "MAX_QUEUE_SIZE, WORKERS = 6, 1\n",
    "fp_penalty_coef, fn_penalty_coef = 1, 1\n",
    "hyper_metric, mode = \"val_mae\", 'min'  # the metric that hyper parameters are tuned with\n",
    "prev_sample = 0\n",
    "lambda_vec = [0.001, 0.01, 0.1, 1]  #0.003, 0.01, 0.03, 0.1, 0.3, 1, 3\n",
    "# lambda_vec = [0.01, 0.1, 1]\n",
    "# lambda_vec = [10]\n",
    "# MODEL_PATH = 'models/'\n",
    "average_diff_power, fp_mean_power = [],[] #[7.177, 8.088, 8.183], [3.438, 3.506, 2.662]\n",
    "best_lambda = []\n",
    "average_diff_power_conserve, fp_mean_power_conserve = [], []\n",
    "all_cnns = []\n",
    "if CONSERVE: # for conservative\n",
    "    prev_number_samples = [0] + number_samples[:-1]\n",
    "\n",
    "for num_sample_idx, number_sample in enumerate(number_samples):\n",
    "#     if num_sample_idx < 3:\n",
    "#         continue\n",
    "#     if num_sample_idx == 0:\n",
    "    if CONSERVE:\n",
    "        data_reg[prev_number_samples[num_sample_idx]:number_sample, -1] = data_reg[\n",
    "            prev_number_samples[num_sample_idx]:number_sample, -1] - 1 # conserv value\n",
    "    MODEL_PATH = '/'.join(image_dir.split('/')[:-1]) + '/models/' + str(number_sample)\n",
    "    if not os.path.exists(MODEL_PATH):\n",
    "        os.makedirs(MODEL_PATH)\n",
    "    MODEL_PATH += \"/best_model_lambda_\"\n",
    "    if True:\n",
    "        cnns = [cnn_model(10, lamb, 0) for lamb in lambda_vec]\n",
    "        for cnn in cnns:\n",
    "#             cnn.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse','mae', fp_mean])\n",
    "            cnn.compile(loss=custom_loss(fp_penalty_coef, fn_penalty_coef), \n",
    "                        optimizer='adam', \n",
    "                        metrics=['mse', 'mae', fp_mae])\n",
    "        checkpointers = [ModelCheckpoint(filepath=MODEL_PATH + str(lamb_idx)+ '.h5',\n",
    "                                         verbose=1, save_best_only=True, \n",
    "                                         monitor=hyper_metric,\n",
    "                                         mode=mode)\n",
    "                         for lamb_idx in range(len(lambda_vec))]\n",
    "    else:\n",
    "        cnns = []\n",
    "        cnns = [models.load_model(MODEL_PATH + str(lamb_idx) + '.h5', \n",
    "                                  custom_objects={ 'loss': custom_loss(fp_penalty_coef, fn_penalty_coef), \n",
    "                                                  'fp_mae': fp_mae }) \n",
    "                for lamb_idx in range(len(lambda_vec))]\n",
    "    number_start = time.time()\n",
    "    train_generator = DataBatchGenerator(dataset=data_reg[prev_sample:number_sample], batch_size=mini_batch,\n",
    "                                         start_idx=prev_sample, number_image_channels=number_image_channels,\n",
    "                                         max_x=max_x, max_y=max_y, float_memory_used=float_memory_used)\n",
    "    \n",
    "\n",
    "    val_size = math.ceil(number_sample * validation_size)\n",
    "    val_generator = DataBatchGenerator(dataset=data_reg[number_sample:number_sample+val_size], \n",
    "                                       batch_size=mini_batch,\n",
    "                                       start_idx=number_sample,\n",
    "                                       number_image_channels=number_image_channels,\n",
    "                                       max_x=max_x, max_y=max_y, \n",
    "                                       float_memory_used=float_memory_used)\n",
    "  \n",
    "    print('number_samples:', number_sample, \", New samples:\", number_sample - prev_sample)\n",
    "    print(\"Validation size:\", val_size, \", starts:\", number_sample, \", ends:\", number_sample + val_size - 1)\n",
    "    \n",
    "    for lamb_idx, lamb in enumerate(lambda_vec):\n",
    "#     for lamb_idx, lamb in enumerate(lambda_vec[:len(lambda_vec) - num_sample_idx//2]):\n",
    "#         if num_sample_idx == 3 and lamb_idx < 4:\n",
    "#             continue\n",
    "        lambda_start = time.time()\n",
    "        cnns[lamb_idx].fit(train_generator, epochs=epochs, verbose=0,\n",
    "                           validation_data=val_generator, \n",
    "                           shuffle=True, callbacks=[checkpointers[lamb_idx]], \n",
    "                           workers=WORKERS, max_queue_size=MAX_QUEUE_SIZE, \n",
    "                           use_multiprocessing=False)\n",
    "        \n",
    "        print(\"\\nLambda:\", lamb, \", Time:\", str(datetime.timedelta(seconds=int(time.time() - lambda_start))))\n",
    "        print(\"Train Error(all epochs):\", min(cnns[lamb_idx].history.history['mae']), '\\n', \n",
    "              [round(val, 3) for val in cnns[lamb_idx].history.history['mae']])\n",
    "        print(\"Train FP Error(all epochs):\", min(cnns[lamb_idx].history.history['fp_mae']), '\\n',\n",
    "              [round(val,3) for val in cnns[lamb_idx].history.history['fp_mae']])\n",
    "        print(\"Val Error(all epochs):\", min(cnns[lamb_idx].history.history['val_mae']), '\\n', \n",
    "              [round(val,3) for val in cnns[lamb_idx].history.history['val_mae']])\n",
    "        print(\"Val FP Error(all epochs):\", min(cnns[lamb_idx].history.history['val_fp_mae']), '\\n',\n",
    "              [round(val,3) for val in cnns[lamb_idx].history.history['val_fp_mae']])\n",
    "#     if num_sample_idx == 3:    \n",
    "#         models_min_mae = [8.27781, 8.23545, 8.20838, 7.74743]\n",
    "#         models_min_mae += [min(cnns[lamb_idx].history.history[hyper_metric]) for lamb_idx in range(4,lamb_idx+1)]\n",
    "#     else:\n",
    "    models_min_mae = [min(cnns[lam_idx].history.history[hyper_metric]) for\n",
    "                      lam_idx,_ in enumerate(lambda_vec)]\n",
    "    best_lamb_idx = models_min_mae.index(min(models_min_mae))\n",
    "    best_lambda.append(lambda_vec[best_lamb_idx])\n",
    "    print(\"\\nTrainig set size:\", number_sample, \", Time:\", str(datetime.timedelta(seconds=int(time.time() - \n",
    "                                                                                              number_start))),\n",
    "          \", best_lambda:\", lambda_vec[best_lamb_idx], \", min_\" , (\"fp_\" if hyper_metric == \"val_fp_mae\" else \"\"),\n",
    "          \"error:\", round(min(models_min_mae), 3))\n",
    "    all_cnns.append(cnns)\n",
    "    del cnns, train_generator, val_generator, checkpointers\n",
    "    \n",
    "    if TEST:\n",
    "        # evaluating test images\n",
    "        best_model = None\n",
    "        best_model = models.load_model(MODEL_PATH + str(best_lamb_idx) + '.h5', \n",
    "                                       custom_objects={ 'loss': custom_loss(fp_penalty_coef, fn_penalty_coef), \n",
    "                                                       'fp_mae': fp_mae,\n",
    "                                                      'mae':'mae', 'mse':'mse'})\n",
    "        test_generator = DataBatchGenerator(dataset=data_reg[number_sample + val_size:], \n",
    "                                            batch_size=mini_batch,\n",
    "                                            start_idx=number_sample + val_size, \n",
    "                                            number_image_channels=number_image_channels,\n",
    "                                            max_x=max_x, max_y=max_y, float_memory_used=float_memory_used)\n",
    "\n",
    "        print(\"Test starts: \", number_sample + val_size, \", ends: \", data_reg.shape[0] - 1)\n",
    "        time.sleep(1)\n",
    "        test_res = best_model.evaluate(test_generator, verbose=1, \n",
    "                                       workers=WORKERS, max_queue_size=MAX_QUEUE_SIZE, use_multiprocessing=False)\n",
    "        \n",
    "        test_mae_idx, test_fp_mae_idx = [best_model.metrics_names.index(mtrc) \n",
    "                                         for mtrc in ['mae','fp_mae']]\n",
    "        test_mae, test_fp_mae = test_res[test_mae_idx], test_res[test_fp_mae_idx]\n",
    "        average_diff_power.append(round(test_mae, 3))\n",
    "        fp_mean_power.append(round(test_fp_mae, 3))\n",
    "        print('average_error: ', average_diff_power[-1], ', fp_average_error: ', \n",
    "              fp_mean_power[-1])\n",
    "        \n",
    "        if False:\n",
    "            test_generator_conserve = DataBatchGenerator(dataset=data_reg[number_sample + val_size:], \n",
    "                                                         batch_size=mini_batch,\n",
    "                                                         start_idx=number_sample + val_size, \n",
    "                                                         number_image_channels=number_image_channels,\n",
    "                                                         max_x=max_x, max_y=max_y, \n",
    "                                                         float_memory_used=float_memory_used, \n",
    "                                                         conserve=1)\n",
    "            test_res_conserve = best_model.evaluate(test_generator_conserve, verbose=1, \n",
    "                                                    workers=WORKERS, max_queue_size=MAX_QUEUE_SIZE, \n",
    "                                                    use_multiprocessing=False)\n",
    "            test_mae_cons, test_fp_mae_cons = test_res_conserve[test_mae_idx], test_res_conserve[test_fp_mae_idx]\n",
    "            average_diff_power_conserve.append(round(test_mae_cons, 3))\n",
    "            fp_mean_power_conserve.append(round(test_fp_mae_cons, 3))\n",
    "            print('Conserve, average_error: ', average_diff_power_conserve[-1], ', fp_average_error: ',\n",
    "                 fp_mean_power_conserve[-1])\n",
    "        print(\"\\n\\n\")\n",
    "\n",
    "        \n",
    "        var_f = open('/'.join(image_dir.split('/')[:-1]) +  '/' + intensity_degradation + '_' + str(slope) + '_' + \n",
    "                     dtime + \".dat\", \"wb\") # file for saving results\n",
    "        pickle.dump([average_diff_power, fp_mean_power, number_samples, best_lambda, \n",
    "                     dataset_name, average_diff_power_conserve, fp_mean_power_conserve],\n",
    "                    file=var_f)\n",
    "        var_f.close()\n",
    "        del best_model, test_generator\n",
    "#     prev_sample = number_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(number_samples)\n",
    "print(average_diff_power)\n",
    "print(fp_mean_power)\n",
    "# print(best_lambda)\n",
    "print(average_diff_power_conserve)\n",
    "print(fp_mean_power_conserve)\n",
    "print(best_lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cnns[0][0].history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = all_cnns[0][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    checkpointers = ModelCheckpoint(filepath=MODEL_PATH + str(0)+ 'new.h5',\n",
    "                                         verbose=1, save_best_only=True, \n",
    "                                         monitor=hyper_metric,\n",
    "                                         mode=mode)\n",
    "    number_start = time.time()\n",
    "    train_generator = DataBatchGenerator(dataset=data_reg[prev_sample:number_sample], batch_size=mini_batch,\n",
    "                                         start_idx=prev_sample, number_image_channels=number_image_channels,\n",
    "                                         max_x=max_x, max_y=max_y, float_memory_used=float_memory_used)\n",
    "    \n",
    "\n",
    "    val_size = math.ceil(number_sample * validation_size)\n",
    "    val_generator = DataBatchGenerator(dataset=data_reg[number_sample:number_sample+val_size], \n",
    "                                       batch_size=mini_batch,\n",
    "                                       start_idx=number_sample,\n",
    "                                       number_image_channels=number_image_channels,\n",
    "                                       max_x=max_x, max_y=max_y, \n",
    "                                       float_memory_used=float_memory_used)\n",
    "  \n",
    "    print('number_samples:', number_sample, \", New samples:\", number_sample - prev_sample)\n",
    "    print(\"Validation size:\", val_size, \", starts:\", number_sample, \", ends:\", number_sample + val_size - 1)\n",
    "    best_model.fit(train_generator, epochs=80, verbose=0,\n",
    "                   validation_data=val_generator, shuffle=True, callbacks=[checkpointers], \n",
    "                   workers=WORKERS, max_queue_size=MAX_QUEUE_SIZE, \n",
    "                   use_multiprocessing=False, initial_epoch=60)\n",
    "    print(\"Train Error(all epochs):\", min(best_model.history.history['mae']), '\\n',\n",
    "          [round(val, 3) for val in best_model.history.history['mae']])\n",
    "    print(\"Train FP Error(all epochs):\", min(best_model.history.history['fp_mae']), '\\n',\n",
    "          [round(val,3) for val in best_model.history.history['fp_mae']])\n",
    "    print(\"Val Error(all epochs):\", min(best_model.history.history['val_mae']), '\\n', \n",
    "          [round(val,3) for val in best_model.history.history['val_mae']])\n",
    "    print(\"Val FP Error(all epochs):\", min(best_model.history.history['val_fp_mae']), '\\n',\n",
    "          [round(val,3) for val in best_model.history.history['val_fp_mae']])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_best_model = models.load_model(MODEL_PATH + str(0) + 'new.h5', \n",
    "                               custom_objects={ 'loss': custom_loss(fp_penalty_coef, fn_penalty_coef), \n",
    "                                               'fp_mae': fp_mae,\n",
    "                                               'mae':'mae', 'mse':'mse'})\n",
    "test_generator = DataBatchGenerator(dataset=data_reg[number_sample + val_size:], \n",
    "                                            batch_size=mini_batch,\n",
    "                                            start_idx=number_sample + val_size, \n",
    "                                            number_image_channels=number_image_channels,\n",
    "                                            max_x=max_x, max_y=max_y, float_memory_used=float_memory_used)\n",
    "\n",
    "print(\"Test starts: \", number_sample + val_size, \", ends: \", data_reg.shape[0] - 1)\n",
    "time.sleep(1)\n",
    "test_res = best_best_model.evaluate(test_generator, verbose=1, \n",
    "                                    workers=WORKERS, max_queue_size=MAX_QUEUE_SIZE,\n",
    "                                    use_multiprocessing=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.fit(train_generator, epochs=15, verbose=0,\n",
    "               validation_data=val_generator, shuffle=True, callbacks=[checkpointers], \n",
    "               workers=WORKERS, max_queue_size=MAX_QUEUE_SIZE, \n",
    "               use_multiprocessing=False, initial_epoch=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_min_mae = [8.27781, 8.23545, 8.20838]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_diff_power = [8.166, 7.844, 7.592]\n",
    "fp_mean_power = [4.56, 4.42, 4.37]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# CNN: support batching\n",
    "TEST = True\n",
    "mini_batch, epochs = 16, 30\n",
    "batch_size = (batch_size // mini_batch) * mini_batch\n",
    "prev_sample = 0\n",
    "lambda_vec = [0, 0.001, 0.003, 0.01, 0.03, 0.1, 0.3, 1, 3, 10]  #, 0.3, 1, 3, 10\n",
    "average_diff_power, fp_mean_power = [], []\n",
    "cnns = [cnn_model(10, lamb, 0) for lamb in lambda_vec]\n",
    "for cnn in cnns:\n",
    "    cnn.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse','mae'])\n",
    "for number_sample in number_samples:\n",
    "    number_start = time.time()\n",
    "    current_sample = number_sample - prev_sample\n",
    "    train_samples = [batch_size] * (current_sample//batch_size) + ([current_sample%batch_size] if \n",
    "                                                                    current_sample%batch_size else [])\n",
    "    val_size = math.ceil(number_sample * validation_size)\n",
    "#     val_samples = [batch_size] * (val_size//batch_size) + ([val_size%batch_size] if \n",
    "#                                                                val_size%batch_size else [])\n",
    "    \n",
    "    print('number_samples:', number_sample)\n",
    "    print(\"Train batches:\", train_samples)\n",
    "    for i, train_sample in enumerate(train_samples):\n",
    "        print(\"Train batch#:\", i, \", batch size:\", train_sample, \", starts:\", prev_sample + i * batch_size,\n",
    "                      \", ends:\", prev_sample + i * batch_size + train_sample - 1)\n",
    "    print(\"Validation size:\", val_size, \", starts:\", number_sample, \", ends:\", number_sample + val_size - 1)\n",
    "#     print(\"Validation Batches:\", val_samples)\n",
    "#     for i, val_sample in enumerate(val_samples):\n",
    "#         print(\"Validation batch#:\", i, \", batch size:\", val_sample, \", starts:\", number_sample + i * batch_size,\n",
    "#                       \", ends:\", number_sample + i * batch_size + val_sample - 1)\n",
    "        \n",
    "    min_error = float('inf')\n",
    "    best_model, best_lam = None, None\n",
    "    for lamb_idx, lamb in enumerate(lambda_vec):\n",
    "        lambda_start = time.time()\n",
    "        \n",
    "#         cnn = cnn_model(10, lamb, 0)\n",
    "#         cnn.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse','mae'])\n",
    "        \n",
    "        # training on all batches\n",
    "        for i, train_sample in enumerate(train_samples):\n",
    "#             if lamb_idx == 0:\n",
    "#                 print(\"Train batch#:\", i, \", batch size:\", train_sample, \", starts:\", prev_sample + i * batch_size,\n",
    "#                       \", ends:\", prev_sample + i * batch_size + train_sample - 1)\n",
    "            x_train = np.empty((train_sample, number_image_channels, max_x, max_y), dtype=float_memory_used)\n",
    "            y_train = np.empty((train_sample), dtype=float_memory_used)\n",
    "            for image_num in range(prev_sample + i * batch_size, prev_sample + i * batch_size + train_sample):\n",
    "                x_train[(image_num - prev_sample) % batch_size] = read_image(image_num)\n",
    "                y_train[(image_num - prev_sample) % batch_size] = np.asarray(data_reg[image_num][-1], \n",
    "                                                                             dtype=float_memory_used)\n",
    "            cnns[lamb_idx].fit(x_train, y_train, epochs=epochs, verbose=2, batch_size=mini_batch,\n",
    "                               validation_split=0.2, \n",
    "                               shuffle=True)\n",
    "            del x_train, y_train\n",
    "#         if lamb_idx == 0:\n",
    "#             print(\"Validation size:\", val_size, \", starts:\", number_sample, \", ends:\", \n",
    "#                   number_sample + val_size - 1)\n",
    "        print(\"\\nLambda:\", lamb)\n",
    "        print(\"Train Error(all epochs): \", cnns[lamb_idx].history.history['mae'])\n",
    "        \n",
    "        # validating\n",
    "        val_mae, val_fp_mae = 0.0, 0.0\n",
    "#         for i, val_sample in enumerate(val_samples):\n",
    "#             x_val = np.empty((val_sample, number_image_channels, max_x, max_y), dtype=float_memory_used)\n",
    "#             for image_num in range(val_sample):\n",
    "#                 x_val[image_num] = read_image(image_num + number_sample + i * batch_size)\n",
    "#             yp_val = cnns[lamb_idx].predict(x_val)\n",
    "        for image_num in range(val_size):\n",
    "            val_y = data_reg[image_num + number_sample][-1]\n",
    "            image = read_image(image_num + number_sample)\n",
    "            val_yp = cnns[lamb_idx].predict(image)[0][0]\n",
    "#             for image_num in range(val_sample):\n",
    "#                 val_yp = yp_val[image_num][0]\n",
    "#                 val_y = data_reg[image_num + number_sample + i * batch_size][-1]\n",
    "            val_mae += abs(val_y - val_yp)\n",
    "            if val_yp > val_y:\n",
    "                val_fp_mae += abs(val_yp - val_y)\n",
    "        val_mae /= val_size\n",
    "        val_fp_mae /= val_size\n",
    "        print(\"Val Error:\", round(val_mae, 3), \", Time:\", str(datetime.timedelta(seconds=int(time.time() - lambda_start))))\n",
    "        if val_mae < min_error:\n",
    "            min_error = val_mae\n",
    "            best_model = cnns[lamb_idx]\n",
    "            best_lam = lamb\n",
    "            best_lam_idx = lamb_idx\n",
    "    print(\"\\nTrainig set size:\", number_sample, \", Time:\", str(datetime.timedelta(seconds=int(time.time() - number_start)))\n",
    "          ,\", best_lambda:\", best_lam, \", min_error:\", round(min_error, 3))\n",
    "    \n",
    "    \n",
    "    if TEST:\n",
    "        # evaluating test images\n",
    "        sum_mae, sum_fp_mae = 0, 0\n",
    "        test_size = 0\n",
    "\n",
    "        y_test_p = np.empty((data_reg.shape[0] - (number_sample + val_size)), dtype=float_memory_used)\n",
    "    #     test_size = data_reg.shape[0] - (number_sample + val_size)\n",
    "    #     test_samples = [batch_size] * (test_size//batch_size) + ([test_size%batch_size] if \n",
    "    #                                                              test_size%batch_size else [])\n",
    "        print(\"Test starts: \", number_sample + val_size, \", ends: \", data_reg.shape[0] - 1)\n",
    "        time.sleep(1)\n",
    "    #     for i, test_sample in tqdm.tqdm(enumerate(test_samples)):\n",
    "    #         x_test = np.empty((test_sample, number_image_channels, max_x, max_y), dtype=float_memory_used)\n",
    "    #         for image_num in range(test_sample):\n",
    "    #             x_test[image_num] = read_image(number_sample + val_size + i * batch_size)\n",
    "    #         yp_test = cnns[best_lam_idx].predict(x_test)\n",
    "    #         for image_num in range(test_sample):\n",
    "    #             test_y = data_reg[number_sample + val_size + i * batch_size][-1]\n",
    "    #             test_yp = yp_test[image_num][0]\n",
    "    #             sum_mae += abs(test_yp - test_y)\n",
    "    #             if test_yp > test_y:\n",
    "    #                 sum_fp_mae += abs(test_yp - test_y)\n",
    "\n",
    "        for test_num in tqdm.tqdm(range(number_sample + val_size, data_reg.shape[0])):\n",
    "            test_size += 1\n",
    "            test_image = read_image(test_num)\n",
    "            test_y = data_reg[test_num][-1]\n",
    "            test_yp = best_model.predict(test_image)[0][0]\n",
    "            y_test_p[test_num - (number_sample + val_size)] = test_yp\n",
    "            sum_mae += abs(test_yp - test_y)\n",
    "            if test_yp > test_y:\n",
    "                sum_fp_mae += abs(test_yp - test_y)\n",
    "        fp_mean_power.append(round(sum_fp_mae/ test_size, 3))\n",
    "        average_diff_power.append(round(sum_mae / test_size, 3))\n",
    "        print('average_error: ', average_diff_power[-1], ', fp_average_error: ', \n",
    "              fp_mean_power[-1])\n",
    "        print(\"\\n\\n\")\n",
    "        var_f = open('/'.join(image_dir.split('/')[:-1]) +  '/' + intensity_degradation + '_' + str(slope) + '_' + \n",
    "                     dtime + \".dat\", \"wb\") # file for saving results\n",
    "        pickle.dump([average_diff_power, fp_mean_power, number_samples], file=var_f)\n",
    "        var_f.close()\n",
    "    prev_sample = number_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnns[1].weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# CNN: support batching\n",
    "prev_sample = 0\n",
    "# number_samples = [120, 200, 700]\n",
    "lambda_vec = [0, 0.001]  #0.003, 0.01, 0.03, 0.1, 0.3, 1, 3, 10\n",
    "average_diff_power, fp_mean_power = [], []\n",
    "cnns = [cnn_model(10, lamb, 0) for lamb in lambda_vec]\n",
    "for cnn in cnns:\n",
    "    cnn.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse','mae'])\n",
    "for number_sample in number_samples:\n",
    "    current_sample = number_sample - prev_sample\n",
    "    print(\"prev: \", prev_sample, \", now: \", number_sample, \", size\", current_sample) \n",
    "    train_samples = [batch_size] * (current_sample//batch_size) + ([current_sample%batch_size] if \n",
    "                                                                    current_sample%batch_size else [])\n",
    "    print(train_samples)\n",
    "    \n",
    "    min_error = float('inf')\n",
    "    best_model, best_lam = None, None\n",
    "    for lamb_idx, lamb in enumerate(lambda_vec):\n",
    "        print(\"Lambda:\", lamb)\n",
    "#         cnn = cnn_model(10, lamb, 0)\n",
    "#         cnn.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse','mae'])\n",
    "        \n",
    "        # training on all batches\n",
    "                                    \n",
    "        for i, train_sample in enumerate(train_samples):\n",
    "            for image_num in range(prev_sample + i * batch_size, prev_sample + i * batch_size + train_sample):\n",
    "                print(prev_sample + i * batch_size, prev_sample + i * batch_size + train_sample)\n",
    "                print((prev_sample + i * batch_size - prev_sample) % batch_size, \n",
    "                      (prev_sample + i * batch_size + train_sample - prev_sample)% batch_size)\n",
    "                break\n",
    "\n",
    "        \n",
    "        # validating\n",
    "        print(\"validating\")\n",
    "        val_size = math.ceil(number_sample * validation_size)\n",
    "        for image_num in range(val_size):\n",
    "            print(number_sample, val_size + number_sample)\n",
    "            break\n",
    "     \n",
    "    print(\"Test\") \n",
    "    \n",
    "    # evaluating test images\n",
    "\n",
    "    \n",
    "    for test_num in tqdm.tqdm(range(number_sample + val_size, data_reg.shape[0])):\n",
    "        print(number_sample + val_size, data_reg.shape[0])\n",
    "        break\n",
    "    prev_sample = number_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_f = open('/'.join(image_dir.split('/')[:-1]) +  '/' + 'best_cnn_4000samples' + intensity_degradation + '_' + str(slope) + '_' + \n",
    "                 dtime + \".dat\", \"wb\") # file for saving results\n",
    "pickle.dump(best_model, file=var_f)\n",
    "var_f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## use self-training\n",
    "unlabeled_train_samples = [batch_size] * (len(y_test_p)//batch_size) + ([len(y_test_p)%batch_size] if len(y_test_p)%batch_size else [])\n",
    "labeled_train_samples = [batch_size] * (number_sample//batch_size) + ([number_sample%batch_size] if number_sample%batch_size else [])   \n",
    "min_min_error = float('inf')\n",
    "best_best_model, best_best_lam = None, None\n",
    "for lamb in tqdm.tqdm(lambda_vec):\n",
    "    print(\"Lambda:\", lamb)\n",
    "    cnn = cnn_model(10, lamb, 0)\n",
    "    cnn.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse','mae'])\n",
    "#     cnn.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse','mae'])\n",
    "        \n",
    "    # training on all batches\n",
    "    # training on all batches\n",
    "    for i, train_sample in tqdm.tqdm(enumerate(labeled_train_samples)):\n",
    "        x_train = np.empty((train_sample, number_image_channels, max_x, max_y), dtype=float_memory_used)\n",
    "        y_train = np.empty((train_sample), dtype=float_memory_used)\n",
    "        for image_num in range(i * batch_size, i * batch_size + train_sample):\n",
    "            x_train[image_num % batch_size] = read_image(image_num)\n",
    "            y_train[image_num % batch_size] = np.asarray(data_reg[image_num][-1], dtype=float_memory_used)\n",
    "        cnn.fit(x_train, y_train, epochs=6, verbose=0, batch_size=1, validation_split=0.0)\n",
    "        del x_train, y_train\n",
    "            \n",
    "    for i, train_sample in tqdm.tqdm(enumerate(unlabeled_train_samples)):\n",
    "        x_train = np.empty((train_sample, number_image_channels, max_x, max_y), dtype=float_memory_used)\n",
    "        y_train = np.empty((train_sample), dtype=float_memory_used)\n",
    "        for image_num in range(i * batch_size + number_sample + val_size, i * batch_size + number_sample + val_size + train_sample):\n",
    "            x_train[(image_num-number_sample - val_size) % batch_size] = read_image(image_num)\n",
    "            y_train[(image_num-number_sample - val_size) % batch_size] = np.asarray(y_test_p[image_num-(number_sample + val_size)], dtype=float_memory_used)\n",
    "        cnn.fit(x_train, y_train, epochs=3, verbose=0, batch_size=1, validation_split=0.0)\n",
    "        del x_train, y_train\n",
    "        \n",
    "    # validating\n",
    "    val_size = math.ceil(number_sample * validation_size)\n",
    "    val_mae, val_fp_mae = 0.0, 0.0\n",
    "    for image_num in range(val_size):\n",
    "        val_y = data_reg[image_num + number_sample][-1]\n",
    "        image = read_image(image_num + number_sample)\n",
    "        val_yp = cnn.predict(image)[0][0]\n",
    "        val_mae += abs(val_y - val_yp)\n",
    "        if val_yp > val_y:\n",
    "            val_fp_mae += abs(val_yp - val_y)\n",
    "    val_mae /= val_size\n",
    "    val_fp_mae /= val_size\n",
    "    print(val_mae)\n",
    "    if val_mae < min_min_error:\n",
    "        min_min_error = val_mae\n",
    "        best_best_model = cnn\n",
    "        best_best_lam = lamb\n",
    "    sum_mae, sum_fp_mae = 0, 0\n",
    "    test_size = 0\n",
    "    \n",
    "for test_num in tqdm.tqdm(range(number_sample + val_size, data_reg.shape[0])):\n",
    "    test_size += 1\n",
    "    test_image = read_image(test_num)\n",
    "    test_y = data_reg[test_num][-1]\n",
    "    test_yp = best_best_model.predict(test_image)[0][0]\n",
    "#     y_test_p[test_num - (number_sample + val_size)] = test_yp\n",
    "    sum_mae += abs(test_yp - test_y)\n",
    "    if test_yp > test_y:\n",
    "        sum_fp_mae += abs(test_yp - test_y)\n",
    "fp_mean_power.append(round(sum_fp_mae/ test_size, 3))\n",
    "average_diff_power.append(round(sum_mae / test_size, 3))\n",
    "print('number_samples: ', number_sample, ', average_error: ', average_diff_power[-1], ' fp_average_error: ', \n",
    "      fp_mean_power[-1])\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "6.285, 6.366, 6.45, 6.454, 6.382, 6.26, 6.49, 6.224, 6.052, 5.87, 4.915, 4.836"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN\n",
    "prev_sample = 0\n",
    "lambda_vec = [0, 0.001, 0.003, 0.01, 0.03, 0.1]\n",
    "max_train_samples = math.ceil(number_samples[-1] * (1 + validation_size))\n",
    "x_train = np.empty((max_train_samples, number_image_channels, max_x, max_y), dtype=float_memory_used)\n",
    "# x_train1 = np.empty((max_train_samples, 1, max_x, max_y), dtype=float_memory_used)\n",
    "# x_train2 = np.empty((max_train_samples, 1, max_x, max_y), dtype=float_memory_used)\n",
    "y_train = np.empty((max_train_samples), dtype=float_memory_used)\n",
    "average_diff_power, fp_mean_power = [], []\n",
    "for number_sample in number_samples:\n",
    "    sample = math.ceil(number_sample * (1 + validation_size))\n",
    "    for image_num in range(prev_sample, sample):\n",
    "        prev_sample = sample\n",
    "        if style == \"image_intensity\":\n",
    "            image = plt.imread(image_dir + '/image' + str(image_num)+'.png')\n",
    "            image = np.swapaxes(image, 0, 2)\n",
    "            x_train[image_num] = np.array(image[:number_image_channels], dtype=float_memory_used).reshape(1, number_image_channels, max_x, max_y)\n",
    "            del image\n",
    "        elif  style == \"raw_power_min_max_norm\" or style == \"raw_power_zscore_norm\":\n",
    "            x_train[image_num] = np.load(image_dir + '/image' + str(image_num)+'.npy')\n",
    "#             image = np.load(image_dir + '/image' + str(image_num)+'.npy')\n",
    "#             x_train1[image_num][0] = image[0][0]\n",
    "#             x_train2[image_num][0] = image[0][1]\n",
    "        y_train[image_num] = np.asarray(data_reg[image_num][-1], dtype=float_memory_used)\n",
    "        if image_num + 1 % 100 == 0:\n",
    "            print(image_num)\n",
    "#     cnn = cnn_model(7, 0, 0)\n",
    "#     cnn.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse','mae'])\n",
    "#     cnn.fit(x_train[:sample], y_train[:sample], epochs=5, verbose=1, batch_size=1, validation_split=validation_size/\n",
    "#             (validation_size + 1))\n",
    "    \n",
    "    min_error = float('inf')\n",
    "    best_model, best_lam = None, None\n",
    "    for lamb in lambda_vec:\n",
    "        print(\"Lambda:\", lamb)\n",
    "        cnn = cnn_model(10, lamb, 0)\n",
    "        cnn.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse','mae'])\n",
    "#         cnn.fit([x_train1[:sample], x_train2[:sample]], y_train[:sample], epochs=6, verbose=1, batch_size=1, validation_split=validation_size/\n",
    "#                 (validation_size + 1))\n",
    "        cnn.fit(x_train[:sample], y_train[:sample], epochs=6, verbose=0, batch_size=1, validation_split=validation_size/\n",
    "                (validation_size + 1))\n",
    "        if cnn.history.history['val_mean_absolute_error'][-1] < min_error:\n",
    "            min_error = cnn.history.history['val_mean_absolute_error'][-1]\n",
    "            best_model = cnn\n",
    "            best_lam = lamb\n",
    "    print(\"best_lambda, \", best_lam, \"min_error\", min_error)    \n",
    "    # evaluating test images\n",
    "    sum_mae, sum_fp_mae = 0, 0\n",
    "    test_size = 0\n",
    "#     for test_num in range(max_train_samples, data_reg.shape[0]):\n",
    "    for test_num in range(sample, data_reg.shape[0]):\n",
    "        test_size += 1\n",
    "        if style == \"image_intensity\":\n",
    "            test_image = plt.imread(image_dir + '/image' + str(test_num) + '.png')\n",
    "            test_image = np.swapaxes(test_image, 0, 2)\n",
    "            test_image = np.array(test_image[:number_image_channels]).reshape(1, number_image_channels, max_x, max_y)\n",
    "        elif  style == \"raw_power_min_max_norm\" or style == \"raw_power_zscore_norm\":\n",
    "            test_image = np.load(image_dir + '/image' + str(test_num)+'.npy')\n",
    "        test_y = data_reg[test_num][-1]\n",
    "        test_yp = best_model.predict(test_image)[0][0]\n",
    "        sum_mae += abs(test_yp - test_y)\n",
    "        if test_yp > test_y:\n",
    "            sum_fp_mae += abs(test_yp - test_y)\n",
    "        if test_num % 500 == 0:\n",
    "            print('test: ', test_num)\n",
    "    fp_mean_power.append(round(sum_fp_mae/ test_size, 3))\n",
    "    average_diff_power.append(round(sum_mae / test_size, 3))\n",
    "    print('number_samples: ', number_sample, ', average_error: ', average_diff_power[-1], ' fp_average_error: ', fp_mean_power[-1])\n",
    "    print(\"\\n\")\n",
    "    var_f = open('/'.join(image_dir.split('/')[:-1]) +  '/' + intensity_degradation + '_' + str(slope) + '_' + dtime + \".dat\", \"wb\") # file for saving results\n",
    "    pickle.dump([average_diff_power, fp_mean_power, number_samples], file=var_f)\n",
    "    var_f.close()       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_diff_power[8], average_diff_power[9] = average_diff_power[9], average_diff_power[8]\n",
    "# fp_mean_power = fp_mean_power[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shapee = Input(shape=(number_image_channels, max_x, max_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shapee[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = cnn_model(1, 0)\n",
    "cnn.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse','mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cnn.history.history['val_mean_absolute_error'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = cnn_model(10, 0, 0)\n",
    "cnn.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse','mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cnn.fit(x_train[:sample], y_train[:sample], epochs=5, verbose=1, batch_size=1, validation_split=validation_size/\n",
    "            (validation_size + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_vec = [0, 0.001, 0.003, 0.01, 0.03, 0.1, 0.3, 1, 3]\n",
    "min_error = float('inf')\n",
    "best_model, best_lam = None, None\n",
    "for lamb in lambda_vec:\n",
    "    print(\"Lambda:\", lamb)\n",
    "    cnn = cnn_model(15, lamb, 0)\n",
    "    cnn.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse','mae'])\n",
    "    cnn.fit(x_train[:sample], y_train[:sample], epochs=5, verbose=1, batch_size=1, validation_split=validation_size/\n",
    "            (validation_size + 1))\n",
    "    if cnn.history.history['val_mean_absolute_error'][-1] < min_error:\n",
    "        min_error = cnn.history.history['val_mean_absolute_error'][-1]\n",
    "        best_model = cnn\n",
    "        best_lam = lamb\n",
    "    print(\"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_lam)\n",
    "print(best_model.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# just run to dispaly the image. First change return line from create_image\n",
    "aa = np.swapaxes(np.append(np.array(x_train[50]), np.zeros((2,max_x, max_y), dtype=float_memory_used), axis=0), 0, 2)\n",
    "plt.imshow(aa)\n",
    "# plt.imsave('image.png', aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_diff_power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this cell to read saved variables\n",
    "var_ff = open('ML/data/pictures_1000_1000/log_201912_0705_37.txt', 'rb')\n",
    "[average_diff_power_1, fp_mean_power_1, number_samples_1] = pickle.load(var_ff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_mean_power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_diff_power[-1]*(data_reg.shape[0] - max_train_samples)/(300-sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_fp_mae/200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_mean_power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import pydotplus\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "keras.utils.vis_utils.pydot = pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARALLEL CNN\n",
    "def cnn_model(num_filters, kernel_lam, bias_lam):\n",
    "#     num_filters, lam = 5, 5\n",
    "    data_format = 'channels_first'\n",
    "    convolution_filter, dense_filter = 'selu', 'linear' #softsign, sigmoid; relu, linear\n",
    "    filter_shape, pool_size = (3, 3), (2,2)\n",
    "    # CNN for PU image\n",
    "    input1  = layers.Input(shape=(number_image_channels - 1, max_x, max_y), name='pus_input')\n",
    "    x1 = layers.Conv2D(num_filters, filter_shape, padding='same', activation=convolution_filter, \n",
    "                          input_shape=(number_image_channels - 1, max_x, max_y), data_format=data_format,\n",
    "                          kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "                          kernel_initializer='lecun_normal')(input1)\n",
    "    x1 = layers.MaxPooling2D(pool_size=pool_size, data_format=data_format)(x1)\n",
    "    \n",
    "    x1 = layers.Conv2D(num_filters, filter_shape, padding='same', activation=convolution_filter, \n",
    "                          input_shape=(number_image_channels - 1, max_x, max_y), data_format=data_format,\n",
    "                          kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "                          kernel_initializer='lecun_normal')(x1)\n",
    "    x1 = layers.MaxPooling2D(pool_size=pool_size, data_format=data_format)(x1)\n",
    "    \n",
    "    x1 = layers.Conv2D(num_filters, filter_shape, padding='same', activation=convolution_filter, \n",
    "                          input_shape=(number_image_channels - 1, max_x, max_y), data_format=data_format,\n",
    "                          kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "                          kernel_initializer='lecun_normal')(x1)\n",
    "    x1 = layers.MaxPooling2D(pool_size=pool_size, data_format=data_format)(x1)\n",
    "    \n",
    "    x1 = layers.Conv2D(num_filters, filter_shape, padding='same', activation=convolution_filter, \n",
    "                          input_shape=(number_image_channels - 1, max_x, max_y), data_format=data_format,\n",
    "                          kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "                          kernel_initializer='lecun_normal')(x1)\n",
    "    x1 = layers.MaxPooling2D(pool_size=pool_size, data_format=data_format)(x1)\n",
    "    \n",
    "    x1 = layers.Conv2D(num_filters, filter_shape, padding='same', activation=convolution_filter, \n",
    "                          input_shape=(number_image_channels - 1, max_x, max_y), data_format=data_format,\n",
    "                          kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "                          kernel_initializer='lecun_normal')(x1)\n",
    "    x1 = layers.MaxPooling2D(pool_size=pool_size, data_format=data_format)(x1)\n",
    "    \n",
    "    \n",
    "    # CNN for SU\n",
    "    input2  = layers.Input(shape=(1, max_x, max_y), name='su_input')\n",
    "    x2 = layers.Conv2D(num_filters, filter_shape, padding='same', activation=convolution_filter, \n",
    "                          input_shape=(1, max_x, max_y), data_format=data_format,\n",
    "                          kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "                          kernel_initializer='lecun_normal')(input2)\n",
    "    x2 = layers.MaxPooling2D(pool_size=pool_size, data_format=data_format)(x2)\n",
    "    \n",
    "    x2 = layers.Conv2D(num_filters, filter_shape, padding='same', activation=convolution_filter, \n",
    "                          input_shape=(1, max_x, max_y), data_format=data_format,\n",
    "                          kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "                          kernel_initializer='lecun_normal')(x2)\n",
    "    x2 = layers.MaxPooling2D(pool_size=pool_size, data_format=data_format)(x2)\n",
    "    \n",
    "    x2 = layers.Conv2D(num_filters, filter_shape, padding='same', activation=convolution_filter, \n",
    "                          input_shape=(1, max_x, max_y), data_format=data_format,\n",
    "                          kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "                          kernel_initializer='lecun_normal')(x2)\n",
    "    x2 = layers.MaxPooling2D(pool_size=pool_size, data_format=data_format)(x2)\n",
    "    \n",
    "    x2 = layers.Conv2D(num_filters, filter_shape, padding='same', activation=convolution_filter, \n",
    "                          input_shape=(1, max_x, max_y), data_format=data_format,\n",
    "                          kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "                          kernel_initializer='lecun_normal')(x2)\n",
    "    x2 = layers.MaxPooling2D(pool_size=pool_size, data_format=data_format)(x2)\n",
    "    \n",
    "    x2 = layers.Conv2D(num_filters, filter_shape, padding='same', activation=convolution_filter, \n",
    "                          input_shape=(1, max_x, max_y), data_format=data_format,\n",
    "                          kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "                          kernel_initializer='lecun_normal')(x2)\n",
    "    x2 = layers.MaxPooling2D(pool_size=pool_size, data_format=data_format)(x2)\n",
    "    \n",
    "    \n",
    "    # concatanate two CNN outputs\n",
    "    x = layers.concatenate([x1, x2])\n",
    "    x = layers.Flatten()(x)\n",
    "    \n",
    "    x = layers.Dense(20, activation=convolution_filter, kernel_regularizer=regularizers.l2(kernel_lam),\n",
    "                         bias_regularizer=regularizers.l2(bias_lam), kernel_initializer='lecun_normal')(x)\n",
    "    x = layers.Dense(20, activation=convolution_filter, kernel_regularizer=regularizers.l2(kernel_lam),\n",
    "                         bias_regularizer=regularizers.l2(bias_lam), kernel_initializer='lecun_normal')(x)\n",
    "    out = layers.Dense(1, activation=dense_filter, kernel_regularizer=regularizers.l2(kernel_lam),\n",
    "                         bias_regularizer=regularizers.l2(bias_lam), kernel_initializer='lecun_normal')(x)\n",
    "    \n",
    "    model = models.Model(inputs=[input1, input2], outputs=out)\n",
    "#     plot_model(model, to_file='model.png')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number_samples = [5] + list(range(10, 101, 10)) + [120, 150, 200, 250, 300, 400, 500, 700] + list(range(1000, 1001, 1000))\n",
    "\n",
    "# validation_size, noise_floor = 0.33, -90.0\n",
    "# su_power = 0 # this is not actually su power just a number to show there is an SU in its image\n",
    "# max_x, max_y, number_image_channels, su_szie = 1000, 1000, 2, 10\n",
    "# pu_shape, su_shape = 'circle', 'square'\n",
    "# style = \"image_intensity\"  # {\"raw_power_zscore_norm\", \"image_intensity\", \"raw_power_min_max_norm\"}\n",
    "# pus_num, intensity_degradation, slope = 15, 'log', 4\n",
    "# average_diff_power = [9.110476626067186, 21.070721128267266, 9.389938883165568, 10.886098907990405,\n",
    "#                                        7.697396928362106, 7.522477509027216, 9.493729427772132, 8.198866980620753,\n",
    "#                                        7.781910785203122, 9.41743984825801, 8.499455442627129, 9.86776958065812,\n",
    "#                                        9.033719411254367, 8.150143941293027, 8.963829050517273, 8.708150642874065,\n",
    "#                                        7.468060397898071, 8.233182799553932,8.206, 7.768]\n",
    "# fp_mean_power =  [8.174990557021465, 0.18043087058937837, 1.5141939559853392, 10.273307557711494,\n",
    "#                                    3.2306742061521443, 4.423113329284006, 8.674172526579392, 2.38235061342411,\n",
    "#                                    5.014172646429496, 6.884079514994618, 3.4544130456368367, 7.81721202679044,\n",
    "#                                    6.438635364829745, 4.069245107144559, 5.202978504937615, 3.405858414831347,\n",
    "#                                    4.117573271657338, 2.8100743146184377, 3.951, 3.502]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MAX_POWER ANAlysis\n",
    "# number_samples = [5] + list(range(10, 101, 10)) + [120, 150, 200, 250, 300, 400, 500, 700] + list(range(1000, 1001, 1000))\n",
    "\n",
    "# validation_size, noise_floor = 0.33, -90.0\n",
    "# su_power = 0 # this is not actually su power just a number to show there is an SU in its image\n",
    "# max_x, max_y, number_image_channels, su_szie = 1000, 1000, 2, 10\n",
    "# pus_num, intensity_degradation, slope = 15, 'log', 4\n",
    "# pu_shape, su_shape = 'circle', 'circle'\n",
    "# style = \"image_intensity\"  # {\"raw_power_zscore_norm\", \"image_intensity\", \"raw_power_min_max_norm\"}\n",
    "# test_size = 3670\n",
    "# average_diff_power = [7.811849328268183, 9.178415418536536, 8.11891504382307, 7.881934146750136, 7.918868224324312,\n",
    "#                       7.709452054502398, 7.471729821563216, 8.63783455122861, 7.7635068514166345, 8.557134470036884,\n",
    "#                       8.103793715416188, 9.189284948409279, 11.977416480154307, 8.291134394492891, 8.960065032512803,\n",
    "#                       9.992745143323642, 8.475335283779392, 8.051642160173987, 7.322538645284376, 7.768582958795206]\n",
    "# fp_mean_power = [6.1844398077234635, 1.6157812496465958, 6.5620574110067595, 2.898169187355567, 6.262096880097353,\n",
    "#                  2.5478307871639267, 3.5784209073932067, 7.416731632966506, 5.5822838290638135, 5.800529848947965,\n",
    "#                  4.6984887763519785, 2.337296353076653, 9.85739104089764, 3.710259461284922, 5.323224159423669, \n",
    "#                  6.198328912769283, 2.302462751745074, 4.023802978234984, 3.781413967880959, 3.2793608103510508]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INIT\n",
    "# number_samples = [5] + list(range(10, 101, 10)) + [120, 150, 200, 250, 300, 400, 500, 700] + list(range(1000, 1001, 1000))\n",
    "\n",
    "# validation_size, noise_floor = 0.33, -90.0\n",
    "# su_power = 0 # this is not actually su power just a number to show there is an SU in its image\n",
    "# max_x, max_y, number_image_channels, su_szie = 1000, 1000, 2, 10\n",
    "# pu_shape, su_shape = 'circle', 'circle'\n",
    "# style = \"raw_power_min_max_norm\"  # {\"raw_power_zscore_norm\", \"image_intensity\", \"raw_power_min_max_norm\"}\n",
    "# pus_num, intensity_degradation, slope = 15, 'log', 4\n",
    "# if su_shape == 'circle':\n",
    "#     su_param = Circle(su_szie)\n",
    "# elif su_shape == 'square':\n",
    "#     su_param = Square(su_szie)\n",
    "# num_pus = 15\n",
    "average_diff_power = [9.711, 7.867, 8.958, 7.571, 7.509, 7.891, 8.272, 7.118, 7.696, 7.689, 8.026, 9.674, 7.51, 7.771, 8.17,\n",
    "                      7.938, 7.869, 7.833, 9.434, 8.501]\n",
    "fp_mean_power = [9.229, 5.101, 8.037, 3.993, 5.095, 2.491, 2.298, 4.654, 3.787, 2.685, 5.676, 8.033, 3.911, 4.235, 3.278,\n",
    "                 5.809, 3.586, 4.257, 4.377, 5.015]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INIT\n",
    "\n",
    "# number_samples = [120, 150, 200, 250, 300, 400, 500, 700] + list(range(1000, 8001, 1000))\n",
    "\n",
    "\n",
    "# cnn_type = \"classification\"  # {\"classification\", \"regression\"}\n",
    "# validation_size, noise_floor = 0.33, -90.0\n",
    "# su_power = 0 # this is not actually su power just a number to show there is an SU in its image\n",
    "# max_x, max_y, number_image_channels, su_szie = 200, 200, 2, 10\n",
    "# pu_shape, su_shape = 'circle', 'circle' # shape = {'circle', 'square', 'point'}\n",
    "# style = \"raw_power_min_max_norm\"  # {\"raw_power_zscore_norm\", \"image_intensity\", \"raw_power_min_max_norm\"}\n",
    "# pus_num, intensity_degradation, slope = 15, 'log', 4\n",
    "# if su_shape == 'circle':\n",
    "#     su_param = Circle(su_szie)\n",
    "# elif su_shape == 'square':\n",
    "#     su_param = Square(su_szie)\n",
    "# else:\n",
    "#     su_param = None\n",
    "# sensors = False\n",
    "# if sensors:\n",
    "#     sensors_num = 50\n",
    "#     sensors_file_path = \"rsc/\" + str(sensors_num) + \"/sensors\"\n",
    "    \n",
    "average_diff_power = [6.779, 5.645, 5.473, 4.982, 4.481, 4.071, 4.05, 3.639, 2.813, 2.343, 2.21, 2.372, 2.005, 1.997,\n",
    "                      1.937, 1.901]\n",
    "\n",
    "fp_mean_power = [4.073, 2.409, 3.424, 3.163, 2.833, 2.663, 2.857, 2.744, 1.744, 1.33, 1.184, 1.55, 0.579, 1.216, 1.492, 1.266]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INIT\n",
    "\n",
    "number_samples = [120, 150, 200, 250, 300, 400, 500, 700] + list(range(1000, 6001, 1000)) + [8000]\n",
    "# dataframe = pd.read_csv('ML/data/dynamic_pus_using_pus50000_15PUs_201912_3000_40_200.txt', delimiter=',', header=None)\n",
    "# dataframe_max = pd.read_csv('ML/data/dynamic_pus_max_power50000_15PUs_201912_3000_40_200.txt', delimiter=',', header=None)\n",
    "\n",
    "\n",
    "# validation_size, noise_floor = 0.33, -90.0\n",
    "# su_power = 0 # this is not actually su power just a number to show there is an SU in its image\n",
    "# max_x, max_y, number_image_channels, su_szie = 200, 200, 4, 10\n",
    "# pu_shape, su_shape = 'circle', 'circle' # shape = {'circle', 'square', 'point'}\n",
    "# style = \"raw_power_min_max_norm\"  # {\"raw_power_zscore_norm\", \"image_intensity\", \"raw_power_min_max_norm\"}\n",
    "# pus_num, intensity_degradation, slope = 15, 'log', 5\n",
    "# if su_shape == 'circle':\n",
    "#     su_param = Circle(su_szie)\n",
    "# elif su_shape == 'square':\n",
    "#     su_param = Square(su_szie)\n",
    "# else:\n",
    "#     su_param = None\n",
    "# sensors = False\n",
    "    \n",
    "average_diff_power = [12.742, 12.906, 12.731, 12.595, 12.859, 13.272, 12.632, 12.647, 11.309, 7.455, 7.131, 5.677,\n",
    "                      5.645, 5.292, 4.445]\n",
    "\n",
    "fp_mean_power = [5.963, 5.861, 8.957, 8.821, 8.215, 9.518, 8.633, 6.644, 6.605, 3.919, 2.539, 3.866, 1.96, 2.717, 1.671]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(average_diff_power)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_width = 5\n",
    "marker_size = 12\n",
    "reg_style = 'solid'\n",
    "class_reg = 'dashed'\n",
    "fig = plt.figure(figsize=(15,8))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "plt.plot(number_samples, average_diff_power, color='r', linewidth=line_width, markersize=marker_size, linestyle=class_reg)\n",
    "plt.plot(number_samples, fp_mean_power, color='midnightblue', linewidth=line_width, markersize=marker_size, linestyle=class_reg)\n",
    "plt.xlabel('# of Training Samples', fontsize=47)\n",
    "plt.ylabel('Avg. Diff. wrt Opt. (dB)', fontsize=45)\n",
    "plt.title('Dynamic PUs(200m*200m)')\n",
    "plt.grid(True)\n",
    "\n",
    "ax.set_yticks(np.arange(0,14, 2))\n",
    "# ax.set_xticks(np.arange(100,7000, 1500))\n",
    "plt.rcParams.update({'font.size': 42})\n",
    "ax.tick_params(axis='x', labelsize=46)\n",
    "ax.tick_params(axis='y', labelsize=45)\n",
    "\n",
    "# matplotlib.rcParams.update({'font.size': 22})\n",
    "\n",
    "ax.set_ylim([0, 14])\n",
    "ax.set_xlim([0, 8000])\n",
    "plt.legend(['Total', 'False-Positive'], ncol=2, loc='best', handletextpad=0.1,borderpad=0, columnspacing=0.2, borderaxespad=0.2)\n",
    "# plt.legend(handletextpad=0.1)\n",
    "plt.savefig('/'.join(image_dir.split('/')[:-1]) +  '/' + intensity_degradation + '_' + str(slope) + '_' + dtime + \".png\", \n",
    "            bbox_inches = 'tight', pad_inches = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.load(image_dir + '/image10.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('/'.join(image_dir.split('/')[:-1]) + '/log_5__202006_2714_19.dat', 'rb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('/home/shahrokh/projects/research/MLSpectrumAllocation/ML/data/pictures_1000_1000/log/noisy_std_1/' +\n",
    "            'pu_circle_su_circle_30/raw_power_min_max_norm/color/log_4/pus/log_4__202005_0512_10.dat', 'rb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[average_diff_power, fp_mean_power, number_samples, best_lambda, \n",
    " dataset_name, max_dataset_name, average_power_conserve, \n",
    " fp_mean_power_conserve] = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(number_samples)\n",
    "print(average_diff_power)\n",
    "print(fp_mean_power)\n",
    "print(best_lambda)\n",
    "print(average_power_conserve)\n",
    "print(fp_mean_power_conserve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fp1, fp2, fp3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(samples1, samples2, samples3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(samples3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POST-Proccess testbed data\n",
    "import random as rd\n",
    "max_pus_num, max_sus_num, sensors_num = 4, 1, 18\n",
    "num_columns = (sensors_num if sensors else max_pus_num * 3 + 1) + max_sus_num * 3 + 1\n",
    "num_cols_sensor = sensors_num + max_sus_num * 3 + 1\n",
    "cols = [i for i in range(num_columns)]\n",
    "sensor_cols = [i for i in range(num_cols_sensor)]\n",
    "dataset_name = \"testbed_pu_1\"\n",
    "sensor_dataset_name = \"testbed_ss_1\"\n",
    "\n",
    "dataframe = pd.read_csv('ML/data/' + dataset_name, delimiter=',', header=None, names=cols)\n",
    "dataframe_sensor = pd.read_csv('ML/data/' + sensor_dataset_name, delimiter=',', header=None, names=sensor_cols)\n",
    "# dataframe_max = pd.read_csv('../../../java_workspace/research/spectrum_allocation/resources/data/'\n",
    "#                             + max_dataset_name, delimiter=',', header=None)\n",
    "dataframe.reset_index(drop=True, inplace=True)\n",
    "dataframe_sensor.reset_index(drop=True, inplace=True)\n",
    "\n",
    "for i in range(dataframe.shape[0]):\n",
    "    idx = rd.randint(i, dataframe.shape[0] - 1)\n",
    "    b, c = dataframe.iloc[i], dataframe.iloc[idx]\n",
    "    temp = dataframe.iloc[i].copy()\n",
    "    dataframe.iloc[i] = c\n",
    "    dataframe.iloc[idx] = temp\n",
    "    \n",
    "    b, c = dataframe_sensor.iloc[i], dataframe_sensor.iloc[idx]\n",
    "    temp = dataframe_sensor.iloc[i].copy()\n",
    "    dataframe_sensor.iloc[i] = c\n",
    "    dataframe_sensor.iloc[idx] = temp\n",
    "    \n",
    "\n",
    "data_reg = dataframe.values\n",
    "# data_reg[data_reg < noise_floor] = noise_floor\n",
    "\n",
    "for sample_idx in range(data_reg.shape[0]):\n",
    "    num_pus = int(data_reg[sample_idx][0])\n",
    "    data_reg[sample_idx][num_pus * 3 + 2:] = data_reg[sample_idx][num_pus * 3 + 1 : -1]\n",
    "    data_reg[sample_idx][num_pus * 3 + 1] = 1\n",
    "    data_reg[sample_idx][-1] = data_reg[sample_idx][num_pus * 3 + 3 + 1]\n",
    "\n",
    "data_reg_sensor = dataframe_sensor.values\n",
    "col_avg = [0] * 18\n",
    "for col_id in range(18):\n",
    "    count = 0\n",
    "    for sample_idx in range(data_reg_sensor.shape[0]):\n",
    "        if data_reg_sensor[sample_idx][col_id] != ' nan':\n",
    "            col_avg[col_id] += float(data_reg_sensor[sample_idx][col_id])\n",
    "            count += 1\n",
    "    col_avg[col_id] /= count\n",
    "    for sample_idx in range(data_reg_sensor.shape[0]):\n",
    "        if data_reg_sensor[sample_idx][col_id] == ' nan':\n",
    "            data_reg_sensor[sample_idx][col_id] = col_avg[col_id]\n",
    "        else:\n",
    "            data_reg_sensor[sample_idx][col_id] = float(data_reg_sensor[sample_idx][col_id])\n",
    "            \n",
    "for sample_idx in range(data_reg_sensor.shape[0]):\n",
    "    data_reg_sensor[sample_idx][19:22] = data_reg_sensor[sample_idx][18:21]\n",
    "    data_reg_sensor[sample_idx][18] = 1\n",
    "            \n",
    "np.savetxt(\"ML/data/testbed_pu_1_shuf2\", data_reg, delimiter=',', fmt=\"%.1f\")\n",
    "np.savetxt(\"ML/data/testbed_ss_1_shuf2\", data_reg_sensor, delimiter=',', fmt=\"%.2f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(299, 17)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_reg[3][4 * 3 + 2:] = data_reg[3][4*3+1:-1]\n",
    "data_reg[3][4 * 3 + 1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-47.86, -48.32, -48.21, -48.12, -48.26, -48.2, -47.67, -48.37,\n",
       "       -48.17, -48.2, -48.34, -48.4, -48.52, -48.27, -48.36, -48.37,\n",
       "       -48.31, -48.37, 8.0, 9.0, 42], dtype=object)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_reg_sensor[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_reg_sensor[:][19:-1] = data_reg_sensor[:][18:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-44.58, -46.1, -36.75, -47.19, -47.63, -48.28, -45.02, -48.41,\n",
       "       -47.94, -46.21, -48.24, -48.42, -48.39, -48.07, -48.42, -48.35,\n",
       "       -48.27, -48.32, 1, 9.0, 1.0, 54], dtype=object)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_reg_sensor[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
