{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SVM and SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "# from sklearn.cross_validation import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC, SVR, LinearSVR\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INIT\n",
    "number_samples = [128, 256, 512, 1024, 2048, 4096]\n",
    "C_vec = list(np.arange(0.1, 10, 0.5))\n",
    "max_pus_number, max_sus_number, num_sensors = 20, 4, 1600\n",
    "IS_SENSORS = True\n",
    "DUMMY_LOC_VALUE, DUMMY_POWER_VALUE = -110.0, -110.0\n",
    "NOISE_FLOOR = -90.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#utils\n",
    "def false_analysis(y_test, y_pred):\n",
    "    tp = sum(y_pred[y_test==1])\n",
    "    fp = sum(y_pred) - tp\n",
    "    return fp, sum(y_test) - tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD DATA\n",
    "num_columns = (num_sensors if IS_SENSORS else max_pus_number * 3 + 1) + max_sus_number * 3 + 2\n",
    "cols = [i for i in range(num_columns)]\n",
    "dataframe = pd.read_csv('../../java_workspace/research/spectrum_allocation/resources/data/' +\n",
    "                        'dynamic_pus_1600sensor_30000_min10_max20PUs_min1_max4SUs_square100grid_splat_2021_10_28_15_33.txt', \n",
    "                        delimiter=',', header=None, names=cols)\n",
    "dataframe_max = pd.read_csv('../../java_workspace/research/spectrum_allocation/resources/data/' +\n",
    "                            'dynamic_pus_max_power_30000_min10_max20PUs_min1_max4SUs_square100grid_splat_2021_10_28_15_33.txt', delimiter=',', header=None)\n",
    "\n",
    "dataframe.reset_index(drop=True, inplace=True)\n",
    "dataframe_max.reset_index(drop=True, inplace=True)\n",
    "dataframe_max[dataframe_max.shape[1] - 1] = dataframe_max[dataframe_max.shape[1] - 1].astype(float)\n",
    "\n",
    "dataframe_tot = pd.concat([dataframe, dataframe_max.iloc[:, dataframe_max.columns.values[-1]]], axis=1,\n",
    "                        ignore_index=True)\n",
    "idx = dataframe_tot[dataframe_tot[dataframe_tot.columns[-1]] == -float('inf')].index\n",
    "dataframe_tot.drop(idx, inplace=True)\n",
    "\n",
    "data_reg = np.concatenate((dataframe_tot.values[:, 0:dataframe_tot.shape[1]-3], \n",
    "                           dataframe_tot.values[:, dataframe_tot.shape[1]-1:dataframe_tot.shape[1]]), axis=1)\n",
    "data_reg[data_reg < NOISE_FLOOR] = NOISE_FLOOR\n",
    "data_class = dataframe_tot.values[:, 0:dataframe_tot.shape[1]-1]\n",
    "y_class_power = dataframe_tot.values[:, -1]\n",
    "del dataframe, dataframe_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD DATA for testbed\n",
    "num_columns = (num_sensors if IS_SENSORS else max_pus_number * 3 + 1) + max_sus_number * 3 + 1\n",
    "cols = [i for i in range(num_columns)]\n",
    "dataframe = pd.read_csv('ML/data/testbed/' + 'su_ss_calibrate_shuffled', \n",
    "                        delimiter=',', header=None, names=cols)\n",
    "dataframe.reset_index(drop=True, inplace=True)\n",
    "data_reg = dataframe.values\n",
    "data_reg[data_reg < NOISE_FLOOR] = NOISE_FLOOR\n",
    "selected_columns = [4, 2, 16, 14]\n",
    "droped_columns = []\n",
    "for i in range(num_sensors):\n",
    "    if i not in selected_columns:\n",
    "        droped_columns.append(i)\n",
    "data_reg = np.delete(data_reg, droped_columns, 1)\n",
    "num_sensors = len(selected_columns)\n",
    "num_columns = (num_sensors if IS_SENSORS else max_pus_number * 3 + 1) + max_sus_number * 3 + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data\n",
    "# def split_data(data, train_samples):\n",
    "#     num_inputs = data.shape[1] - 1\n",
    "#     val_samples = round(train_samples/3)\n",
    "#     X_train, y_train = data[0:train_samples, 0: num_inputs], data[0:train_samples, -1]\n",
    "#     X_val, y_val = data[train_samples:train_samples+val_samples, 0: num_inputs],data[train_samples:train_samples+val_samples, -1]\n",
    "#     X_test, y_test = data[train_samples:, 0: num_inputs], data[train_samples:, -1]\n",
    "#     return X_train,X_val, X_test, y_train, y_val, y_test\n",
    "\n",
    "def split_data(data: np.ndarray, train_samples):\n",
    "    num_inputs = (max_sus_number - 1) * 3 + 2 + (max_pus_number * 3 \n",
    "                                                 if not IS_SENSORS else num_sensors)\n",
    "    val_samples = round(train_samples/5)\n",
    "    test_samples = data.shape[0] - val_samples - train_samples\n",
    "    #init arrays\n",
    "    X_train = np.ones((train_samples, num_inputs), dtype=float) * DUMMY_LOC_VALUE\n",
    "    X_val = np.ones((val_samples, num_inputs), dtype=float) * DUMMY_LOC_VALUE\n",
    "    X_test = np.ones((test_samples, num_inputs), dtype=float) * DUMMY_LOC_VALUE\n",
    "    # read values\n",
    "    if not IS_SENSORS:\n",
    "        # fill train\n",
    "        for train_sample in range(train_samples):\n",
    "            num_pus = int(data[train_sample, 0])\n",
    "            num_sus = int(data[train_sample, 1 + num_pus * 3])\n",
    "            X_train[train_sample, :num_pus * 3] = data[train_sample, 1:1 + num_pus * 3]#pus\n",
    "            #sus except power of last su\n",
    "            X_train[train_sample, max_pus_number * 3: (max_pus_number + num_sus) * 3 \n",
    "                    - 1] = data[train_sample, 2 + num_pus * 3: \n",
    "                                1 + (num_pus + num_sus) * 3]\n",
    "        # fill validation\n",
    "        for val_sample in range(train_samples, train_samples + val_samples):\n",
    "            num_pus = int(data[val_sample, 0])\n",
    "            num_sus = int(data[val_sample, 1 + num_pus * 3])\n",
    "            X_val[val_sample - train_samples, :num_pus * 3] = data[val_sample, 1:1 + num_pus * 3]\n",
    "            X_val[val_sample - train_samples, max_pus_number * 3: \n",
    "                  (max_pus_number + num_sus) * 3 - 1] = data[val_sample, 2 + num_pus * 3:\n",
    "                                                             1 + (num_pus + num_sus) * 3]\n",
    "        # fill test\n",
    "        for test_sample in range(train_samples + val_samples, \n",
    "                                 train_samples + val_samples + test_samples):\n",
    "            num_pus = int(data[test_sample, 0])\n",
    "            num_sus = int(data[test_sample, 1 + num_pus * 3])\n",
    "            X_test[test_sample - (train_samples + val_samples), :num_pus * 3] = data[\n",
    "                test_sample, 1:1 + num_pus * 3]\n",
    "            X_test[test_sample - (train_samples + val_samples), max_pus_number * 3:\n",
    "                   (max_pus_number + num_sus) * 3 - 1] = data[test_sample, 2 + num_pus * 3:\n",
    "                                                              1 + (num_pus + num_sus) * 3]\n",
    "    else:\n",
    "        # read sensors\n",
    "        X_train[:, :num_sensors] = data[:train_samples, :num_sensors]\n",
    "        X_val[:, :num_sensors] = data[train_samples: train_samples + val_samples,\n",
    "                                         :num_sensors]\n",
    "        X_test[:, :num_sensors] = data[train_samples + val_samples : , :num_sensors]\n",
    "        #read sus\n",
    "        for train_sample in range(train_samples):\n",
    "            num_sus = int(data[train_sample, num_sensors])\n",
    "            X_train[train_sample, num_sensors: num_sensors + num_sus * 3 - 1] = data[\n",
    "                train_sample, num_sensors + 1:num_sensors + num_sus * 3]\n",
    "            \n",
    "        for val_sample in range(train_samples, train_samples + val_samples):\n",
    "            num_sus = int(data[val_sample, num_sensors])\n",
    "            X_val[val_sample - train_samples, num_sensors: num_sensors + num_sus * 3 - 1] =\\\n",
    "                data[val_sample, num_sensors + 1:num_sensors + num_sus * 3]\n",
    "            \n",
    "        for test_sample in range(train_samples + val_samples, \n",
    "                                 train_samples + val_samples + test_samples):\n",
    "            num_sus = int(data[test_sample, num_sensors])\n",
    "            X_test[test_sample - (train_samples + val_samples), num_sensors:\n",
    "                   num_sensors + num_sus * 3 - 1] = data[test_sample, \n",
    "                                                         num_sensors + 1:num_sensors + num_sus * 3]\n",
    "\n",
    "    \n",
    "    y_train = data[0 : train_samples, -1]\n",
    "    y_val = data[train_samples : train_samples + val_samples, -1]\n",
    "    y_test = data[train_samples + val_samples:, -1]\n",
    "    return np.asarray(X_train).astype(np.float32),  np.asarray(X_val).astype(np.float32),\\\n",
    "           np.asarray(X_test).astype(np.float32), np.asarray(y_train).astype(np.float32), \\\n",
    "           np.asarray(y_val).astype(np.float32), np.asarray(y_test).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, X_test, y_train, y_val, y_test = split_data(data_reg, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## SVM(SVC)\n",
    "average_class_diff_power = []\n",
    "fp_mean_power = []\n",
    "accuracy, f_score, false_positive, false_negative = [], [], [], []\n",
    "best_c_lst = []\n",
    "fp_penalty_coef, fn_penalty_coef = 1, 1\n",
    "metric = \"fp_min\"  # {\"accuracy\", \"fp_min\"}\n",
    "class_weight = {0:fp_penalty_coef/(fp_penalty_coef + fn_penalty_coef), 1:fn_penalty_coef/(fp_penalty_coef + fn_penalty_coef)}\n",
    "best_c, bestsvcclassifier = None, None\n",
    "for number_sample in number_samples:\n",
    "    best_accuracy = -float('inf')\n",
    "    best_fp = float('inf')\n",
    "    X_train, X_val, X_test, y_train, y_val, y_test = split_data(data_class, number_sample)\n",
    "    scaler_x = StandardScaler()\n",
    "    scaler_x.fit(X_train)\n",
    "    X_train = scaler_x.transform(X_train)\n",
    "    X_val = scaler_x.transform(X_val)\n",
    "    for c in C_vec:\n",
    "        svclassifier = SVC(kernel='rbf', C=c, class_weight = class_weight)\n",
    "        svclassifier.fit(X_train, y_train)\n",
    "        \n",
    "        #validating\n",
    "        y_pred_val = svclassifier.predict(X_val)\n",
    "        if metric == \"accuracy\":\n",
    "            accuracy_tmp = metrics.accuracy_score(y_val, y_pred_val)\n",
    "            if accuracy_tmp > best_accuracy:\n",
    "                best_accuracy = accuracy_tmp\n",
    "                best_c = c\n",
    "                bestsvcclassifier = svclassifier\n",
    "        elif metric == \"fp_min\":\n",
    "            conf_mat = metrics.confusion_matrix(y_val, y_pred_val)\n",
    "            fp_tmp = conf_mat[0][1] if len(conf_mat) == 2 else 0\n",
    "            if fp_tmp < best_fp:\n",
    "                best_fp = fp_tmp\n",
    "                best_c = c\n",
    "                bestsvcclassifier = svclassifier\n",
    "                    \n",
    "            \n",
    "    best_c_lst.append(best_c)\n",
    "    #predicting\n",
    "    X_test = scaler_x.transform(X_test)\n",
    "    y_pred = bestsvcclassifier.predict(X_test)\n",
    "    \n",
    "    #evaluating\n",
    "    accuracy.append(round(metrics.accuracy_score(y_test, y_pred), 3))\n",
    "    f_score.append(round(metrics.f1_score(y_true=y_test, y_pred=y_pred), 3))\n",
    "    fp, fn = false_analysis(y_test, y_pred)\n",
    "    false_positive.append(int(fp))\n",
    "    false_negative.append(int(fn))\n",
    "    \n",
    "    #Power max calculations\n",
    "    y_class_power_test = y_class_power[len(y_class_power)-X_test.shape[0]:]\n",
    "    y_class_power_pred = np.zeros(y_class_power_test.size)\n",
    "    max_power = max(y_class_power_test) + 10  # 10 is added to increase higher bound\n",
    "    min_power = min(y_class_power_test) - 10  # 10 is subtracted to decrease lower bound\n",
    "    for i in range(len(y_class_power_test)):\n",
    "        h = max_power\n",
    "        l = min_power\n",
    "        while h - l > 0.5:\n",
    "            mid = l + (h - l)/2;\n",
    "            mid_norm = (mid - scaler_x.mean_[-1])/scaler_x.scale_[-1]\n",
    "            X_test[i][-1] = mid_norm\n",
    "            res_tmp = bestsvcclassifier.predict(X_test[i:i+1])\n",
    "            if res_tmp[0]:\n",
    "                l = mid\n",
    "            else:\n",
    "                h = mid\n",
    "        y_class_power_pred[i] = l + (h - l)/2\n",
    "    average_class_diff_power.append(round(np.mean(np.absolute(y_class_power_pred - y_class_power_test)), 3))\n",
    "    fp_samples = np.zeros(len(y_class_power_pred), dtype=float)\n",
    "    fp_samples[y_class_power_pred > y_class_power_test] = (y_class_power_pred - y_class_power_test)[y_class_power_pred > \n",
    "                                                                                                    y_class_power_test]\n",
    "    fp_mean_power.append(round(np.mean(fp_samples), 3))\n",
    "    print('Number_samples:', number_sample, ', accuracy:', accuracy[-1], ', f_score:', f_score[-1], \n",
    "          ', fp:', fp,', fn:', fn, ', error:', average_class_diff_power[-1], 'fp_error:', fp_mean_power[-1])\n",
    "del svclassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MAX_POWER ANAlysis\n",
    "fig = plt.figure(figsize=(15,8))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "plt.plot(number_samples, accuracy)\n",
    "plt.xlabel('# training samples')\n",
    "plt.ylabel('%')\n",
    "plt.title('SVM: Classification Accuracy(Dynamic PUs, Using PUs, Test_size=40k)')\n",
    "plt.grid(True)\n",
    "plt.savefig('ML\\\\results\\\\changing_training_test40k_4kx4k_smallVal_compare_dynamicPUS_svmAcc.png')\n",
    "\n",
    "fig = plt.figure(figsize=(15,8))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "plt.plot(number_samples, f_score)\n",
    "plt.xlabel('# training samples')\n",
    "plt.ylabel('%')\n",
    "plt.title('SVM: Classification F_score(Dynamic PUs, Using PUs, Test_size=40k)')\n",
    "plt.grid(True)\n",
    "plt.savefig('ML\\\\results\\\\changing_training_test40k_4kx4k_smallVal_compare_dynamicPUS_svmfscore.png')\n",
    "\n",
    "fig = plt.figure(figsize=(15,8))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "plt.plot(number_samples, false_positive)\n",
    "plt.xlabel('# training samples')\n",
    "plt.ylabel('#')\n",
    "plt.title('SVM: Classification FP(Dynamic PUs, Using PUs, Test_size=40k)')\n",
    "plt.grid(True)\n",
    "plt.savefig('ML\\\\results\\\\changing_training_test40k_4kx4k_smallVal_compare_dynamicPUS_svmfp.png')\n",
    "\n",
    "fig = plt.figure(figsize=(15,8))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "plt.plot(number_samples, false_negative)\n",
    "plt.xlabel('# training samples')\n",
    "plt.ylabel('#')\n",
    "plt.title('SVM: Classification FN(Dynamic PUs, Using PUs, Test_size=40k)')\n",
    "plt.grid(True)\n",
    "plt.savefig('ML\\\\results\\\\changing_training_test40k_4kx4k_smallVal_compare_dynamicPUS_svmfn.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVR\n",
    "average_reg_diff_power, best_c_reg_lst, fp_mean_power = [], [], []\n",
    "best_c_reg, bestsvrclassifier =  None, None\n",
    "# TODO: Having different penalties for fp and fn\n",
    "for number_sample in number_samples:\n",
    "    min_err = float('inf')\n",
    "    X_train, X_val, X_test, y_train, y_val, y_test = split_data(data_reg, number_sample)\n",
    "    scaler_x = StandardScaler()\n",
    "    scaler_x.fit(X_train)\n",
    "    X_train = scaler_x.transform(X_train)\n",
    "    X_val = scaler_x.transform(X_val)\n",
    "    for c in C_vec:\n",
    "        svrlassifier = SVR(kernel='rbf', C=c, degree=X_train.shape[1]+1)\n",
    "        svrlassifier.fit(X_train, y_train)\n",
    "        \n",
    "        #validating\n",
    "        y_pred_val = svrlassifier.predict(X_val)\n",
    "        err_tmp = np.mean(np.absolute(y_pred_val - y_val))\n",
    "        if err_tmp < min_err:\n",
    "            min_err = err_tmp\n",
    "            best_c_reg = c\n",
    "            bestsvrclassifier = svrlassifier\n",
    "            \n",
    "    best_c_reg_lst.append(best_c_reg)\n",
    "    #predicting\n",
    "    X_test = scaler_x.transform(X_test)\n",
    "    y_pred = bestsvrclassifier.predict(X_test)\n",
    "    \n",
    "    \n",
    "    #evaluating\n",
    "    average_reg_diff_power.append(round(np.mean(np.absolute(y_test - y_pred)), 3))\n",
    "    fp_samples = np.zeros(len(y_test), dtype=float)\n",
    "    fp_samples[y_pred > y_test] = (y_pred - y_test)[y_pred > y_test]\n",
    "    fp_mean_power.append(round(np.mean(fp_samples), 3))\n",
    "    print('Number_samples: ', number_sample, ' error: ', average_reg_diff_power[-1], \n",
    "          ', fp_error:', fp_mean_power[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear SVR\n",
    "average_reg_diff_power, best_c_reg_lst, fp_mean_power = [], [], []\n",
    "best_c_reg, bestsvrclassifier =  None, None\n",
    "for number_sample in number_samples:\n",
    "    min_err = float('inf')\n",
    "    X_train, X_val, X_test, y_train, y_val, y_test = split_data(data_reg, number_sample)\n",
    "    scaler_x = StandardScaler()\n",
    "    scaler_x.fit(X_train)\n",
    "    X_train = scaler_x.transform(X_train)\n",
    "    X_val = scaler_x.transform(X_val)\n",
    "    for c in C_vec:\n",
    "        svrlassifier = LinearSVR(C=c, loss='epsilon_insensitive')\n",
    "        svrlassifier.fit(X_train, y_train)\n",
    "        \n",
    "        #validating\n",
    "        y_pred_val = svrlassifier.predict(X_val)\n",
    "        err_tmp = np.mean(np.absolute(y_pred_val - y_val))\n",
    "        if err_tmp < min_err:\n",
    "            min_err = err_tmp\n",
    "            best_c_reg = c\n",
    "            bestsvrclassifier = svrlassifier\n",
    "            \n",
    "    best_c_reg_lst.append(best_c_reg)\n",
    "    #predicting\n",
    "    X_test = scaler_x.transform(X_test)\n",
    "    y_pred = bestsvrclassifier.predict(X_test)\n",
    "    \n",
    "    \n",
    "    #evaluating\n",
    "    average_reg_diff_power.append(round(np.mean(np.absolute(y_test - y_pred)), 3))\n",
    "    fp_samples = np.zeros(len(y_test), dtype=float)\n",
    "    fp_samples[y_pred > y_test] = (y_pred - y_test)[y_pred > y_test]\n",
    "    fp_mean_power.append(round(np.mean(fp_samples), 3))\n",
    "    print('Number_samples: ', number_sample, ' error: ', average_reg_diff_power[-1], ', fp_error:', fp_mean_power[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,8))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "plt.plot(number_samples, average_class_diff_power)\n",
    "plt.plot(number_samples, average_reg_diff_power, 'r--')\n",
    "plt.xlabel('# training samples')\n",
    "plt.ylabel('Diff(dB)')\n",
    "plt.title('Average absolute difference power(Dynamic PUs, Using PUs, Test_size=40k)')\n",
    "plt.grid(True)\n",
    "\n",
    "ax.set_yticks(np.arange(0,20, 2))\n",
    "ax.set_ylim([2,20])\n",
    "ax.set_xticks(np.arange(5,4100, 500))\n",
    "plt.legend(['SVM', 'SVR'])\n",
    "plt.savefig('ML\\\\results\\\\changing_training_test40k_4kx4k_smallVal_compare_dynamicPUS_averag_powerSVMSVR.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_reg_diff_power_tot.append(average_reg_diff_power)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,8))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "plt.plot(number_samples, average_reg_diff_power_tot[0])\n",
    "plt.plot(number_samples, average_reg_diff_power_tot[1], 'r--')\n",
    "plt.plot(number_samples, average_reg_diff_power_tot[2], 'g.-')\n",
    "plt.plot(number_samples, average_reg_diff_power_tot[3], 'y->')\n",
    "plt.xlabel('# training samples')\n",
    "plt.ylabel('Diff(dB)')\n",
    "plt.title('Average absolute difference power(Dynamic PUs, Using PUs, Test_size=40k)')\n",
    "plt.grid(True)\n",
    "\n",
    "ax.set_yticks(np.arange(0,8, 2))\n",
    "ax.set_ylim([2,8])\n",
    "ax.set_xticks(np.arange(5,4100, 500))\n",
    "# plt.grid(which='minor')\n",
    "# plt.text(40, 50, '# Validation = 34k')\n",
    "# plt.text(400, 45, '# Test = 34k')\n",
    "plt.legend(['linear', 'rbf', 'poly', 'sigmoid'])\n",
    "# plt.savefig('ML\\\\results\\\\changing_training_test40k_4kx4k_smallVal_compare_dynamicPUS_averag_powerSVMSVR.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
