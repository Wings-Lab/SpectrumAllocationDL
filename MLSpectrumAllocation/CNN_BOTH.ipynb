{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, Input\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from collections import namedtuple\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import datetime, time\n",
    "import os, sys\n",
    "import tqdm\n",
    "import gc\n",
    "from multiprocessing import Process\n",
    "Point = namedtuple('Point', ('x', 'y'))\n",
    "Circle = namedtuple('Circle', ('r'))\n",
    "Square = namedtuple('Square', ('side'))\n",
    "Rectangle = namedtuple('Rectangle', ('length', 'width'))\n",
    "PointWithDistance = namedtuple('PointWithDistance', ('p', 'dist'))\n",
    "float_memory_used = 'float16'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INIT\n",
    "# PART 1\n",
    "# number_samples = [5] + list(range(10, 101, 10)) + [120, 150, 200, 250, 300, 400, 500, 700] + list(range(1000, 10001, 1000))\n",
    "number_samples = [256, 512, 1024, 2048, 4096, 8192] \n",
    "# number_samples = [4096, 4915, 5734, 6554, 7373, 8192]\n",
    "\n",
    "# cnn_type = \"classification\"  # {\"classification\", \"regression\"}\n",
    "max_power_value = 0.0\n",
    "validation_size, noise_floor = 0.33, -110.0  # -90.0\n",
    "su_power = 0 # this is not actually su power just a number to show there is an SU in its image\n",
    "max_x, max_y, su_szie = 100, 100, 10\n",
    "number_image_channels = math.ceil(abs(max_power_value - noise_floor)/5) # 5 is power range for each channel\n",
    "number_image_channels = 8\n",
    "pu_shape, su_shape = 'circle', 'circle' # shape = {'circle', 'square', 'point'}\n",
    "style = \"raw_power_min_max_norm\"  # {\"raw_power_zscore_norm\", \"image_intensity\", \"raw_power_min_max_norm\"}\n",
    "intensity_degradation, slope = 'log', 5  # 'log', 'linear'\n",
    "max_pus_num, max_sus_num = 20, 1\n",
    "propagation_model = 'splat' # 'splat', 'log', 'testbed'\n",
    "noise, std = False, 1\n",
    "if su_shape == 'circle':\n",
    "    su_param = Circle(su_szie)\n",
    "elif su_shape == 'square':\n",
    "    su_param = Square(su_szie)\n",
    "else:\n",
    "    su_param = None\n",
    "    \n",
    "sensors_num = 3600\n",
    "sensors_file_path = \"../../../java_workspace/research/commons/resources/sensors/square\" \\\n",
    "    + str(max(max_x, max_y)) + \"/\" + str(sensors_num) + \"/sensors.txt\"\n",
    "# num_pus = (data_reg.shape[1] - 3)//3\n",
    "\n",
    "# PART 2\n",
    "number_of_proccessors = 10\n",
    "memory_size_allowed = 4 # in Gigabyte\n",
    "float_size = 0\n",
    "if float_memory_used == \"float16\":\n",
    "    float_size = 16\n",
    "elif float_memory_used == \"float\" or \"float32\":\n",
    "    float_size = 32\n",
    "elif float_memory_used == \"float8\":\n",
    "    float_size = 8\n",
    "\n",
    "\n",
    "batch_size = int(memory_size_allowed / (max_x * max_y * number_image_channels * float_size/(8 * 1024 ** 3)))\n",
    "\n",
    "\n",
    "dtime = datetime.datetime.now().strftime('_%Y%m_%d%H_%M')\n",
    "color = \"color\" if number_image_channels > 1 else \"gray\"\n",
    "image_dir = 'ML/data/pictures_' + str(max_x) + '_' + str(max_y) + '/' + propagation_model + (\n",
    "    \"/noisy_std_\" + str(std) if noise else \"\") + '/pu_' + pu_shape + '_su_' + su_shape + '_' + (\n",
    "    \"\" if su_shape == 'point' else str(su_szie)) + \"/\" + style + \"/\" + color +'/' + (\n",
    "    \"\" if pu_shape == 'point' and su_shape == 'point' else (intensity_degradation + '_' + str(slope))) + (\n",
    "    \"/\" + str(sensors_num) + \"sensors_pus\") + \"/images\"\n",
    "\n",
    "if not os.path.exists(image_dir):\n",
    "        os.makedirs(image_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ML/data/pictures_100_100/splat/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/3600sensors_pus/images'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD DATA\n",
    "pu_num_columns = max_pus_num * 3 + 1 + max_sus_num * 3 + 2\n",
    "sensor_columns = sensors_num + max_sus_num * 3 + 2\n",
    "pu_cols = [i for i in range(pu_num_columns)]\n",
    "sensor_cols = [i for i in range(sensor_columns)]\n",
    "pu_dataset_name = \"dynamic_pus_using_pus_60000_min10_max20PUs_1SUs_square100grid_splat_2020_06_29_19_50.txt\"\n",
    "sensor_dataset_name = \"dynamic_pus_3600sensor_60000_min10_max20PUs_1SUs_square100grid_splat_2020_06_29_19_50.txt\"\n",
    "max_dataset_name = \"dynamic_pus_max_power_60000_min10_max20PUs_1SUs_square100grid_splat_2020_06_29_19_50.txt\"\n",
    "with open('/'.join(image_dir.split('/')[:-1]) + '/datasets' + dtime + '.txt', 'w') as set_file:\n",
    "    set_file.write(pu_dataset_name + \"\\n\")\n",
    "    set_file.write(sensor_dataset_name + \"\\n\")\n",
    "    set_file.write(max_dataset_name)\n",
    "\n",
    "pu_dataframe = pd.read_csv('../../../java_workspace/research/spectrum_allocation/resources/data/'\n",
    "                        + pu_dataset_name, delimiter=',', header=None, names=pu_cols)\n",
    "sensor_dataframe = pd.read_csv('../../../java_workspace/research/spectrum_allocation/resources/data/'\n",
    "                        + sensor_dataset_name, delimiter=',', header=None, names=sensor_cols)\n",
    "dataframe_max = pd.read_csv('../../../java_workspace/research/spectrum_allocation/resources/data/'\n",
    "                            + max_dataset_name, delimiter=',', header=None)\n",
    "\n",
    "pu_dataframe.reset_index(drop=True, inplace=True)\n",
    "sensor_dataframe.reset_index(drop=True, inplace=True)\n",
    "dataframe_max.reset_index(drop=True, inplace=True)\n",
    "\n",
    "pu_dataframe_tot = pd.concat([pu_dataframe, \n",
    "                              dataframe_max.iloc[:, dataframe_max.columns.values[-1:]]],\n",
    "                             axis=1,ignore_index=True)\n",
    "sensor_dataframe_tot = pd.concat([sensor_dataframe,\n",
    "                                  dataframe_max.iloc[:, dataframe_max.columns.values[-1:]]],\n",
    "                                 axis=1, ignore_index=True)\n",
    "\n",
    "idx = pu_dataframe_tot[pu_dataframe_tot[pu_dataframe_tot.columns[-1]] == -float('inf')].index\n",
    "pu_dataframe_tot.drop(idx, inplace=True)\n",
    "sensor_dataframe_tot.drop(idx, inplace=True)\n",
    "\n",
    "pu_data_reg = pu_dataframe_tot.values\n",
    "sensor_data_reg = sensor_dataframe_tot.values\n",
    "sensor_data_reg[sensor_data_reg < noise_floor] = noise_floor\n",
    "# data_reg = np.concatenate((dataframe_tot.values[:, 0:dataframe_tot.shape[1]-3], \n",
    "#                            dataframe_tot.values[:, dataframe_tot.shape[1]-1:dataframe_tot.shape[1]]), axis=1)\n",
    "# data_class = dataframe_tot.values[:, 0:dataframe_tot.shape[1]-1]\n",
    "# y_class_power = dataframe_tot.values[:, -1]\n",
    "sensors_location = []\n",
    "with open(sensors_file_path, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        line = line.split(',')\n",
    "        sensors_location.append(Point(int(float(line[0])), int(float(line[1]))))\n",
    "del dataframe_max, pu_dataframe, pu_dataframe_tot, sensor_dataframe, sensor_dataframe_tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39539, 67)\n",
      "(39539, 3606)\n"
     ]
    }
   ],
   "source": [
    "print(pu_data_reg.shape)\n",
    "print(sensor_data_reg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_reg = np.concatenate((data_reg[:,:2500], np.ones((4000, 1)), data_reg[:, 2500:2504],\n",
    "               data_reg[:, 2505:]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pu_data_reg = pu_data_reg[:][:30000]\n",
    "sensor_data_reg = sensor_data_reg[:][:30000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_reg[512:1024, :] = data_reg[:512, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_reg[4096:8192, sensors_num:] = data_reg[:4096, sensors_num:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 10.     62.     30.    -19.362  71.     26.    -23.844  24.     53.\n",
      "  -7.168  90.     75.     -8.733  34.     13.    -23.463  12.      9.\n",
      "  -7.096   4.     22.    -12.819  66.     65.    -10.794   7.     20.\n",
      "  -7.626   4.     36.    -28.694   1.     56.     17.    -16.531   1.\n",
      "     nan     nan     nan     nan     nan     nan     nan     nan     nan\n",
      "     nan     nan     nan     nan     nan     nan     nan     nan     nan\n",
      "     nan     nan     nan     nan     nan     nan     nan     nan     nan\n",
      "     nan     nan     nan   2.312]\n",
      "[ 10.     62.     30.    -19.362  71.     26.    -23.844  24.     53.\n",
      "  -7.168  90.     75.     -8.733  34.     13.    -23.463  12.      9.\n",
      "  -7.096   4.     22.    -12.819  66.     65.    -10.794   7.     20.\n",
      "  -7.626   4.     36.    -28.694   1.     56.     17.    -16.531   1.\n",
      "     nan     nan     nan     nan     nan     nan     nan     nan     nan\n",
      "     nan     nan     nan     nan     nan     nan     nan     nan     nan\n",
      "     nan     nan     nan     nan     nan     nan     nan     nan     nan\n",
      "     nan     nan     nan   2.312]\n"
     ]
    }
   ],
   "source": [
    "print(data_reg[10, :])\n",
    "print(data_reg[266, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidian_distance(p1: Point, p2: Point):\n",
    "    return ((p1.x - p2.x) ** 2 + (p1.y - p2.y) ** 2) ** 0.5\n",
    "\n",
    "def calculate_mu_sigma(data, num_pus):\n",
    "    sum_non_noise = 0\n",
    "    for pu_n in range(num_pus): # calculate mu\n",
    "        sum_non_noise += data[pu_n*3+2]\n",
    "    mu = ((max_x * max_y - num_pus) * noise_floor + sum_non_noise)/(max_x * max_y)\n",
    "    sum_square = 0\n",
    "    for pu_n in range(num_pus): # calculate sigma\n",
    "        sum_square += (data[pu_n*3+2]-mu)**2\n",
    "    sum_square += (max_x * max_y - num_pus) * (noise_floor - mu)**2\n",
    "    sigma = math.sqrt(sum_square/(max_x * max_y))\n",
    "    return mu, sigma\n",
    "\n",
    "def get_pu_param(pu_shape: str, intensity_degradation: str, pu_p: float, noise_floor: float, slope: float):\n",
    "    pu_param = None\n",
    "    if pu_shape == 'circle':\n",
    "        if intensity_degradation == \"linear\":\n",
    "            pu_param = Circle(int((pu_p - noise_floor) / slope)) # linear\n",
    "        elif intensity_degradation == \"log\":\n",
    "            pu_param = Circle(int(10 ** ((pu_p - noise_floor) / (10 *slope)))) # log_based\n",
    "    elif pu_shape == 'square':\n",
    "        if intensity_degradation == \"linear\":\n",
    "            pu_param = Square(int(2 ** 0.5 * (pu_p - noise_floor) / slope)) # linear\n",
    "        elif intensity_degradation == \"log\":\n",
    "            pu_param = Square(int(2 ** 0.5 * 10 ** ((pu_p - noise_floor) / (10 *slope)))) # log_based\n",
    "    elif pu_shape == 'point':\n",
    "        pu_param = None\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported PU shape(create_image)! \", pu_shape)\n",
    "    return pu_param\n",
    "\n",
    "def create_image(pu_data, sensor_data, slope, sensors_num, style=\"raw_power_z_score\", noise_floor=-90,\n",
    "                 pu_shape= 'circle', pu_param=None, su_shape='circle', su_param=None,\n",
    "                 intensity_degradation=\"log\", max_pu_power: float=0):  \n",
    "    # style = {\"raw_power_zscore_norm\", \"image_intensity\", \"raw_power_min_max_norm\"}\n",
    "    # intensity_degradation= {\"log\", \"linear\"}\n",
    "    # if param is None, it's automatically calculated. Highest brightness(or power value) (255 or 1.) would\n",
    "    # assigned to the center(PU location) and radius(side) would be calculated based on its power, slope, and noise floor.\n",
    "    # If it is given, intensity(power) of pixel beside center would be calculated in the same fashin with an exception that \n",
    "    # intensity below zero(noise_floor) would be replaced by zero(noise_floor)\n",
    "    if style == \"raw_power_min_max_norm\":\n",
    "        # In this way, PUs' location are replaced with their power(dBm) and the power would fade with \n",
    "        # slope till gets noise_floor(in circle shape)\n",
    "        \n",
    "        # creating pu matrix\n",
    "        image = np.zeros((1,number_image_channels,max_x, max_y), dtype=float_memory_used)\n",
    "        if True:  # pus\n",
    "            pus_num = int(pu_data[0])\n",
    "#             print(pus_num)\n",
    "            for pu_i in range(pus_num):\n",
    "                pu_x = max(0, min(max_x-1, int(pu_data[pu_i * 3 + 1]))) \n",
    "                pu_y = max(0, min(max_x-1, int(pu_data[pu_i * 3 + 2])))\n",
    "                pu_p = pu_data[pu_i * 3 + 3]\n",
    "                pu_channel = int(abs(pu_p - max_pu_power))//5\n",
    "#                 print(pu_x, pu_y, pu_p)\n",
    "                if pu_param is None:\n",
    "                    pu_param_p = get_pu_param(pu_shape, intensity_degradation, pu_p, noise_floor, slope)\n",
    "                else:\n",
    "                    pu_param_p = pu_param\n",
    "                points = points_inside_shape(center=Point(pu_x, pu_y), shape=pu_shape, param=pu_param_p)\n",
    "                for point in points:\n",
    "                    if 0 <= point.p.x < max_x and 0 <= point.p.y < max_y: # TODO should pass image size\n",
    "                        if intensity_degradation == \"linear\":\n",
    "                            image[0][pu_channel][point.p.x][point.p.y] += (pu_p - slope * point.dist - noise_floor)/(\n",
    "                                max_pu_power - noise_floor)\n",
    "                        elif intensity_degradation == \"log\":\n",
    "                            if point.dist < 1:\n",
    "                                image[0][pu_channel][point.p.x][point.p.y] += (pu_p - noise_floor) / (max_pu_power - noise_floor)\n",
    "                            else:\n",
    "                                image[0][pu_channel][point.p.x][point.p.y] += (pu_p - slope * 10*math.log10(point.dist) - noise_floor)/(\n",
    "                                    max_pu_power - noise_floor)\n",
    "        if True:  # sensors\n",
    "            ss_param, ss_shape = pu_param, pu_shape\n",
    "            ss_channel_offset = 6 # number of channels for pus\n",
    "            for ss_i in range(sensors_num):\n",
    "                ss_x, ss_y, ss_p = max(0, min(max_x-1, int(sensors_location[ss_i].x))), max(0, min(max_x-1, int(\n",
    "                    sensors_location[ss_i].y))), max(noise_floor, sensor_data[ss_i])\n",
    "#                 ss_channel =  int(abs(ss_p - max_pu_power))//5\n",
    "                ss_channel = 0\n",
    "#                 if -62.5 <= ss_p < -50.0:\n",
    "#                     ss_channel = 1\n",
    "#                 elif -75.0 <= ss_p < -62.6:\n",
    "#                     ss_channel = 2\n",
    "#                 elif -87.5 <= ss_p < -75.0:\n",
    "#                     ss_channel = 3\n",
    "#                 elif -100.0 <= ss_p < -87.5:\n",
    "#                     ss_channel = 4\n",
    "# #                 elif -70.0 <= ss_p < -65.0:\n",
    "# #                     ss_channel = 5\n",
    "#                 elif ss_p < -100.0:\n",
    "#                     ss_channel = 5\n",
    "                ss_channel += ss_channel_offset\n",
    "                if ss_param is None:\n",
    "                    ss_param_p = get_pu_param(ss_shape, intensity_degradation, ss_p,\n",
    "                                              noise_floor, slope)\n",
    "                    ss_param_p = Circle(3)\n",
    "                else:\n",
    "                    ss_param_p = ss_param\n",
    "                points = points_inside_shape(center=Point(ss_x, ss_y), shape=ss_shape,\n",
    "                                             param=ss_param_p)\n",
    "                for point in points:\n",
    "                    if 0 <= point.p.x < max_x and 0 <= point.p.y < max_y: # TODO should pass image size\n",
    "                        if intensity_degradation == \"linear\":\n",
    "                            image[0][ss_channel][point.p.x][point.p.y] += (ss_p - slope * point.dist - noise_floor)/(\n",
    "                                max_pu_power - noise_floor)\n",
    "                        elif intensity_degradation == \"log\":\n",
    "                            if point.dist < 1:\n",
    "                                image[0][ss_channel][point.p.x][point.p.y] += (ss_p - noise_floor) / (max_pu_power - noise_floor)\n",
    "                            else:\n",
    "                                image[0][ss_channel][point.p.x][point.p.y] += (ss_p - slope * 10*math.log10(point.dist) - noise_floor)/(\n",
    "                                    max_pu_power - noise_floor)\n",
    "        del points\n",
    "        # creating su matrix\n",
    "        su_num_idx = pus_num * 3 + 1\n",
    "        su_num = int(pu_data[su_num_idx])\n",
    "#         print(su_num)\n",
    "#         su_num = (len(data) - pus_num * (3 if not sensors else 1)) // 2\n",
    "#         if not (len(data) - pus_num * (3 if not sensors else 1)) % 2:\n",
    "#             raise ValueError(\"Data provided is not correct; can't get SUs' information(create_image)\")\n",
    "        if su_param is None:\n",
    "            # if su_param is unavailable, a circle(square) with radius(side) 1 is created\n",
    "            if su_shape == 'circle':\n",
    "                su_param = Circle(1)\n",
    "            elif su_shape == 'square':\n",
    "                su_param = Square(1)\n",
    "            elif su_shape == 'point':\n",
    "                su_param = None\n",
    "            else:\n",
    "                raise ValueError(\"Unsupported SU shape(create_image)! \", su_shape)\n",
    "        \n",
    "        for su_i in range(su_num - 1):\n",
    "            su_x = max(0, min(max_x-1, int(pu_data[su_num_idx + su_i * 3 + 1])))\n",
    "            su_y = max(0, min(max_x-1, int(pu_data[su_num_idx + su_i * 3 + 2])))\n",
    "            su_p = pu_data[su_num_idx + su_i * 3 + 3]\n",
    "#             su_p = su_intensity\n",
    "            points = points_inside_shape(center=Point(su_x, su_y), param=su_param, shape=su_shape)\n",
    "            su_channel = 0 if number_image_channels == 1 else -1\n",
    "            for point in points:\n",
    "                if 0 <= point.p.x < max_x and 0 <= point.p.y < max_y: # TODO should pass image size\n",
    "                    if intensity_degradation == \"linear\":\n",
    "                            su_val = (su_p - slope * point.dist - noise_floor)/(max_pu_power - noise_floor)\n",
    "                    elif intensity_degradation == \"log\":\n",
    "                        if point.dist < 1:\n",
    "                            su_val = (su_p - noise_floor) / (max_pu_power - noise_floor)\n",
    "                        else:\n",
    "                            su_val = (su_p - slope * 10*math.log10(point.dist) - noise_floor)/(\n",
    "                                max_pu_power - noise_floor)\n",
    "                    image[0][su_channel][point.p.x][point.p.y] += su_val\n",
    "            del points\n",
    "        # the last and  target SU\n",
    "        su_intensity = 1.\n",
    "        su_x = max(0, min(max_x-1, int(pu_data[su_num_idx + (su_num - 1) * 3 + 1])))\n",
    "        su_y = max(0, min(max_x-1, int(pu_data[su_num_idx + (su_num - 1) * 3 + 2])))\n",
    "#         print(su_x, su_y)\n",
    "        points = points_inside_shape(center=Point(su_x, su_y), param=su_param, shape=su_shape)\n",
    "        su_channel = 0 if number_image_channels == 1 else -1\n",
    "        for point in points:\n",
    "            if 0 <= point.p.x < max_x and 0 <= point.p.y < max_y: # TODO should pass image size\n",
    "                image[0][su_channel][point.p.x][point.p.y] += su_intensity\n",
    "        del points\n",
    "        return image\n",
    "        \n",
    "#         pu_image = [[(noise_floor - mu)/sigma] * max_y for _ in range(max_x)]\n",
    "    elif style == \"image_intensity\":\n",
    "        # creating PU image\n",
    "        image = np.zeros((1,number_image_channels,max_x, max_y), dtype=float_memory_used)\n",
    "        for pu_i in range(pus_num):\n",
    "            pu_x, pu_y, pu_p = max(0, min(max_x-1, int(data[pu_i*3]))), max(0, min(max_x-1, int(data[pu_i*3+1]))), data[pu_i*3+2]\n",
    "            if pu_param is None:\n",
    "                pu_param_p = get_pu_param(pu_shape, intensity_degradation, pu_p, noise_floor, slope)\n",
    "            else:\n",
    "                pu_param_p = pu_param\n",
    "            points = points_inside_shape(center=Point(pu_x, pu_y), shape=pu_shape, param=pu_param_p)\n",
    "            for point in points:\n",
    "                if 0 <= point.p.x < max_x and 0 <= point.p.y < max_y: # TODO should pass image size\n",
    "                    if intensity_degradation == \"linear\":\n",
    "                        image[0][0][point.p.x][point.p.y] += max((pu_p - slope * point.dist + abs(noise_floor))\n",
    "                                                              /(pu_p + abs(noise_floor)), 0)\n",
    "                    elif intensity_degradation == \"log\":\n",
    "                        if point.dist < 1:\n",
    "                            image[0][0][point.p.x][point.p.y] = 1\n",
    "                        else:\n",
    "                            image[0][0][point.p.x][point.p.y] += max((pu_p - slope * 10*math.log10(point.dist) + abs(noise_floor))\n",
    "                                                                 /(pu_p + abs(noise_floor)), 0)\n",
    "                    image[0][0][point.p.x][point.p.y] = min(image[0][0][point.p.x][point.p.y], 1.0)\n",
    "                        \n",
    "        # creating SU image\n",
    "        su_num = (len(data) - pus_num * 3) // 2\n",
    "        if not (len(data) - pus_num * 3) % 2:\n",
    "            raise ValueError(\"Data provided is not correct; can't get SUs' information(create_image)\")\n",
    "#         su_image = np.zeros((max_x, max_y), dtype=float_memory_used)\n",
    "        if su_param is None:\n",
    "            # if su_param is unavailable, a circle(square) with radius(side) 1 is created\n",
    "            if su_shape == 'circle':\n",
    "                su_param = Circle(1)\n",
    "            elif su_shape == 'square':\n",
    "                su_param = Square(1)\n",
    "            elif su_shape == 'point':\n",
    "                su_param = None\n",
    "            else:\n",
    "                raise ValueError(\"Unsupported SU shape(create_image)! \", su_shape)\n",
    "        su_intensity = 1.\n",
    "        for su_i in range(su_num):\n",
    "            su_x, su_y, su_p = max(0, min(max_x-1, int(data[pus_num * (3 if not sensors else 1) +su_i*2]))\n",
    "                                  ), max(0, min(max_x-1, int(data[pus_num * (3 if not sensors else 1) + su_i*2+1]))), su_intensity\n",
    "            points = points_inside_shape(center=Point(su_x, su_y), param=su_param, shape=su_shape)\n",
    "            for point in points:\n",
    "                if 0 <= point.p.x < max_x and 0 <= point.p.y < max_y: # TODO should pass image size\n",
    "                    if number_image_channels > 1:\n",
    "                        image[0][1][point.p.x][point.p.y] = su_intensity\n",
    "                    elif number_image_channels == 1:\n",
    "                        image[0][0][point.p.x][point.p.y] = su_intensity\n",
    "#         return np.array([pu_image, su_image, [[0.] * max_y for _ in range(max_x)]], dtype='float32') # return like this to be able to display as an RGB image with pyplot.imshow(imsave)\n",
    "#         return np.append(pu_image, su_image, axis=0)\n",
    "        return image\n",
    "        \n",
    "            \n",
    "    else:\n",
    "        raise ValueError(\"Unsupported style(create_image)! \", style)\n",
    "        \n",
    "def points_inside_shape(center: Point, shape: str, param)-> list:\n",
    "    # This function returns points+distance around center with defined shape\n",
    "    if shape == 'circle':\n",
    "        # First creates points inside a square(around orgigin) with 2*r side and then remove those with distance > r.\n",
    "        # Shift all remaining around center. O(4r^2)\n",
    "        r, origin = param.r, Point(0, 0)\n",
    "        square_points = set((Point(x, y) for x in range(max(-r, -max_x), min(r, max_x) + 1) \n",
    "                             for y in range(max(-r, -max_y), min(r, max_y) + 1)))\n",
    "        points = []\n",
    "        while square_points:\n",
    "            p = square_points.pop()\n",
    "            dist = euclidian_distance(p, origin)\n",
    "            if dist <= r:\n",
    "                points.append(PointWithDistance(Point(p.x + center.x, p.y + center.y), dist))\n",
    "                if p.x != 0:\n",
    "                    points.append(PointWithDistance(Point(-p.x + center.x, p.y + center.y), dist))\n",
    "                    square_points.remove(Point(-p.x, p.y))\n",
    "                if p.y != 0:\n",
    "                    points.append(PointWithDistance(Point(p.x + center.x, -p.y + center.y), dist))\n",
    "                    square_points.remove(Point(p.x, -p.y))\n",
    "                if p.x != 0 and p.y != 0:\n",
    "                    points.append(PointWithDistance(Point(-p.x + center.x, -p.y + center.y), dist))\n",
    "                    square_points.remove(Point(-p.x, -p.y))\n",
    "        del square_points\n",
    "        return points\n",
    "    elif shape == 'square':\n",
    "        half_side = param.side // 2\n",
    "        return [PointWithDistance(Point(x, y), euclidian_distance(Point(x, y), center)) for x in range(-half_side + center.x,\n",
    "                                                                                               half_side + center.x+1) \n",
    "                         for y in range(-half_side + center.y, half_side + center.y + 1)]\n",
    "    elif shape == 'point':\n",
    "        return [PointWithDistance(center, 0)]\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported shape(points_inside_shape)! \", shape)\n",
    "        \n",
    "def read_image(image_num):\n",
    "    if style == \"image_intensity\":\n",
    "        image = plt.imread(image_dir + '/image' + str(image_num)+'.png')\n",
    "        image = np.swapaxes(image, 0, 2)\n",
    "        image = np.array(image[:number_image_channels], dtype=float_memory_used).reshape(1, number_image_channels, max_x, max_y)\n",
    "    elif  style == \"raw_power_min_max_norm\" or style == \"raw_power_zscore_norm\":\n",
    "        suffix = 'npz'  # npy, npz\n",
    "        image = np.load(image_dir + '/image' + str(image_num) + '.' + suffix)  \n",
    "        if type(image) == np.lib.npyio.NpzFile:\n",
    "            image = image['a']\n",
    "    \n",
    "    return image\n",
    "    \n",
    "# TODO: Consider using min_max normalization becasue difference between values using\n",
    "# z-score is huge since most of the pixels have the same value, noise floor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.000e+01, 6.000e+00, 9.000e+00, 1.600e+01, 3.200e+01, 4.200e+01,\n",
       "        7.600e+01, 8.400e+01, 1.360e+02, 1.670e+02, 2.610e+02, 3.120e+02,\n",
       "        4.160e+02, 5.200e+02, 5.850e+02, 7.540e+02, 9.580e+02, 1.032e+03,\n",
       "        1.237e+03, 1.306e+03, 1.452e+03, 1.460e+03, 1.491e+03, 1.537e+03,\n",
       "        1.406e+03, 1.361e+03, 1.369e+03, 1.274e+03, 1.283e+03, 1.117e+03,\n",
       "        1.024e+03, 1.051e+03, 1.006e+03, 1.057e+03, 9.080e+02, 9.320e+02,\n",
       "        8.250e+02, 7.970e+02, 7.910e+02, 7.250e+02, 7.520e+02, 7.610e+02,\n",
       "        6.850e+02, 6.920e+02, 6.190e+02, 5.770e+02, 5.570e+02, 6.090e+02,\n",
       "        5.630e+02, 5.100e+02, 4.450e+02, 3.600e+02, 3.160e+02, 2.410e+02,\n",
       "        1.840e+02, 1.720e+02, 1.210e+02, 9.600e+01, 6.500e+01, 4.800e+01,\n",
       "        5.100e+01, 4.400e+01, 3.600e+01, 3.100e+01, 2.800e+01, 1.300e+01,\n",
       "        1.800e+01, 1.300e+01, 1.100e+01, 8.000e+00, 1.400e+01, 6.000e+00,\n",
       "        3.000e+00, 7.000e+00, 4.000e+00, 3.000e+00, 7.000e+00, 4.000e+00,\n",
       "        0.000e+00, 4.000e+00, 3.000e+00, 0.000e+00, 2.000e+00, 1.000e+00,\n",
       "        1.000e+00, 3.000e+00, 1.000e+00, 2.000e+00, 1.000e+00, 2.000e+00,\n",
       "        2.000e+00, 2.000e+00, 0.000e+00, 0.000e+00, 2.000e+00, 0.000e+00,\n",
       "        0.000e+00, 5.000e+00, 2.000e+00, 3.000e+00, 4.000e+00]),\n",
       " array([-110.        , -109.22307921, -108.44615842, -107.66923762,\n",
       "        -106.89231683, -106.11539604, -105.33847525, -104.56155446,\n",
       "        -103.78463366, -103.00771287, -102.23079208, -101.45387129,\n",
       "        -100.6769505 ,  -99.9000297 ,  -99.12310891,  -98.34618812,\n",
       "         -97.56926733,  -96.79234653,  -96.01542574,  -95.23850495,\n",
       "         -94.46158416,  -93.68466337,  -92.90774257,  -92.13082178,\n",
       "         -91.35390099,  -90.5769802 ,  -89.80005941,  -89.02313861,\n",
       "         -88.24621782,  -87.46929703,  -86.69237624,  -85.91545545,\n",
       "         -85.13853465,  -84.36161386,  -83.58469307,  -82.80777228,\n",
       "         -82.03085149,  -81.25393069,  -80.4770099 ,  -79.70008911,\n",
       "         -78.92316832,  -78.14624752,  -77.36932673,  -76.59240594,\n",
       "         -75.81548515,  -75.03856436,  -74.26164356,  -73.48472277,\n",
       "         -72.70780198,  -71.93088119,  -71.1539604 ,  -70.3770396 ,\n",
       "         -69.60011881,  -68.82319802,  -68.04627723,  -67.26935644,\n",
       "         -66.49243564,  -65.71551485,  -64.93859406,  -64.16167327,\n",
       "         -63.38475248,  -62.60783168,  -61.83091089,  -61.0539901 ,\n",
       "         -60.27706931,  -59.50014851,  -58.72322772,  -57.94630693,\n",
       "         -57.16938614,  -56.39246535,  -55.61554455,  -54.83862376,\n",
       "         -54.06170297,  -53.28478218,  -52.50786139,  -51.73094059,\n",
       "         -50.9540198 ,  -50.17709901,  -49.40017822,  -48.62325743,\n",
       "         -47.84633663,  -47.06941584,  -46.29249505,  -45.51557426,\n",
       "         -44.73865347,  -43.96173267,  -43.18481188,  -42.40789109,\n",
       "         -41.6309703 ,  -40.8540495 ,  -40.07712871,  -39.30020792,\n",
       "         -38.52328713,  -37.74636634,  -36.96944554,  -36.19252475,\n",
       "         -35.41560396,  -34.63868317,  -33.86176238,  -33.08484158,\n",
       "         -32.30792079,  -31.531     ]),\n",
       " <a list of 101 Patch objects>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(sensor_data_reg[:,0:1:sensors_num], bins='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving images once to save time\n",
    "# run this cell just for creating images\n",
    "def creating_image(start, end):\n",
    "    # for image_num in range(115, data_reg.shape[0]):\n",
    "    # for image_num in range(1625, 5000):\n",
    "    for image_num in tqdm.tqdm(range(start, end+1)):  #4463, data_reg.shape[0]\n",
    "        image = create_image(pu_data=pu_data_reg[image_num],\n",
    "                             sensor_data=sensor_data_reg[image_num],\n",
    "                             slope=slope, style=style, \n",
    "                             noise_floor=noise_floor,\n",
    "                             pu_shape=pu_shape, su_shape=su_shape, su_param=su_param, \n",
    "                             sensors_num=sensors_num, \n",
    "                             intensity_degradation=intensity_degradation, \n",
    "                             max_pu_power=0.0)\n",
    "        if style == \"image_intensity\":\n",
    "            if number_image_channels != 3:\n",
    "                image = np.append(np.array(image[0]), np.zeros((3-number_image_channels,max_x, max_y), \n",
    "                                                               dtype=float_memory_used), axis=0)\n",
    "            image_save = np.swapaxes(image, 0, 2)\n",
    "            plt.imsave(image_dir + '/image' + str(image_num)+'.png', image_save)\n",
    "        elif style == \"raw_power_min_max_norm\" or style == \"raw_power_zscore_norm\":\n",
    "    #         np.save(image_dir + '/image' + str(image_num), image)\n",
    "            np.savez_compressed(image_dir + '/image' + str(image_num), a=image)\n",
    "        del image\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [2:28:53<00:00,  2.98s/it]  \n",
      "100%|██████████| 3000/3000 [2:29:59<00:00,  3.00s/it]\n",
      "100%|██████████| 3000/3000 [2:30:01<00:00,  3.00s/it]\n",
      "100%|██████████| 3000/3000 [2:30:16<00:00,  3.01s/it]\n",
      "100%|██████████| 3000/3000 [2:30:16<00:00,  3.01s/it]\n",
      "100%|██████████| 3000/3000 [2:30:21<00:00,  3.01s/it]\n",
      "100%|██████████| 3000/3000 [2:30:26<00:00,  3.01s/it]\n",
      "100%|██████████| 3000/3000 [2:30:43<00:00,  3.01s/it]\n",
      "100%|██████████| 3000/3000 [2:31:02<00:00,  3.02s/it]\n",
      "100%|██████████| 3000/3000 [2:31:11<00:00,  3.02s/it]\n"
     ]
    }
   ],
   "source": [
    "jobs = []\n",
    "proc_sizes = [pu_data_reg.shape[0]//number_of_proccessors] * (number_of_proccessors)\n",
    "proc_sizes[-1] += pu_data_reg.shape[0]%number_of_proccessors\n",
    "proc_idx = [(sum(proc_sizes[:i]), sum(proc_sizes[:i+1])-1) for i in range(number_of_proccessors)]\n",
    "\n",
    "for i in range(number_of_proccessors):\n",
    "    p = Process(target=creating_image, args=(proc_idx[i][0], proc_idx[i][1]))\n",
    "    jobs.append(p)\n",
    "    p.start()\n",
    "for i in range(number_of_proccessors):\n",
    "    jobs[i].join()\n",
    "\n",
    "for i in range(number_of_proccessors):\n",
    "    jobs[i].terminate()\n",
    "    jobs[i].close()\n",
    "del jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for idx, point in enumerate(sensors_location):\n",
    "    print(idx+1, point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, point in enumerate(sensors_location):\n",
    "    print(idx+1, point,\"close\") if math.sqrt((point.x-917)**2+(point.y-415)**2)<=1.5 else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = [0, 0, 0, 0]\n",
    "idxx = [[],[],[],[]]\n",
    "for i in range(data_reg.shape[0]):\n",
    "    pus_c = int(data_reg[i][0]) * 3 + 1\n",
    "    idx = int(data_reg[i][pus_c]) - 1\n",
    "    count[idx] += 1\n",
    "    idxx[idx].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(count)\n",
    "print(idxx[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "imm = read_image(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imm[300].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_reg[:,-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 13.     72.     34.    -23.555  36.     65.    -17.024  83.     86.\n",
      " -20.172  51.      4.     -0.146  68.     70.    -18.061  14.     38.\n",
      " -27.592  62.     60.     -3.984   6.     41.    -10.137  96.     29.\n",
      " -23.763  26.      4.    -28.16    6.     51.     -2.209  68.     92.\n",
      " -18.183  46.     15.    -13.68    1.     76.     43.     26.424   0.\n",
      "     nan     nan     nan     nan     nan     nan     nan     nan     nan\n",
      "     nan     nan     nan     nan     nan     nan     nan     nan     nan\n",
      "     nan     nan     nan   3.795]\n",
      "[-88.826 -90.912 -90.741 ...  26.424   0.      3.795]\n"
     ]
    }
   ],
   "source": [
    "print(pu_data_reg[0])\n",
    "print(sensor_data_reg[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_image_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f5bccc08190>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 4320x4320 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(60,60))         # Sample figsize in inches\n",
    "sns.heatmap(imm[0][7], ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model(num_filters, kernel_lam, bias_lam):\n",
    "#     num_filters, lam = 5, 5\n",
    "    data_format = 'channels_first'\n",
    "    convolution_init, dense_init = \"lecun_normal\", \"RandomNormal\"\n",
    "    convolution_filter, dense_filter = 'selu', 'linear' #softsign, sigmoid; relu, linear\n",
    "    filter_shape, pool_size = (3, 3), (2,2)\n",
    "    cnn = models.Sequential()\n",
    "    cnn.add(layers.Conv2D(num_filters, filter_shape, padding='same', activation=convolution_filter, \n",
    "                          input_shape=(number_image_channels, max_x, max_y), data_format=data_format,\n",
    "                          kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "                          kernel_initializer=convolution_init))\n",
    "#     cnn.add(BatchNormalization(axis=1))\n",
    "#     cnn.add(layers.Conv2D(4*num_filters, filter_shape, padding='same', activation=convolution_filter, \n",
    "#                           input_shape=(number_image_channels, max_x, max_y), data_format=data_format,\n",
    "#                           kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "#                           kernel_initializer='lecun_normal'))\n",
    "    cnn.add(layers.MaxPooling2D(pool_size=pool_size, data_format=data_format))\n",
    "    cnn.add(BatchNormalization(axis=1))\n",
    "#     cnn.add(layers.Dropout(0.25))\n",
    "    \n",
    "    cnn.add(layers.Conv2D(2*num_filters, filter_shape,padding='same', activation=convolution_filter, data_format=data_format, \n",
    "                         kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "                         kernel_initializer=convolution_init))\n",
    "#     cnn.add(BatchNormalization(axis=1))\n",
    "#     cnn.add(layers.Conv2D(3*num_filters, filter_shape, padding='same', activation=convolution_filter, \n",
    "#                           input_shape=(number_image_channels, max_x, max_y), data_format=data_format,\n",
    "#                           kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "#                           kernel_initializer='lecun_normal'))\n",
    "    cnn.add(layers.MaxPooling2D(pool_size=pool_size, data_format=data_format))\n",
    "    cnn.add(BatchNormalization(axis=1))\n",
    "#     cnn.add(layers.Dropout(0.25))\n",
    "    \n",
    "    cnn.add(layers.Conv2D(3*num_filters, filter_shape, padding='same', activation=convolution_filter, data_format=data_format, \n",
    "                         kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "                         kernel_initializer=convolution_init))\n",
    "#     cnn.add(BatchNormalization(axis=1))\n",
    "#     cnn.add(layers.Conv2D(2*num_filters, filter_shape, padding='same', activation=convolution_filter, \n",
    "#                           input_shape=(number_image_channels, max_x, max_y), data_format=data_format,\n",
    "#                           kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "#                           kernel_initializer='lecun_normal'))\n",
    "    cnn.add(layers.MaxPooling2D(pool_size, data_format=data_format))\n",
    "    cnn.add(BatchNormalization(axis=1))\n",
    "#     cnn.add(layers.Dropout(0.25))\n",
    "    \n",
    "    cnn.add(layers.Conv2D(4*num_filters, filter_shape, padding='same', activation=convolution_filter, data_format=data_format, \n",
    "                         kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "                         kernel_initializer=convolution_init))\n",
    "#     cnn.add(BatchNormalization(axis=1))\n",
    "#     cnn.add(layers.Conv2D(num_filters, filter_shape, padding='same', activation=convolution_filter, data_format=data_format, \n",
    "#                          kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "#                          kernel_initializer='lecun_normal'))\n",
    "    cnn.add(layers.MaxPooling2D(pool_size, data_format=data_format))\n",
    "    cnn.add(BatchNormalization(axis=1))\n",
    "#     cnn.add(layers.Dropout(0.25))\n",
    "# from here for 1000\n",
    "    if max(max_x, max_y) == 1000:\n",
    "        cnn.add(layers.Conv2D(4*num_filters, filter_shape, padding='same', activation=convolution_filter, data_format=data_format, \n",
    "                             kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "                             kernel_initializer=convolution_init))\n",
    "    #     cnn.add(BatchNormalization(axis=1))\n",
    "    #     cnn.add(layers.Conv2D(num_filters, filter_shape, padding='same', activation=convolution_filter, data_format=data_format, \n",
    "    #                          kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "    #                          kernel_initializer='lecun_normal'))\n",
    "        cnn.add(layers.MaxPooling2D(pool_size, data_format=data_format))\n",
    "        cnn.add(BatchNormalization(axis=1))\n",
    "    #     cnn.add(layers.Dropout(0.25))\n",
    "\n",
    "        cnn.add(layers.Conv2D(4*num_filters, filter_shape, padding='same', activation=convolution_filter, data_format=data_format, \n",
    "                             kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam), \n",
    "                             kernel_initializer=convolution_init))\n",
    "    #     cnn.add(BatchNormalization(axis=1))\n",
    "    #     cnn.add(layers.Conv2D(2*num_filters, filter_shape, padding='same', activation=convolution_filter, data_format=data_format, \n",
    "    #                          kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "    #                          kernel_initializer='lecun_normal'))\n",
    "        cnn.add(layers.MaxPooling2D(pool_size, data_format=data_format))\n",
    "        cnn.add(BatchNormalization(axis=1))\n",
    "    #     cnn.add(layers.Dropout(0.25))\n",
    "\n",
    "        cnn.add(layers.Conv2D(4*num_filters, filter_shape, padding='same', activation=convolution_filter, data_format=data_format, \n",
    "                             kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam), \n",
    "                             kernel_initializer=convolution_init))\n",
    "    #     cnn.add(BatchNormalization(axis=1))\n",
    "    #     cnn.add(layers.Conv2D(3*num_filters, filter_shape, padding='same', activation=convolution_filter, data_format=data_format, \n",
    "    #                          kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "    #                          kernel_initializer='lecun_normal'))\n",
    "        cnn.add(layers.MaxPooling2D(pool_size, data_format=data_format))\n",
    "        cnn.add(BatchNormalization(axis=1))\n",
    "    #     cnn.add(layers.Dropout(0.25))\n",
    "    \n",
    "    cnn.add(layers.Flatten())\n",
    "    cnn.add(layers.Dense(20, activation=convolution_filter, kernel_regularizer=regularizers.l2(kernel_lam),\n",
    "                         bias_regularizer=regularizers.l2(bias_lam), kernel_initializer=convolution_init))\n",
    "    cnn.add(BatchNormalization())\n",
    "    cnn.add(layers.Dense(20, activation=convolution_filter, kernel_regularizer=regularizers.l2(kernel_lam),\n",
    "                         bias_regularizer=regularizers.l2(bias_lam), kernel_initializer=convolution_init))\n",
    "#     cnn.add(BatchNormalization())\n",
    "    cnn.add(layers.Dense(1, activation=dense_filter, kernel_regularizer=regularizers.l2(kernel_lam),\n",
    "                         bias_regularizer=regularizers.l2(bias_lam), kernel_initializer=dense_init))\n",
    "    return cnn\n",
    "\n",
    "\n",
    "class DataBatchGenerator(Sequence):\n",
    "    def __init__(self, dataset:np.ndarray, batch_size:int, start_idx:int,\n",
    "                 number_image_channels:int,\n",
    "                 max_x, max_y, float_memory_used, conserve=0):\n",
    "#         print(dataset.shape[0])\n",
    "        self.dataset, self.batch_size, self.start_idx = dataset, batch_size, start_idx\n",
    "        self.number_image_channels, self.max_x, self.max_y = number_image_channels, max_x, max_y\n",
    "        self.float_memory_used = float_memory_used\n",
    "        self.conserve = conserve\n",
    "    \n",
    "    def __len__(self):\n",
    "        return np.ceil(self.dataset.shape[0] / self.batch_size).astype(np.int)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        size = min(self.dataset.shape[0] - idx * self.batch_size, self.batch_size)\n",
    "        batch_x = np.empty((size, self.number_image_channels, self.max_x, self.max_y), dtype=self.float_memory_used)\n",
    "        batch_y = np.empty((size), dtype=self.float_memory_used)\n",
    "        for i in range(size):\n",
    "            batch_x[i] = read_image(self.start_idx + idx * self.batch_size + i)\n",
    "            batch_y[i] = self.dataset[idx * self.batch_size + i][- 1 - self.conserve]\n",
    "        return batch_x, batch_y\n",
    "    \n",
    "def custom_loss(fp_penalty_coef, fn_penalty_coef):\n",
    "    # custom loss function that penalize false positive and negative differently\n",
    "    def loss(y_true, y_pred):\n",
    "        res = y_pred - y_true\n",
    "        res = tf.where(res > 0, res * fp_penalty_coef, res * fn_penalty_coef)\n",
    "        return K.mean(K.square(res))\n",
    "    return loss\n",
    "\n",
    "def fp_mae(y_true, y_pred):\n",
    "    # custom metric that replace false negative with zero and return the mean of new vector\n",
    "    res = y_pred - y_true\n",
    "    res = tf.nn.relu(res)\n",
    "#     res = tf.where(res <= 0, 0, res)\n",
    "    return K.mean(res)\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = cnn_model(10, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 10, 100, 100)      730       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 10, 50, 50)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 10, 50, 50)        40        \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 20, 50, 50)        1820      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 20, 25, 25)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 20, 25, 25)        80        \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 30, 25, 25)        5430      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 30, 12, 12)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 30, 12, 12)        120       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 40, 12, 12)        10840     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 40, 6, 6)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 40, 6, 6)          160       \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1440)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 20)                28820     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 48,561\n",
      "Trainable params: 48,321\n",
      "Non-trainable params: 240\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/device:GPU:0'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_samples = [8192]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number_samples: 8192 , New samples: 8192\n",
      "Validation size: 2704 , starts: 8192 , ends: 10895\n",
      "\n",
      "Epoch 00001: val_mae improved from inf to 9.78520, saving model to ML/data/pictures_100_100/splat/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/3600sensors_pus/models/8192/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00002: val_mae did not improve from 9.78520\n",
      "\n",
      "Epoch 00003: val_mae improved from 9.78520 to 9.51208, saving model to ML/data/pictures_100_100/splat/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/3600sensors_pus/models/8192/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00004: val_mae improved from 9.51208 to 9.47149, saving model to ML/data/pictures_100_100/splat/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/3600sensors_pus/models/8192/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00005: val_mae improved from 9.47149 to 7.91613, saving model to ML/data/pictures_100_100/splat/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/3600sensors_pus/models/8192/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00006: val_mae did not improve from 7.91613\n",
      "\n",
      "Epoch 00007: val_mae did not improve from 7.91613\n",
      "\n",
      "Epoch 00008: val_mae did not improve from 7.91613\n",
      "\n",
      "Epoch 00009: val_mae improved from 7.91613 to 7.86169, saving model to ML/data/pictures_100_100/splat/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/3600sensors_pus/models/8192/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00010: val_mae improved from 7.86169 to 7.08941, saving model to ML/data/pictures_100_100/splat/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/3600sensors_pus/models/8192/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00011: val_mae improved from 7.08941 to 5.09998, saving model to ML/data/pictures_100_100/splat/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/3600sensors_pus/models/8192/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00012: val_mae improved from 5.09998 to 4.86865, saving model to ML/data/pictures_100_100/splat/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/3600sensors_pus/models/8192/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00013: val_mae did not improve from 4.86865\n",
      "\n",
      "Epoch 00014: val_mae did not improve from 4.86865\n",
      "\n",
      "Epoch 00015: val_mae improved from 4.86865 to 4.65072, saving model to ML/data/pictures_100_100/splat/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/3600sensors_pus/models/8192/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00016: val_mae improved from 4.65072 to 4.59835, saving model to ML/data/pictures_100_100/splat/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/3600sensors_pus/models/8192/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00017: val_mae did not improve from 4.59835\n",
      "\n",
      "Epoch 00018: val_mae did not improve from 4.59835\n",
      "\n",
      "Epoch 00019: val_mae did not improve from 4.59835\n",
      "\n",
      "Epoch 00020: val_mae did not improve from 4.59835\n",
      "\n",
      "Epoch 00021: val_mae did not improve from 4.59835\n",
      "\n",
      "Epoch 00022: val_mae did not improve from 4.59835\n",
      "\n",
      "Epoch 00023: val_mae did not improve from 4.59835\n",
      "\n",
      "Epoch 00024: val_mae did not improve from 4.59835\n",
      "\n",
      "Epoch 00025: val_mae did not improve from 4.59835\n",
      "\n",
      "Epoch 00026: val_mae did not improve from 4.59835\n",
      "\n",
      "Epoch 00027: val_mae did not improve from 4.59835\n",
      "\n",
      "Epoch 00028: val_mae did not improve from 4.59835\n",
      "\n",
      "Epoch 00029: val_mae did not improve from 4.59835\n",
      "\n",
      "Epoch 00030: val_mae improved from 4.59835 to 4.57229, saving model to ML/data/pictures_100_100/splat/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/3600sensors_pus/models/8192/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00031: val_mae did not improve from 4.57229\n",
      "\n",
      "Epoch 00032: val_mae did not improve from 4.57229\n",
      "\n",
      "Epoch 00033: val_mae did not improve from 4.57229\n",
      "\n",
      "Epoch 00034: val_mae did not improve from 4.57229\n",
      "\n",
      "Epoch 00035: val_mae did not improve from 4.57229\n",
      "\n",
      "Epoch 00036: val_mae did not improve from 4.57229\n",
      "\n",
      "Epoch 00037: val_mae did not improve from 4.57229\n",
      "\n",
      "Epoch 00038: val_mae did not improve from 4.57229\n",
      "\n",
      "Epoch 00039: val_mae did not improve from 4.57229\n",
      "\n",
      "Epoch 00040: val_mae did not improve from 4.57229\n",
      "\n",
      "Epoch 00041: val_mae did not improve from 4.57229\n",
      "\n",
      "Epoch 00042: val_mae did not improve from 4.57229\n",
      "\n",
      "Epoch 00043: val_mae did not improve from 4.57229\n",
      "\n",
      "Epoch 00044: val_mae did not improve from 4.57229\n",
      "\n",
      "Epoch 00045: val_mae improved from 4.57229 to 4.36832, saving model to ML/data/pictures_100_100/splat/pu_circle_su_circle_10/raw_power_min_max_norm/color/log_5/3600sensors_pus/models/8192/best_model_lambda_0.h5\n",
      "\n",
      "Epoch 00046: val_mae did not improve from 4.36832\n",
      "\n",
      "Epoch 00047: val_mae did not improve from 4.36832\n",
      "\n",
      "Epoch 00048: val_mae did not improve from 4.36832\n",
      "\n",
      "Epoch 00049: val_mae did not improve from 4.36832\n",
      "\n",
      "Epoch 00050: val_mae did not improve from 4.36832\n",
      "\n",
      "Epoch 00051: val_mae did not improve from 4.36832\n",
      "\n",
      "Epoch 00052: val_mae did not improve from 4.36832\n",
      "\n",
      "Epoch 00053: val_mae did not improve from 4.36832\n",
      "\n",
      "Epoch 00054: val_mae did not improve from 4.36832\n",
      "\n",
      "Epoch 00055: val_mae did not improve from 4.36832\n",
      "\n",
      "Epoch 00056: val_mae did not improve from 4.36832\n",
      "\n",
      "Epoch 00057: val_mae did not improve from 4.36832\n",
      "\n",
      "Epoch 00058: val_mae did not improve from 4.36832\n",
      "\n",
      "Epoch 00059: val_mae did not improve from 4.36832\n",
      "\n",
      "Epoch 00060: val_mae did not improve from 4.36832\n",
      "\n",
      "Epoch 00061: val_mae did not improve from 4.36832\n",
      "\n",
      "Epoch 00062: val_mae did not improve from 4.36832\n",
      "\n",
      "Epoch 00063: val_mae did not improve from 4.36832\n",
      "\n",
      "Epoch 00064: val_mae did not improve from 4.36832\n",
      "\n",
      "Epoch 00065: val_mae did not improve from 4.36832\n",
      "\n",
      "Epoch 00066: val_mae did not improve from 4.36832\n",
      "\n",
      "Epoch 00067: val_mae did not improve from 4.36832\n",
      "\n",
      "Epoch 00068: val_mae did not improve from 4.36832\n",
      "\n",
      "Epoch 00069: val_mae did not improve from 4.36832\n",
      "\n",
      "Epoch 00070: val_mae did not improve from 4.36832\n",
      "\n",
      "Epoch 00071: val_mae did not improve from 4.36832\n",
      "\n",
      "Epoch 00072: val_mae did not improve from 4.36832\n",
      "\n",
      "Epoch 00073: val_mae did not improve from 4.36832\n",
      "\n",
      "Epoch 00074: val_mae did not improve from 4.36832\n",
      "\n",
      "Epoch 00075: val_mae did not improve from 4.36832\n",
      "\n",
      "Epoch 00076: val_mae did not improve from 4.36832\n",
      "\n",
      "Epoch 00077: val_mae did not improve from 4.36832\n",
      "\n",
      "Epoch 00078: val_mae did not improve from 4.36832\n",
      "\n",
      "Epoch 00079: val_mae did not improve from 4.36832\n",
      "\n",
      "Epoch 00080: val_mae did not improve from 4.36832\n",
      "\n",
      "Epoch 00081: val_mae did not improve from 4.36832\n",
      "\n",
      "Epoch 00082: val_mae did not improve from 4.36832\n",
      "\n",
      "Epoch 00083: val_mae did not improve from 4.36832\n",
      "\n",
      "Epoch 00084: val_mae did not improve from 4.36832\n",
      "\n",
      "Epoch 00085: val_mae did not improve from 4.36832\n",
      "\n",
      "Epoch 00086: val_mae did not improve from 4.36832\n",
      "\n",
      "Epoch 00087: val_mae did not improve from 4.36832\n",
      "\n",
      "Epoch 00088: val_mae did not improve from 4.36832\n",
      "\n",
      "Epoch 00089: val_mae did not improve from 4.36832\n",
      "\n",
      "Epoch 00090: val_mae did not improve from 4.36832\n",
      "\n",
      "Epoch 00091: val_mae did not improve from 4.36832\n",
      "\n",
      "Epoch 00092: val_mae did not improve from 4.36832\n",
      "\n",
      "Epoch 00093: val_mae did not improve from 4.36832\n",
      "\n",
      "Epoch 00094: val_mae did not improve from 4.36832\n",
      "\n",
      "Epoch 00095: val_mae did not improve from 4.36832\n",
      "\n",
      "Epoch 00096: val_mae did not improve from 4.36832\n",
      "\n",
      "Epoch 00097: val_mae did not improve from 4.36832\n",
      "\n",
      "Epoch 00098: val_mae did not improve from 4.36832\n",
      "\n",
      "Epoch 00099: val_mae did not improve from 4.36832\n",
      "\n",
      "Epoch 00100: val_mae did not improve from 4.36832\n",
      "\n",
      "Lambda: 0.01 , Time: 0:22:17\n",
      "Train Error(all epochs): 1.1403669118881226 \n",
      " [9.559, 9.41, 9.22, 8.943, 8.49, 7.683, 6.775, 5.921, 5.248, 4.758, 4.503, 4.374, 4.287, 4.152, 4.098, 4.074, 4.015, 3.948, 3.89, 3.81, 3.752, 3.722, 3.643, 3.621, 3.526, 3.602, 3.431, 3.347, 3.371, 3.281, 3.226, 3.304, 3.18, 3.06, 3.014, 2.969, 2.914, 2.858, 2.863, 2.768, 2.73, 2.665, 2.681, 2.604, 2.562, 2.486, 2.465, 2.409, 2.322, 2.275, 2.239, 2.217, 2.179, 2.108, 2.064, 2.057, 2.009, 1.967, 1.931, 1.878, 1.89, 1.93, 1.876, 1.805, 1.768, 1.788, 1.73, 1.691, 1.653, 1.627, 1.628, 1.625, 1.546, 1.499, 1.529, 1.511, 1.469, 1.536, 1.477, 1.426, 1.372, 1.389, 1.346, 1.307, 1.331, 1.332, 1.302, 1.299, 1.297, 1.251, 1.222, 1.24, 1.221, 1.208, 1.181, 1.207, 1.22, 1.205, 1.175, 1.14]\n",
      "Train FP Error(all epochs): 0.56430584192276 \n",
      " [0.961, 0.968, 0.979, 1.002, 0.987, 0.879, 0.839, 0.998, 1.231, 1.455, 1.641, 1.804, 1.823, 1.84, 1.837, 1.877, 1.806, 1.827, 1.816, 1.796, 1.784, 1.737, 1.743, 1.714, 1.707, 1.741, 1.64, 1.62, 1.689, 1.573, 1.598, 1.607, 1.592, 1.496, 1.475, 1.478, 1.449, 1.431, 1.443, 1.365, 1.36, 1.31, 1.358, 1.281, 1.307, 1.218, 1.241, 1.2, 1.175, 1.122, 1.133, 1.123, 1.064, 1.065, 1.045, 1.011, 1.012, 0.978, 0.958, 0.924, 0.958, 0.975, 0.936, 0.886, 0.907, 0.885, 0.855, 0.855, 0.839, 0.799, 0.815, 0.811, 0.785, 0.736, 0.756, 0.764, 0.741, 0.752, 0.752, 0.689, 0.704, 0.709, 0.658, 0.66, 0.661, 0.653, 0.661, 0.646, 0.642, 0.624, 0.598, 0.631, 0.604, 0.602, 0.578, 0.608, 0.604, 0.609, 0.574, 0.564]\n",
      "Val Error(all epochs): 4.368319988250732 \n",
      " [9.785, 9.861, 9.512, 9.471, 7.916, 13.66, 15.013, 11.637, 7.862, 7.089, 5.1, 4.869, 5.043, 5.368, 4.651, 4.598, 4.749, 5.1, 4.63, 4.739, 4.912, 4.679, 4.934, 4.939, 4.971, 4.706, 4.973, 5.039, 5.054, 4.572, 5.322, 4.923, 5.128, 5.863, 5.381, 4.815, 4.97, 5.005, 4.866, 4.644, 4.939, 4.762, 4.835, 4.802, 4.368, 4.461, 4.378, 4.46, 4.452, 4.671, 4.42, 4.382, 4.46, 4.445, 4.425, 4.539, 4.482, 4.464, 4.515, 4.48, 4.522, 4.648, 4.572, 4.532, 4.615, 4.526, 4.678, 4.618, 4.72, 4.652, 4.586, 4.642, 4.654, 4.639, 4.689, 4.647, 4.701, 4.739, 4.778, 4.688, 4.771, 4.737, 4.722, 4.711, 4.708, 4.878, 4.825, 4.837, 4.891, 4.78, 4.83, 5.004, 4.806, 4.861, 4.792, 4.805, 4.842, 4.822, 4.822, 4.842]\n",
      "Val FP Error(all epochs): 0.18915784358978271 \n",
      " [0.857, 0.837, 0.86, 0.836, 1.067, 0.285, 0.189, 0.309, 0.598, 0.794, 2.144, 3.235, 2.776, 4.34, 3.257, 3.343, 3.401, 4.142, 3.454, 3.733, 4.028, 3.72, 4.127, 4.1, 4.18, 3.696, 4.203, 4.31, 4.301, 3.475, 4.651, 4.173, 4.448, 5.38, 4.717, 3.75, 4.163, 4.201, 3.958, 3.687, 4.046, 3.865, 3.97, 3.85, 2.378, 3.153, 2.699, 3.103, 2.984, 3.543, 2.791, 2.523, 2.886, 2.823, 2.585, 2.395, 2.392, 2.221, 2.58, 2.692, 2.443, 3.056, 2.469, 2.405, 2.312, 2.638, 2.236, 2.423, 2.111, 2.446, 2.5, 2.638, 2.338, 2.643, 2.657, 2.38, 2.691, 2.663, 2.495, 2.701, 2.554, 2.446, 2.657, 2.782, 2.5, 3.198, 2.351, 2.953, 2.189, 2.396, 2.459, 1.979, 2.35, 2.52, 2.512, 2.699, 2.647, 2.283, 2.852, 2.93]\n",
      "\n",
      "Trainig set size: 8192 , Time: 0:22:17 , best_lambda: 0.01 , min_  error: 4.368\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test starts:  10896 , ends:  29999\n",
      "38/38 [==============================] - 22s 571ms/step - loss: 34.1477 - mse: 32.3247 - mae: 4.3490 - fp_mae: 2.3934\n",
      "average_error:  4.349 , fp_average_error:  2.393\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# CNN: support batching\n",
    "TEST, CONSERVE = True, False\n",
    "mini_batch = 16 if max(max_x, max_y) == 1000 else 512\n",
    "epochs = 35 if max(max_x, max_y) == 1000 else 100\n",
    "MAX_QUEUE_SIZE, WORKERS = 6, 1\n",
    "fp_penalty_coef, fn_penalty_coef = 1, 1\n",
    "hyper_metric, mode = \"val_mae\", 'min'  # the metric that hyper parameters are tuned with\n",
    "prev_sample = 0\n",
    "lambda_vec = [0, 0.001, 0.01, 0.1, 1]  #0.003, 0.01, 0.03, 0.1, 0.3, 1, 3\n",
    "# lambda_vec = [0.01, 0.1, 1]\n",
    "lambda_vec = [0.01]\n",
    "# MODEL_PATH = 'models/'\n",
    "average_diff_power, fp_mean_power = [],[] #[7.177, 8.088, 8.183], [3.438, 3.506, 2.662]\n",
    "best_lambda = []\n",
    "average_diff_power_conserve, fp_mean_power_conserve = [], []\n",
    "all_cnns, all_checkpointers = [], []\n",
    "if CONSERVE: # for conservative\n",
    "    prev_number_samples = [0] + number_samples[:-1]\n",
    "\n",
    "for num_sample_idx, number_sample in enumerate(number_samples):\n",
    "#     if num_sample_idx < 3:\n",
    "#         continue\n",
    "#     if num_sample_idx == 0:\n",
    "    if CONSERVE:\n",
    "        pu_data_reg[prev_number_samples[num_sample_idx]:number_sample, -1] = pu_data_reg[\n",
    "            prev_number_samples[num_sample_idx]:number_sample, -1] - 1 # conserv value\n",
    "    MODEL_PATH = '/'.join(image_dir.split('/')[:-1]) + '/models/' + str(number_sample)\n",
    "    if not os.path.exists(MODEL_PATH):\n",
    "        os.makedirs(MODEL_PATH)\n",
    "    MODEL_PATH += \"/best_model_lambda_\"\n",
    "    if True:\n",
    "        cnns = [cnn_model(10, lamb, 0) for lamb in lambda_vec]\n",
    "        for cnn in cnns:\n",
    "#             cnn.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse','mae', fp_mean])\n",
    "            cnn.compile(loss=custom_loss(fp_penalty_coef, fn_penalty_coef), \n",
    "                        optimizer='Adam', \n",
    "                        metrics=['mse', 'mae', fp_mae])\n",
    "        checkpointers = [ModelCheckpoint(filepath=MODEL_PATH + str(lamb_idx)+ '.h5',\n",
    "                                         verbose=1, save_best_only=True, \n",
    "                                         monitor=hyper_metric,\n",
    "                                         mode=mode)\n",
    "                         for lamb_idx in range(len(lambda_vec))]\n",
    "    else:\n",
    "        cnns = []\n",
    "        cnns = [models.load_model(MODEL_PATH + str(lamb_idx) + '.h5', \n",
    "                                  custom_objects={ 'loss': custom_loss(fp_penalty_coef, fn_penalty_coef), \n",
    "                                                  'fp_mae': fp_mae }) \n",
    "                for lamb_idx in range(len(lambda_vec))]\n",
    "    number_start = time.time()\n",
    "    train_generator = DataBatchGenerator(dataset=pu_data_reg[prev_sample:number_sample],\n",
    "                                         batch_size=mini_batch,\n",
    "                                         start_idx=prev_sample, \n",
    "                                         number_image_channels=number_image_channels,\n",
    "                                         max_x=max_x, max_y=max_y,\n",
    "                                         float_memory_used=float_memory_used)\n",
    "    \n",
    "\n",
    "    val_size = math.ceil(number_sample * validation_size)\n",
    "    val_generator = DataBatchGenerator(dataset=pu_data_reg[number_sample:number_sample+val_size], \n",
    "                                       batch_size=mini_batch,\n",
    "                                       start_idx=number_sample,\n",
    "                                       number_image_channels=number_image_channels,\n",
    "                                       max_x=max_x, max_y=max_y, \n",
    "                                       float_memory_used=float_memory_used)\n",
    "  \n",
    "    print('number_samples:', number_sample, \", New samples:\", number_sample - prev_sample)\n",
    "    print(\"Validation size:\", val_size, \", starts:\", number_sample, \", ends:\", number_sample + val_size - 1)\n",
    "    \n",
    "    for lamb_idx, lamb in enumerate(lambda_vec):\n",
    "#     for lamb_idx, lamb in enumerate(lambda_vec[:len(lambda_vec) - num_sample_idx//2]):\n",
    "#         if num_sample_idx == 3 and lamb_idx < 4:\n",
    "#             continue\n",
    "        lambda_start = time.time()\n",
    "        cnns[lamb_idx].fit(train_generator, epochs=epochs, verbose=0,\n",
    "                           validation_data=val_generator, \n",
    "                           shuffle=True, callbacks=[checkpointers[lamb_idx]], \n",
    "                           workers=WORKERS, max_queue_size=MAX_QUEUE_SIZE, \n",
    "                           use_multiprocessing=False)\n",
    "        \n",
    "        print(\"\\nLambda:\", lamb, \", Time:\", str(datetime.timedelta(seconds=int(time.time() - lambda_start))))\n",
    "        print(\"Train Error(all epochs):\", min(cnns[lamb_idx].history.history['mae']), '\\n', \n",
    "              [round(val, 3) for val in cnns[lamb_idx].history.history['mae']])\n",
    "        print(\"Train FP Error(all epochs):\", min(cnns[lamb_idx].history.history['fp_mae']), '\\n',\n",
    "              [round(val,3) for val in cnns[lamb_idx].history.history['fp_mae']])\n",
    "        print(\"Val Error(all epochs):\", min(cnns[lamb_idx].history.history['val_mae']), '\\n', \n",
    "              [round(val,3) for val in cnns[lamb_idx].history.history['val_mae']])\n",
    "        print(\"Val FP Error(all epochs):\", min(cnns[lamb_idx].history.history['val_fp_mae']), '\\n',\n",
    "              [round(val,3) for val in cnns[lamb_idx].history.history['val_fp_mae']])\n",
    "#     if num_sample_idx == 3:    \n",
    "#         models_min_mae = [8.27781, 8.23545, 8.20838, 7.74743]\n",
    "#         models_min_mae += [min(cnns[lamb_idx].history.history[hyper_metric]) for lamb_idx in range(4,lamb_idx+1)]\n",
    "#     else:\n",
    "    models_min_mae = [min(cnns[lam_idx].history.history[hyper_metric]) for\n",
    "                      lam_idx,_ in enumerate(lambda_vec)]\n",
    "    best_lamb_idx = models_min_mae.index(min(models_min_mae))\n",
    "    best_lambda.append(lambda_vec[best_lamb_idx])\n",
    "    print(\"\\nTrainig set size:\", number_sample, \", Time:\", str(datetime.timedelta(seconds=int(time.time() - \n",
    "                                                                                              number_start))),\n",
    "          \", best_lambda:\", lambda_vec[best_lamb_idx], \", min_\" , (\"fp_\" if hyper_metric == \"val_fp_mae\" else \"\"),\n",
    "          \"error:\", round(min(models_min_mae), 3))\n",
    "    \n",
    "    if TEST:\n",
    "        # evaluating test images\n",
    "        best_model = None\n",
    "        best_model = models.load_model(MODEL_PATH + str(best_lamb_idx) + '.h5', \n",
    "                                       custom_objects={ 'loss': custom_loss(fp_penalty_coef, fn_penalty_coef), \n",
    "                                                       'fp_mae': fp_mae,\n",
    "                                                      'mae':'mae', 'mse':'mse'})\n",
    "        test_generator = DataBatchGenerator(dataset=pu_data_reg[number_sample + val_size:], \n",
    "                                            batch_size=mini_batch,\n",
    "                                            start_idx=number_sample + val_size, \n",
    "                                            number_image_channels=number_image_channels,\n",
    "                                            max_x=max_x, max_y=max_y, float_memory_used=float_memory_used)\n",
    "\n",
    "        print(\"Test starts: \", number_sample + val_size, \", ends: \", pu_data_reg.shape[0] - 1)\n",
    "        time.sleep(1)\n",
    "        test_res = best_model.evaluate(test_generator, verbose=1, \n",
    "                                       workers=WORKERS, max_queue_size=MAX_QUEUE_SIZE, use_multiprocessing=False)\n",
    "        \n",
    "        test_mae_idx, test_fp_mae_idx = [best_model.metrics_names.index(mtrc) \n",
    "                                         for mtrc in ['mae','fp_mae']]\n",
    "        test_mae, test_fp_mae = test_res[test_mae_idx], test_res[test_fp_mae_idx]\n",
    "        average_diff_power.append(round(test_mae, 3))\n",
    "        fp_mean_power.append(round(test_fp_mae, 3))\n",
    "        print('average_error: ', average_diff_power[-1], ', fp_average_error: ', \n",
    "              fp_mean_power[-1])\n",
    "        \n",
    "        if False:\n",
    "            test_generator_conserve = DataBatchGenerator(dataset=pu_data_reg[number_sample + val_size:], \n",
    "                                                         batch_size=mini_batch,\n",
    "                                                         start_idx=number_sample + val_size, \n",
    "                                                         number_image_channels=number_image_channels,\n",
    "                                                         max_x=max_x, max_y=max_y, \n",
    "                                                         float_memory_used=float_memory_used, \n",
    "                                                         conserve=1)\n",
    "            test_res_conserve = best_model.evaluate(test_generator_conserve, verbose=1, \n",
    "                                                    workers=WORKERS, max_queue_size=MAX_QUEUE_SIZE, \n",
    "                                                    use_multiprocessing=False)\n",
    "            test_mae_cons, test_fp_mae_cons = test_res_conserve[test_mae_idx], test_res_conserve[test_fp_mae_idx]\n",
    "            average_diff_power_conserve.append(round(test_mae_cons, 3))\n",
    "            fp_mean_power_conserve.append(round(test_fp_mae_cons, 3))\n",
    "            print('Conserve, average_error: ', average_diff_power_conserve[-1], ', fp_average_error: ',\n",
    "                 fp_mean_power_conserve[-1])\n",
    "        print(\"\\n\\n\")\n",
    "\n",
    "        \n",
    "        var_f = open('/'.join(image_dir.split('/')[:-1]) +  '/' + intensity_degradation + '_' + str(slope) + '_' + \n",
    "                     dtime + \".dat\", \"wb\") # file for saving results\n",
    "        pickle.dump([average_diff_power, fp_mean_power, number_samples, best_lambda, \n",
    "                     pu_dataset_name, sensor_dataset_name,\n",
    "                     max_dataset_name, average_diff_power_conserve, fp_mean_power_conserve,\n",
    "                    all_cnns, all_checkpointers],\n",
    "                    file=var_f)\n",
    "        var_f.close()\n",
    "        all_cnns.append(cnns)\n",
    "        all_checkpointers.append(checkpointers)\n",
    "        del cnns, train_generator, val_generator, checkpointers\n",
    "        del best_model, test_generator\n",
    "#     prev_sample = number_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[256, 512, 1024, 2048, 4096, 8192]\n",
      "[7.304, 7.435, 6.058, 5.099, 4.514, 3.998]\n",
      "[3.036, 3.115, 3.43, 2.506, 2.0, 2.144]\n",
      "[]\n",
      "[]\n",
      "[0.01, 0.01, 0.1, 0.001, 1, 0.01]\n"
     ]
    }
   ],
   "source": [
    "print(number_samples)\n",
    "print(average_diff_power)\n",
    "print(fp_mean_power)\n",
    "# print(best_lambda)\n",
    "print(average_diff_power_conserve)\n",
    "print(fp_mean_power_conserve)\n",
    "print(best_lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [34.280517578125,\n",
       "  32.139129638671875,\n",
       "  30.026790618896484,\n",
       "  26.77768898010254,\n",
       "  22.154972076416016,\n",
       "  16.8223819732666,\n",
       "  12.144721984863281,\n",
       "  9.570384979248047,\n",
       "  7.8615312576293945,\n",
       "  6.511453151702881,\n",
       "  5.97813606262207,\n",
       "  5.705277919769287,\n",
       "  5.531862258911133,\n",
       "  5.38530158996582,\n",
       "  5.206046104431152,\n",
       "  5.079604148864746,\n",
       "  4.93232536315918,\n",
       "  4.80665922164917,\n",
       "  4.676588535308838,\n",
       "  4.540332794189453,\n",
       "  4.43764066696167,\n",
       "  4.290816307067871,\n",
       "  4.191329002380371,\n",
       "  4.067809104919434,\n",
       "  4.628100395202637,\n",
       "  6.274977684020996,\n",
       "  5.784174919128418,\n",
       "  5.09354829788208,\n",
       "  4.657415866851807,\n",
       "  4.24078369140625,\n",
       "  3.9520764350891113,\n",
       "  3.7179880142211914,\n",
       "  3.524243116378784,\n",
       "  3.3813459873199463,\n",
       "  3.3246569633483887,\n",
       "  3.348724126815796,\n",
       "  3.2289745807647705,\n",
       "  3.259772300720215,\n",
       "  3.4742321968078613,\n",
       "  3.3629093170166016,\n",
       "  3.278648853302002,\n",
       "  3.1227707862854004,\n",
       "  3.1056971549987793,\n",
       "  3.05012845993042,\n",
       "  2.9284372329711914,\n",
       "  2.980515241622925,\n",
       "  3.0709378719329834,\n",
       "  2.9922614097595215,\n",
       "  2.940444231033325,\n",
       "  2.8742055892944336,\n",
       "  2.7167561054229736,\n",
       "  2.77622652053833,\n",
       "  2.7793784141540527,\n",
       "  2.6848957538604736,\n",
       "  2.6082096099853516,\n",
       "  2.555168390274048,\n",
       "  2.5030012130737305,\n",
       "  2.427560806274414,\n",
       "  2.3778016567230225,\n",
       "  2.3583602905273438,\n",
       "  2.316555976867676,\n",
       "  2.3370628356933594,\n",
       "  2.3684959411621094,\n",
       "  2.5095138549804688,\n",
       "  2.6002492904663086,\n",
       "  2.6764237880706787,\n",
       "  2.713268756866455,\n",
       "  2.6889007091522217,\n",
       "  2.6353466510772705,\n",
       "  2.4244720935821533,\n",
       "  2.2964820861816406,\n",
       "  2.2210073471069336,\n",
       "  2.2414896488189697,\n",
       "  2.1672468185424805,\n",
       "  2.071078300476074],\n",
       " 'mse': [138.95742797851562,\n",
       "  139.4345245361328,\n",
       "  139.73812866210938,\n",
       "  140.0347900390625,\n",
       "  141.56851196289062,\n",
       "  141.51560974121094,\n",
       "  141.60562133789062,\n",
       "  141.06564331054688,\n",
       "  142.76235961914062,\n",
       "  137.42697143554688,\n",
       "  131.61819458007812,\n",
       "  127.66020202636719,\n",
       "  123.37792205810547,\n",
       "  119.57726287841797,\n",
       "  115.3846435546875,\n",
       "  111.5514907836914,\n",
       "  107.3299331665039,\n",
       "  103.61212158203125,\n",
       "  99.46189880371094,\n",
       "  95.27288818359375,\n",
       "  91.22123718261719,\n",
       "  86.87760162353516,\n",
       "  82.57862091064453,\n",
       "  78.5640869140625,\n",
       "  78.25345611572266,\n",
       "  90.71188354492188,\n",
       "  98.90522003173828,\n",
       "  95.09429931640625,\n",
       "  90.563720703125,\n",
       "  83.42247772216797,\n",
       "  76.28433227539062,\n",
       "  69.02035522460938,\n",
       "  62.48311996459961,\n",
       "  57.880950927734375,\n",
       "  54.20793151855469,\n",
       "  53.020755767822266,\n",
       "  51.203853607177734,\n",
       "  49.65223693847656,\n",
       "  51.83290100097656,\n",
       "  51.98475646972656,\n",
       "  50.03435516357422,\n",
       "  47.88712692260742,\n",
       "  45.68757629394531,\n",
       "  44.05602264404297,\n",
       "  42.191627502441406,\n",
       "  41.27357864379883,\n",
       "  43.198917388916016,\n",
       "  42.454933166503906,\n",
       "  40.829612731933594,\n",
       "  39.660850524902344,\n",
       "  36.852935791015625,\n",
       "  35.93998336791992,\n",
       "  35.903038024902344,\n",
       "  34.98988723754883,\n",
       "  33.64731979370117,\n",
       "  31.835708618164062,\n",
       "  31.012672424316406,\n",
       "  28.438907623291016,\n",
       "  27.509937286376953,\n",
       "  26.83949089050293,\n",
       "  25.925865173339844,\n",
       "  25.67839813232422,\n",
       "  25.363515853881836,\n",
       "  27.992380142211914,\n",
       "  30.31098175048828,\n",
       "  30.659076690673828,\n",
       "  33.82777404785156,\n",
       "  33.3546028137207,\n",
       "  32.89173126220703,\n",
       "  29.846450805664062,\n",
       "  26.9140682220459,\n",
       "  23.964824676513672,\n",
       "  23.839977264404297,\n",
       "  23.498361587524414,\n",
       "  21.193939208984375],\n",
       " 'mae': [9.568568229675293,\n",
       "  9.60628890991211,\n",
       "  9.628937721252441,\n",
       "  9.644261360168457,\n",
       "  9.67042064666748,\n",
       "  9.650049209594727,\n",
       "  9.664739608764648,\n",
       "  9.68792724609375,\n",
       "  9.712377548217773,\n",
       "  9.602705001831055,\n",
       "  9.444931983947754,\n",
       "  9.319391250610352,\n",
       "  9.175576210021973,\n",
       "  9.040199279785156,\n",
       "  8.890301704406738,\n",
       "  8.727949142456055,\n",
       "  8.559429168701172,\n",
       "  8.404231071472168,\n",
       "  8.235840797424316,\n",
       "  8.060441017150879,\n",
       "  7.892435550689697,\n",
       "  7.694075107574463,\n",
       "  7.503599166870117,\n",
       "  7.321473598480225,\n",
       "  7.275202751159668,\n",
       "  7.773203372955322,\n",
       "  8.196409225463867,\n",
       "  8.121919631958008,\n",
       "  7.985069751739502,\n",
       "  7.685394763946533,\n",
       "  7.353413105010986,\n",
       "  6.9830851554870605,\n",
       "  6.620302677154541,\n",
       "  6.319255828857422,\n",
       "  6.087718486785889,\n",
       "  5.990026473999023,\n",
       "  5.896487236022949,\n",
       "  5.777924060821533,\n",
       "  5.8873090744018555,\n",
       "  5.9037675857543945,\n",
       "  5.815201759338379,\n",
       "  5.729607105255127,\n",
       "  5.560135841369629,\n",
       "  5.423348903656006,\n",
       "  5.342309951782227,\n",
       "  5.271992206573486,\n",
       "  5.388915061950684,\n",
       "  5.355019569396973,\n",
       "  5.264732837677002,\n",
       "  5.205231189727783,\n",
       "  5.012448310852051,\n",
       "  4.900557041168213,\n",
       "  4.9147186279296875,\n",
       "  4.854438304901123,\n",
       "  4.784154891967773,\n",
       "  4.61916446685791,\n",
       "  4.553294658660889,\n",
       "  4.366307735443115,\n",
       "  4.25223445892334,\n",
       "  4.19352912902832,\n",
       "  4.1321516036987305,\n",
       "  4.103394508361816,\n",
       "  4.080540180206299,\n",
       "  4.319300174713135,\n",
       "  4.517905235290527,\n",
       "  4.534417152404785,\n",
       "  4.761448860168457,\n",
       "  4.753091335296631,\n",
       "  4.7662739753723145,\n",
       "  4.548783779144287,\n",
       "  4.300647258758545,\n",
       "  4.032342910766602,\n",
       "  3.9714109897613525,\n",
       "  3.974112033843994,\n",
       "  3.7625133991241455],\n",
       " 'fp_mae': [0.8757335543632507,\n",
       "  0.8362340927124023,\n",
       "  0.7910929322242737,\n",
       "  0.7265692353248596,\n",
       "  0.6322803497314453,\n",
       "  0.5046727061271667,\n",
       "  0.37385767698287964,\n",
       "  0.2594864070415497,\n",
       "  0.17712929844856262,\n",
       "  0.08700224757194519,\n",
       "  0.04615789279341698,\n",
       "  0.0286738108843565,\n",
       "  0.023867575451731682,\n",
       "  0.02009620890021324,\n",
       "  0.013288630172610283,\n",
       "  0.013877389021217823,\n",
       "  0.01204006839543581,\n",
       "  0.01277848519384861,\n",
       "  0.014464703388512135,\n",
       "  0.015045681968331337,\n",
       "  0.02172103151679039,\n",
       "  0.02018497698009014,\n",
       "  0.02581704407930374,\n",
       "  0.02792665734887123,\n",
       "  0.07724101096391678,\n",
       "  0.17399320006370544,\n",
       "  0.11896859854459763,\n",
       "  0.06565311551094055,\n",
       "  0.044544022530317307,\n",
       "  0.019941510632634163,\n",
       "  0.01081253495067358,\n",
       "  0.011223874986171722,\n",
       "  0.01651868224143982,\n",
       "  0.019244013354182243,\n",
       "  0.029722880572080612,\n",
       "  0.03894929587841034,\n",
       "  0.03340519219636917,\n",
       "  0.039644915610551834,\n",
       "  0.05869905278086662,\n",
       "  0.04865427687764168,\n",
       "  0.043211717158555984,\n",
       "  0.03212028741836548,\n",
       "  0.03515591844916344,\n",
       "  0.04212021455168724,\n",
       "  0.03073122724890709,\n",
       "  0.044389329850673676,\n",
       "  0.050836432725191116,\n",
       "  0.04328303784132004,\n",
       "  0.038926221430301666,\n",
       "  0.03935988247394562,\n",
       "  0.028175583109259605,\n",
       "  0.03954663872718811,\n",
       "  0.04407496005296707,\n",
       "  0.03602404147386551,\n",
       "  0.028622223064303398,\n",
       "  0.03277350962162018,\n",
       "  0.026339637115597725,\n",
       "  0.02931462600827217,\n",
       "  0.02785148099064827,\n",
       "  0.029781240969896317,\n",
       "  0.027893854305148125,\n",
       "  0.033705566078424454,\n",
       "  0.0444902703166008,\n",
       "  0.053840674459934235,\n",
       "  0.050547145307064056,\n",
       "  0.05854751914739609,\n",
       "  0.04866339638829231,\n",
       "  0.04817085713148117,\n",
       "  0.04092201963067055,\n",
       "  0.025672009214758873,\n",
       "  0.021238161250948906,\n",
       "  0.02465384639799595,\n",
       "  0.03125966340303421,\n",
       "  0.024158567190170288,\n",
       "  0.01754622533917427],\n",
       " 'val_loss': [27.701032638549805,\n",
       "  27.114723205566406,\n",
       "  25.555381774902344,\n",
       "  23.660282135009766,\n",
       "  16.630056381225586,\n",
       "  14.22280502319336,\n",
       "  14.467507362365723,\n",
       "  14.206449508666992,\n",
       "  15.25165843963623,\n",
       "  16.547962188720703,\n",
       "  16.518856048583984,\n",
       "  17.636119842529297,\n",
       "  16.603595733642578,\n",
       "  16.440916061401367,\n",
       "  15.279376029968262,\n",
       "  14.711442947387695,\n",
       "  14.447875022888184,\n",
       "  13.657086372375488,\n",
       "  13.080232620239258,\n",
       "  12.993061065673828,\n",
       "  12.458075523376465,\n",
       "  11.768416404724121,\n",
       "  11.573246002197266,\n",
       "  11.44144058227539,\n",
       "  11.878591537475586,\n",
       "  12.830615997314453,\n",
       "  11.252320289611816,\n",
       "  12.575824737548828,\n",
       "  13.753491401672363,\n",
       "  13.651358604431152,\n",
       "  13.819133758544922,\n",
       "  16.028156280517578,\n",
       "  15.607954978942871,\n",
       "  16.888216018676758,\n",
       "  17.165435791015625,\n",
       "  22.438262939453125,\n",
       "  20.497806549072266,\n",
       "  29.523338317871094,\n",
       "  33.77013397216797,\n",
       "  29.01215171813965,\n",
       "  37.24893569946289,\n",
       "  31.790571212768555,\n",
       "  35.257205963134766,\n",
       "  43.21108627319336,\n",
       "  35.294944763183594,\n",
       "  33.65171813964844,\n",
       "  25.89348602294922,\n",
       "  27.556808471679688,\n",
       "  23.253582000732422,\n",
       "  30.200891494750977,\n",
       "  33.268856048583984,\n",
       "  31.737709045410156,\n",
       "  38.988990783691406,\n",
       "  30.693267822265625,\n",
       "  41.60560607910156,\n",
       "  31.8389892578125,\n",
       "  38.68429946899414,\n",
       "  39.64955520629883,\n",
       "  41.06806182861328,\n",
       "  32.145912170410156,\n",
       "  43.99365997314453,\n",
       "  37.36620330810547,\n",
       "  39.24705123901367,\n",
       "  40.77823257446289,\n",
       "  29.055973052978516,\n",
       "  38.17567825317383,\n",
       "  31.208189010620117,\n",
       "  33.73896789550781,\n",
       "  45.55735778808594,\n",
       "  39.96580123901367,\n",
       "  41.07185745239258,\n",
       "  63.05266571044922,\n",
       "  42.36210632324219,\n",
       "  37.91758346557617,\n",
       "  38.38783264160156],\n",
       " 'val_mse': [131.5735321044922,\n",
       "  132.94903564453125,\n",
       "  137.59432983398438,\n",
       "  144.00941467285156,\n",
       "  190.94908142089844,\n",
       "  254.15472412109375,\n",
       "  342.9757385253906,\n",
       "  326.5900573730469,\n",
       "  401.8948669433594,\n",
       "  449.29193115234375,\n",
       "  451.7496643066406,\n",
       "  490.8843994140625,\n",
       "  455.33135986328125,\n",
       "  452.0580749511719,\n",
       "  411.7303466796875,\n",
       "  391.2557373046875,\n",
       "  383.2771911621094,\n",
       "  352.2546081542969,\n",
       "  333.18243408203125,\n",
       "  326.4960021972656,\n",
       "  300.8323669433594,\n",
       "  279.1268005371094,\n",
       "  263.6731872558594,\n",
       "  258.8364562988281,\n",
       "  181.84121704101562,\n",
       "  181.14381408691406,\n",
       "  204.1774444580078,\n",
       "  187.20458984375,\n",
       "  125.48226928710938,\n",
       "  124.85722351074219,\n",
       "  119.20436096191406,\n",
       "  96.94213104248047,\n",
       "  98.06595611572266,\n",
       "  90.61659240722656,\n",
       "  87.44786071777344,\n",
       "  72.6369400024414,\n",
       "  78.33419799804688,\n",
       "  72.42845916748047,\n",
       "  57.234928131103516,\n",
       "  60.011024475097656,\n",
       "  54.26087951660156,\n",
       "  57.54944610595703,\n",
       "  57.3054313659668,\n",
       "  50.18709945678711,\n",
       "  53.81249237060547,\n",
       "  57.4285888671875,\n",
       "  71.0619888305664,\n",
       "  67.78023529052734,\n",
       "  77.804931640625,\n",
       "  58.76274871826172,\n",
       "  56.100868225097656,\n",
       "  60.2158203125,\n",
       "  53.759498596191406,\n",
       "  60.11495590209961,\n",
       "  48.341922760009766,\n",
       "  57.5165901184082,\n",
       "  51.54823303222656,\n",
       "  49.06593322753906,\n",
       "  48.88787841796875,\n",
       "  53.773990631103516,\n",
       "  49.05105209350586,\n",
       "  51.692256927490234,\n",
       "  52.831233978271484,\n",
       "  54.50913619995117,\n",
       "  64.28040313720703,\n",
       "  54.52835464477539,\n",
       "  62.04332733154297,\n",
       "  59.839786529541016,\n",
       "  48.87601852416992,\n",
       "  54.01548767089844,\n",
       "  50.23514938354492,\n",
       "  44.680789947509766,\n",
       "  49.095096588134766,\n",
       "  51.98741912841797,\n",
       "  50.680381774902344],\n",
       " 'val_mae': [9.298479080200195,\n",
       "  9.36836051940918,\n",
       "  9.582399368286133,\n",
       "  9.865554809570312,\n",
       "  11.756539344787598,\n",
       "  13.980988502502441,\n",
       "  16.68907356262207,\n",
       "  16.17669105529785,\n",
       "  18.399377822875977,\n",
       "  19.655776977539062,\n",
       "  19.732574462890625,\n",
       "  20.723745346069336,\n",
       "  19.83918571472168,\n",
       "  19.804880142211914,\n",
       "  18.795761108398438,\n",
       "  18.289033889770508,\n",
       "  18.102792739868164,\n",
       "  17.260740280151367,\n",
       "  16.76466941833496,\n",
       "  16.533395767211914,\n",
       "  15.797470092773438,\n",
       "  15.201926231384277,\n",
       "  14.708893775939941,\n",
       "  14.609565734863281,\n",
       "  11.82087516784668,\n",
       "  11.773801803588867,\n",
       "  12.726445198059082,\n",
       "  11.887100219726562,\n",
       "  9.594481468200684,\n",
       "  9.609915733337402,\n",
       "  9.422100067138672,\n",
       "  8.362160682678223,\n",
       "  8.434253692626953,\n",
       "  8.050840377807617,\n",
       "  7.827771186828613,\n",
       "  7.059072494506836,\n",
       "  7.328733921051025,\n",
       "  6.937481880187988,\n",
       "  6.086619853973389,\n",
       "  6.293088436126709,\n",
       "  5.938018798828125,\n",
       "  6.180086135864258,\n",
       "  6.119192123413086,\n",
       "  5.65084981918335,\n",
       "  5.933087348937988,\n",
       "  6.110011577606201,\n",
       "  6.9567670822143555,\n",
       "  6.753399848937988,\n",
       "  7.319133758544922,\n",
       "  6.233630180358887,\n",
       "  6.090268611907959,\n",
       "  6.303443908691406,\n",
       "  5.869543075561523,\n",
       "  6.318245887756348,\n",
       "  5.612604141235352,\n",
       "  6.176711559295654,\n",
       "  5.774494171142578,\n",
       "  5.6121673583984375,\n",
       "  5.649049282073975,\n",
       "  5.957334041595459,\n",
       "  5.6253581047058105,\n",
       "  5.805909156799316,\n",
       "  5.881579875946045,\n",
       "  5.94459867477417,\n",
       "  6.577937126159668,\n",
       "  5.917793273925781,\n",
       "  6.431214332580566,\n",
       "  6.291696071624756,\n",
       "  5.63870906829834,\n",
       "  5.911204814910889,\n",
       "  5.713443279266357,\n",
       "  5.309280872344971,\n",
       "  5.63872766494751,\n",
       "  5.849617958068848,\n",
       "  5.7642621994018555],\n",
       " 'val_fp_mae': [0.7785448431968689,\n",
       "  0.7557740211486816,\n",
       "  0.6990954875946045,\n",
       "  0.6374534368515015,\n",
       "  0.3499869108200073,\n",
       "  0.17726540565490723,\n",
       "  0.08151146024465561,\n",
       "  0.09042427688837051,\n",
       "  0.04333247244358063,\n",
       "  0.026314059272408485,\n",
       "  0.023008033633232117,\n",
       "  0.015303527005016804,\n",
       "  0.01988721638917923,\n",
       "  0.019194476306438446,\n",
       "  0.026645764708518982,\n",
       "  0.029987340793013573,\n",
       "  0.029973573982715607,\n",
       "  0.03915213420987129,\n",
       "  0.04230624437332153,\n",
       "  0.04284100607037544,\n",
       "  0.05878112092614174,\n",
       "  0.06337492167949677,\n",
       "  0.07584269344806671,\n",
       "  0.08386609703302383,\n",
       "  0.19398874044418335,\n",
       "  0.23028625547885895,\n",
       "  0.16068993508815765,\n",
       "  0.21382765471935272,\n",
       "  0.3501199781894684,\n",
       "  0.3496076166629791,\n",
       "  0.36181017756462097,\n",
       "  0.4604138433933258,\n",
       "  0.44616374373435974,\n",
       "  0.506967306137085,\n",
       "  0.5131387710571289,\n",
       "  0.724962055683136,\n",
       "  0.6332568526268005,\n",
       "  0.9380209445953369,\n",
       "  1.131161093711853,\n",
       "  1.031607747077942,\n",
       "  1.2321544885635376,\n",
       "  1.0980838537216187,\n",
       "  1.180215835571289,\n",
       "  1.4021376371383667,\n",
       "  1.1933064460754395,\n",
       "  1.100930094718933,\n",
       "  0.832655668258667,\n",
       "  0.9237565398216248,\n",
       "  0.7059701085090637,\n",
       "  1.0472887754440308,\n",
       "  1.0938546657562256,\n",
       "  1.032322645187378,\n",
       "  1.2932273149490356,\n",
       "  1.040101170539856,\n",
       "  1.4429906606674194,\n",
       "  1.124444603919983,\n",
       "  1.3082584142684937,\n",
       "  1.3665471076965332,\n",
       "  1.4357147216796875,\n",
       "  1.140723466873169,\n",
       "  1.5076793432235718,\n",
       "  1.2952944040298462,\n",
       "  1.3526383638381958,\n",
       "  1.375780701637268,\n",
       "  0.981248676776886,\n",
       "  1.2827385663986206,\n",
       "  1.0603300333023071,\n",
       "  1.15763521194458,\n",
       "  1.5314626693725586,\n",
       "  1.3450216054916382,\n",
       "  1.3932299613952637,\n",
       "  2.0574522018432617,\n",
       "  1.4187321662902832,\n",
       "  1.280022144317627,\n",
       "  1.2936455011367798]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_cnns[0][0].history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = all_cnns[0][0]\n",
    "checkpointers = all_checkpointers[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.ModelCheckpoint at 0x7f5e509c3190>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpointers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number_samples: 4096 , New samples: 4096\n",
      "Validation size: 1352 , starts: 4096 , ends: 5447\n",
      "\n",
      "Epoch 00202: val_mae did not improve from 4.91669\n",
      "\n",
      "Epoch 00203: val_mae did not improve from 4.91669\n",
      "\n",
      "Epoch 00204: val_mae did not improve from 4.91669\n",
      "\n",
      "Epoch 00205: val_mae did not improve from 4.91669\n",
      "\n",
      "Epoch 00206: val_mae did not improve from 4.91669\n",
      "\n",
      "Epoch 00207: val_mae did not improve from 4.91669\n",
      "\n",
      "Epoch 00208: val_mae did not improve from 4.91669\n",
      "\n",
      "Epoch 00209: val_mae did not improve from 4.91669\n",
      "\n",
      "Epoch 00210: val_mae did not improve from 4.91669\n",
      "\n",
      "Epoch 00211: val_mae did not improve from 4.91669\n",
      "\n",
      "Epoch 00212: val_mae did not improve from 4.91669\n",
      "\n",
      "Epoch 00213: val_mae did not improve from 4.91669\n",
      "\n",
      "Epoch 00214: val_mae did not improve from 4.91669\n",
      "\n",
      "Epoch 00215: val_mae did not improve from 4.91669\n",
      "\n",
      "Epoch 00216: val_mae did not improve from 4.91669\n",
      "\n",
      "Epoch 00217: val_mae did not improve from 4.91669\n",
      "\n",
      "Epoch 00218: val_mae did not improve from 4.91669\n",
      "\n",
      "Epoch 00219: val_mae did not improve from 4.91669\n",
      "\n",
      "Epoch 00220: val_mae did not improve from 4.91669\n",
      "\n",
      "Epoch 00221: val_mae did not improve from 4.91669\n",
      "\n",
      "Epoch 00222: val_mae did not improve from 4.91669\n",
      "\n",
      "Epoch 00223: val_mae did not improve from 4.91669\n",
      "\n",
      "Epoch 00224: val_mae did not improve from 4.91669\n",
      "\n",
      "Epoch 00225: val_mae did not improve from 4.91669\n",
      "\n",
      "Epoch 00226: val_mae did not improve from 4.91669\n",
      "\n",
      "Epoch 00227: val_mae did not improve from 4.91669\n",
      "\n",
      "Epoch 00228: val_mae did not improve from 4.91669\n",
      "\n",
      "Epoch 00229: val_mae did not improve from 4.91669\n",
      "\n",
      "Epoch 00230: val_mae did not improve from 4.91669\n",
      "\n",
      "Epoch 00231: val_mae did not improve from 4.91669\n",
      "\n",
      "Epoch 00232: val_mae did not improve from 4.91669\n",
      "\n",
      "Epoch 00233: val_mae did not improve from 4.91669\n",
      "\n",
      "Epoch 00234: val_mae did not improve from 4.91669\n",
      "\n",
      "Epoch 00235: val_mae did not improve from 4.91669\n",
      "\n",
      "Epoch 00236: val_mae did not improve from 4.91669\n",
      "\n",
      "Epoch 00237: val_mae did not improve from 4.91669\n",
      "\n",
      "Epoch 00238: val_mae did not improve from 4.91669\n",
      "\n",
      "Epoch 00239: val_mae did not improve from 4.91669\n",
      "\n",
      "Epoch 00240: val_mae did not improve from 4.91669\n",
      "\n",
      "Epoch 00241: val_mae did not improve from 4.91669\n",
      "\n",
      "Epoch 00242: val_mae did not improve from 4.91669\n",
      "\n",
      "Epoch 00243: val_mae did not improve from 4.91669\n",
      "\n",
      "Epoch 00244: val_mae did not improve from 4.91669\n",
      "\n",
      "Epoch 00245: val_mae did not improve from 4.91669\n",
      "\n",
      "Epoch 00246: val_mae did not improve from 4.91669\n",
      "\n",
      "Epoch 00247: val_mae did not improve from 4.91669\n",
      "\n",
      "Epoch 00248: val_mae did not improve from 4.91669\n",
      "\n",
      "Epoch 00249: val_mae did not improve from 4.91669\n",
      "\n",
      "Epoch 00250: val_mae did not improve from 4.91669\n",
      "\n",
      "Epoch 00251: val_mae did not improve from 4.91669\n",
      "\n",
      "Epoch 00252: val_mae did not improve from 4.91669\n",
      "\n",
      "Epoch 00253: val_mae did not improve from 4.91669\n",
      "\n",
      "Epoch 00254: val_mae did not improve from 4.91669\n",
      "\n",
      "Epoch 00255: val_mae did not improve from 4.91669\n",
      "\n",
      "Epoch 00256: val_mae did not improve from 4.91669\n",
      "\n",
      "Epoch 00257: val_mae did not improve from 4.91669\n",
      "\n",
      "Epoch 00258: val_mae did not improve from 4.91669\n",
      "\n",
      "Epoch 00259: val_mae did not improve from 4.91669\n",
      "\n",
      "Epoch 00260: val_mae did not improve from 4.91669\n",
      "\n",
      "Epoch 00261: val_mae did not improve from 4.91669\n",
      "\n",
      "Epoch 00262: val_mae did not improve from 4.91669\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-a42e502c5850>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m                    \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpointers\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                    \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mWORKERS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMAX_QUEUE_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                    use_multiprocessing=False, initial_epoch=201)\n\u001b[0m\u001b[1;32m     26\u001b[0m     print(\"Train Error(all epochs):\", min(best_model.history.history['mae']), '\\n',\n\u001b[1;32m     27\u001b[0m           [round(val, 3) for val in best_model.history.history['mae']])\n",
      "\u001b[0;32m~/miniconda3/envs/research/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/research/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    870\u001b[0m               \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m               \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 872\u001b[0;31m               return_dict=True)\n\u001b[0m\u001b[1;32m    873\u001b[0m           \u001b[0mval_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'val_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    874\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/research/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/research/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1055\u001b[0m           \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1057\u001b[0;31m           model=self)\n\u001b[0m\u001b[1;32m   1058\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m       \u001b[0;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/research/lib/python3.7/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model)\u001b[0m\n\u001b[1;32m   1110\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m         \u001b[0mdistribution_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1112\u001b[0;31m         model=model)\n\u001b[0m\u001b[1;32m   1113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/research/lib/python3.7/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, shuffle, workers, use_multiprocessing, max_queue_size, model, **kwargs)\u001b[0m\n\u001b[1;32m    906\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 908\u001b[0;31m         **kwargs)\n\u001b[0m\u001b[1;32m    909\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/research/lib/python3.7/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, workers, use_multiprocessing, max_queue_size, model, **kwargs)\u001b[0m\n\u001b[1;32m    773\u001b[0m     \u001b[0massert_not_namedtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpeek\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    774\u001b[0m     \u001b[0mpeek\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpeek\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 775\u001b[0;31m     \u001b[0mpeek\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_tensorlike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpeek\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m     \u001b[0;31m# Need to build the Model on concrete input shapes.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/research/lib/python3.7/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m_process_tensorlike\u001b[0;34m(inputs)\u001b[0m\n\u001b[1;32m   1011\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1013\u001b[0;31m   \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_convert_numpy_and_scipy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1014\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_list_to_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/research/lib/python3.7/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 617\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/research/lib/python3.7/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 617\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/research/lib/python3.7/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m_convert_numpy_and_scipy\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1006\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloating\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1007\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloatx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1008\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1009\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mscipy_sparse\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mscipy_sparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1010\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_scipy_sparse_to_sparse_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/research/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1340\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1341\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/research/lib/python3.7/site-packages/tensorflow/python/framework/tensor_conversion_registry.py\u001b[0m in \u001b[0;36m_default_conversion_function\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_default_conversion_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mdel\u001b[0m \u001b[0mas_ref\u001b[0m  \u001b[0;31m# Unused.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/research/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    260\u001b[0m   \"\"\"\n\u001b[1;32m    261\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0;32m--> 262\u001b[0;31m                         allow_broadcast=True)\n\u001b[0m\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/research/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    268\u001b[0m   \u001b[0mctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m     \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/research/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m     94\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if True:\n",
    "#     checkpointers = ModelCheckpoint(filepath=MODEL_PATH + str(0)+ 'new.h5',\n",
    "#                                          verbose=1, save_best_only=True, \n",
    "#                                          monitor=hyper_metric,\n",
    "#                                          mode=mode)\n",
    "    number_start = time.time()\n",
    "    train_generator = DataBatchGenerator(dataset=pu_data_reg[prev_sample:number_sample], batch_size=mini_batch,\n",
    "                                         start_idx=prev_sample, number_image_channels=number_image_channels,\n",
    "                                         max_x=max_x, max_y=max_y, float_memory_used=float_memory_used)\n",
    "    \n",
    "\n",
    "    val_size = math.ceil(number_sample * validation_size)\n",
    "    val_generator = DataBatchGenerator(dataset=pu_data_reg[number_sample:number_sample+val_size], \n",
    "                                       batch_size=mini_batch,\n",
    "                                       start_idx=number_sample,\n",
    "                                       number_image_channels=number_image_channels,\n",
    "                                       max_x=max_x, max_y=max_y, \n",
    "                                       float_memory_used=float_memory_used)\n",
    "  \n",
    "    print('number_samples:', number_sample, \", New samples:\", number_sample - prev_sample)\n",
    "    print(\"Validation size:\", val_size, \", starts:\", number_sample, \", ends:\", number_sample + val_size - 1)\n",
    "    best_model.fit(train_generator, epochs=300, verbose=0,\n",
    "                   validation_data=val_generator, shuffle=True, callbacks=[checkpointers], \n",
    "                   workers=WORKERS, max_queue_size=MAX_QUEUE_SIZE, \n",
    "                   use_multiprocessing=False, initial_epoch=201)\n",
    "    print(\"Train Error(all epochs):\", min(best_model.history.history['mae']), '\\n',\n",
    "          [round(val, 3) for val in best_model.history.history['mae']])\n",
    "    print(\"Train FP Error(all epochs):\", min(best_model.history.history['fp_mae']), '\\n',\n",
    "          [round(val,3) for val in best_model.history.history['fp_mae']])\n",
    "    print(\"Val Error(all epochs):\", min(best_model.history.history['val_mae']), '\\n', \n",
    "          [round(val,3) for val in best_model.history.history['val_mae']])\n",
    "    print(\"Val FP Error(all epochs):\", min(best_model.history.history['val_fp_mae']), '\\n',\n",
    "          [round(val,3) for val in best_model.history.history['val_fp_mae']])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test starts:  681 , ends:  29999\n",
      "58/58 [==============================] - 34s 582ms/step - loss: 105.1952 - mse: 103.6270 - mae: 8.1336 - fp_mae: 3.3546\n"
     ]
    }
   ],
   "source": [
    "best_best_model = models.load_model(MODEL_PATH + str(0) + 'new.h5', \n",
    "                               custom_objects={ 'loss': custom_loss(fp_penalty_coef, fn_penalty_coef), \n",
    "                                               'fp_mae': fp_mae,\n",
    "                                               'mae':'mae', 'mse':'mse'})\n",
    "test_generator = DataBatchGenerator(dataset=pu_data_reg[number_sample + val_size:], \n",
    "                                            batch_size=mini_batch,\n",
    "                                            start_idx=number_sample + val_size, \n",
    "                                            number_image_channels=number_image_channels,\n",
    "                                            max_x=max_x, max_y=max_y, float_memory_used=float_memory_used)\n",
    "\n",
    "print(\"Test starts: \", number_sample + val_size, \", ends: \", pu_data_reg.shape[0] - 1)\n",
    "time.sleep(1)\n",
    "test_res = best_best_model.evaluate(test_generator, verbose=1, \n",
    "                                    workers=WORKERS, max_queue_size=MAX_QUEUE_SIZE,\n",
    "                                    use_multiprocessing=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[496.0564270019531, 56.21223449707031, 5.682240009307861, 1.5113146305084229]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [105.50102233886719,\n",
       "  100.78263854980469,\n",
       "  99.25178527832031,\n",
       "  104.09859466552734,\n",
       "  104.50546264648438],\n",
       " 'mse': [44.08177185058594,\n",
       "  41.80543518066406,\n",
       "  41.379180908203125,\n",
       "  44.375244140625,\n",
       "  44.21040725708008],\n",
       " 'mae': [5.269191265106201,\n",
       "  5.1021318435668945,\n",
       "  5.071562767028809,\n",
       "  5.278663635253906,\n",
       "  5.268550872802734],\n",
       " 'fp_mae': [0.19422784447669983,\n",
       "  0.1903233528137207,\n",
       "  0.19018331170082092,\n",
       "  0.2034783661365509,\n",
       "  0.19720497727394104],\n",
       " 'val_loss': [396.6565246582031,\n",
       "  401.5822448730469,\n",
       "  435.2545166015625,\n",
       "  567.9744262695312,\n",
       "  345.01153564453125],\n",
       " 'val_mse': [120.43984985351562,\n",
       "  76.076171875,\n",
       "  161.7263946533203,\n",
       "  71.23866271972656,\n",
       "  77.79705047607422],\n",
       " 'val_mae': [9.087770462036133,\n",
       "  6.748907089233398,\n",
       "  10.751054763793945,\n",
       "  6.494345188140869,\n",
       "  6.804019927978516],\n",
       " 'val_fp_mae': [0.6868877410888672,\n",
       "  0.9997519850730896,\n",
       "  0.640586793422699,\n",
       "  1.5676021575927734,\n",
       "  0.9557649493217468]}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fac19dcf810>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.fit(train_generator, epochs=15, verbose=0,\n",
    "               validation_data=val_generator, shuffle=True, callbacks=[checkpointers], \n",
    "               workers=WORKERS, max_queue_size=MAX_QUEUE_SIZE, \n",
    "               use_multiprocessing=False, initial_epoch=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_min_mae = [8.27781, 8.23545, 8.20838]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_diff_power = [8.166, 7.844, 7.592]\n",
    "fp_mean_power = [4.56, 4.42, 4.37]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# CNN: support batching\n",
    "TEST = True\n",
    "mini_batch, epochs = 16, 30\n",
    "batch_size = (batch_size // mini_batch) * mini_batch\n",
    "prev_sample = 0\n",
    "lambda_vec = [0, 0.001, 0.003, 0.01, 0.03, 0.1, 0.3, 1, 3, 10]  #, 0.3, 1, 3, 10\n",
    "average_diff_power, fp_mean_power = [], []\n",
    "cnns = [cnn_model(10, lamb, 0) for lamb in lambda_vec]\n",
    "for cnn in cnns:\n",
    "    cnn.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse','mae'])\n",
    "for number_sample in number_samples:\n",
    "    number_start = time.time()\n",
    "    current_sample = number_sample - prev_sample\n",
    "    train_samples = [batch_size] * (current_sample//batch_size) + ([current_sample%batch_size] if \n",
    "                                                                    current_sample%batch_size else [])\n",
    "    val_size = math.ceil(number_sample * validation_size)\n",
    "#     val_samples = [batch_size] * (val_size//batch_size) + ([val_size%batch_size] if \n",
    "#                                                                val_size%batch_size else [])\n",
    "    \n",
    "    print('number_samples:', number_sample)\n",
    "    print(\"Train batches:\", train_samples)\n",
    "    for i, train_sample in enumerate(train_samples):\n",
    "        print(\"Train batch#:\", i, \", batch size:\", train_sample, \", starts:\", prev_sample + i * batch_size,\n",
    "                      \", ends:\", prev_sample + i * batch_size + train_sample - 1)\n",
    "    print(\"Validation size:\", val_size, \", starts:\", number_sample, \", ends:\", number_sample + val_size - 1)\n",
    "#     print(\"Validation Batches:\", val_samples)\n",
    "#     for i, val_sample in enumerate(val_samples):\n",
    "#         print(\"Validation batch#:\", i, \", batch size:\", val_sample, \", starts:\", number_sample + i * batch_size,\n",
    "#                       \", ends:\", number_sample + i * batch_size + val_sample - 1)\n",
    "        \n",
    "    min_error = float('inf')\n",
    "    best_model, best_lam = None, None\n",
    "    for lamb_idx, lamb in enumerate(lambda_vec):\n",
    "        lambda_start = time.time()\n",
    "        \n",
    "#         cnn = cnn_model(10, lamb, 0)\n",
    "#         cnn.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse','mae'])\n",
    "        \n",
    "        # training on all batches\n",
    "        for i, train_sample in enumerate(train_samples):\n",
    "#             if lamb_idx == 0:\n",
    "#                 print(\"Train batch#:\", i, \", batch size:\", train_sample, \", starts:\", prev_sample + i * batch_size,\n",
    "#                       \", ends:\", prev_sample + i * batch_size + train_sample - 1)\n",
    "            x_train = np.empty((train_sample, number_image_channels, max_x, max_y), dtype=float_memory_used)\n",
    "            y_train = np.empty((train_sample), dtype=float_memory_used)\n",
    "            for image_num in range(prev_sample + i * batch_size, prev_sample + i * batch_size + train_sample):\n",
    "                x_train[(image_num - prev_sample) % batch_size] = read_image(image_num)\n",
    "                y_train[(image_num - prev_sample) % batch_size] = np.asarray(data_reg[image_num][-1], \n",
    "                                                                             dtype=float_memory_used)\n",
    "            cnns[lamb_idx].fit(x_train, y_train, epochs=epochs, verbose=2, batch_size=mini_batch,\n",
    "                               validation_split=0.2, \n",
    "                               shuffle=True)\n",
    "            del x_train, y_train\n",
    "#         if lamb_idx == 0:\n",
    "#             print(\"Validation size:\", val_size, \", starts:\", number_sample, \", ends:\", \n",
    "#                   number_sample + val_size - 1)\n",
    "        print(\"\\nLambda:\", lamb)\n",
    "        print(\"Train Error(all epochs): \", cnns[lamb_idx].history.history['mae'])\n",
    "        \n",
    "        # validating\n",
    "        val_mae, val_fp_mae = 0.0, 0.0\n",
    "#         for i, val_sample in enumerate(val_samples):\n",
    "#             x_val = np.empty((val_sample, number_image_channels, max_x, max_y), dtype=float_memory_used)\n",
    "#             for image_num in range(val_sample):\n",
    "#                 x_val[image_num] = read_image(image_num + number_sample + i * batch_size)\n",
    "#             yp_val = cnns[lamb_idx].predict(x_val)\n",
    "        for image_num in range(val_size):\n",
    "            val_y = data_reg[image_num + number_sample][-1]\n",
    "            image = read_image(image_num + number_sample)\n",
    "            val_yp = cnns[lamb_idx].predict(image)[0][0]\n",
    "#             for image_num in range(val_sample):\n",
    "#                 val_yp = yp_val[image_num][0]\n",
    "#                 val_y = data_reg[image_num + number_sample + i * batch_size][-1]\n",
    "            val_mae += abs(val_y - val_yp)\n",
    "            if val_yp > val_y:\n",
    "                val_fp_mae += abs(val_yp - val_y)\n",
    "        val_mae /= val_size\n",
    "        val_fp_mae /= val_size\n",
    "        print(\"Val Error:\", round(val_mae, 3), \", Time:\", str(datetime.timedelta(seconds=int(time.time() - lambda_start))))\n",
    "        if val_mae < min_error:\n",
    "            min_error = val_mae\n",
    "            best_model = cnns[lamb_idx]\n",
    "            best_lam = lamb\n",
    "            best_lam_idx = lamb_idx\n",
    "    print(\"\\nTrainig set size:\", number_sample, \", Time:\", str(datetime.timedelta(seconds=int(time.time() - number_start)))\n",
    "          ,\", best_lambda:\", best_lam, \", min_error:\", round(min_error, 3))\n",
    "    \n",
    "    \n",
    "    if TEST:\n",
    "        # evaluating test images\n",
    "        sum_mae, sum_fp_mae = 0, 0\n",
    "        test_size = 0\n",
    "\n",
    "        y_test_p = np.empty((data_reg.shape[0] - (number_sample + val_size)), dtype=float_memory_used)\n",
    "    #     test_size = data_reg.shape[0] - (number_sample + val_size)\n",
    "    #     test_samples = [batch_size] * (test_size//batch_size) + ([test_size%batch_size] if \n",
    "    #                                                              test_size%batch_size else [])\n",
    "        print(\"Test starts: \", number_sample + val_size, \", ends: \", data_reg.shape[0] - 1)\n",
    "        time.sleep(1)\n",
    "    #     for i, test_sample in tqdm.tqdm(enumerate(test_samples)):\n",
    "    #         x_test = np.empty((test_sample, number_image_channels, max_x, max_y), dtype=float_memory_used)\n",
    "    #         for image_num in range(test_sample):\n",
    "    #             x_test[image_num] = read_image(number_sample + val_size + i * batch_size)\n",
    "    #         yp_test = cnns[best_lam_idx].predict(x_test)\n",
    "    #         for image_num in range(test_sample):\n",
    "    #             test_y = data_reg[number_sample + val_size + i * batch_size][-1]\n",
    "    #             test_yp = yp_test[image_num][0]\n",
    "    #             sum_mae += abs(test_yp - test_y)\n",
    "    #             if test_yp > test_y:\n",
    "    #                 sum_fp_mae += abs(test_yp - test_y)\n",
    "\n",
    "        for test_num in tqdm.tqdm(range(number_sample + val_size, data_reg.shape[0])):\n",
    "            test_size += 1\n",
    "            test_image = read_image(test_num)\n",
    "            test_y = data_reg[test_num][-1]\n",
    "            test_yp = best_model.predict(test_image)[0][0]\n",
    "            y_test_p[test_num - (number_sample + val_size)] = test_yp\n",
    "            sum_mae += abs(test_yp - test_y)\n",
    "            if test_yp > test_y:\n",
    "                sum_fp_mae += abs(test_yp - test_y)\n",
    "        fp_mean_power.append(round(sum_fp_mae/ test_size, 3))\n",
    "        average_diff_power.append(round(sum_mae / test_size, 3))\n",
    "        print('average_error: ', average_diff_power[-1], ', fp_average_error: ', \n",
    "              fp_mean_power[-1])\n",
    "        print(\"\\n\\n\")\n",
    "        var_f = open('/'.join(image_dir.split('/')[:-1]) +  '/' + intensity_degradation + '_' + str(slope) + '_' + \n",
    "                     dtime + \".dat\", \"wb\") # file for saving results\n",
    "        pickle.dump([average_diff_power, fp_mean_power, number_samples], file=var_f)\n",
    "        var_f.close()\n",
    "    prev_sample = number_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnns[1].weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# CNN: support batching\n",
    "prev_sample = 0\n",
    "# number_samples = [120, 200, 700]\n",
    "lambda_vec = [0, 0.001]  #0.003, 0.01, 0.03, 0.1, 0.3, 1, 3, 10\n",
    "average_diff_power, fp_mean_power = [], []\n",
    "cnns = [cnn_model(10, lamb, 0) for lamb in lambda_vec]\n",
    "for cnn in cnns:\n",
    "    cnn.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse','mae'])\n",
    "for number_sample in number_samples:\n",
    "    current_sample = number_sample - prev_sample\n",
    "    print(\"prev: \", prev_sample, \", now: \", number_sample, \", size\", current_sample) \n",
    "    train_samples = [batch_size] * (current_sample//batch_size) + ([current_sample%batch_size] if \n",
    "                                                                    current_sample%batch_size else [])\n",
    "    print(train_samples)\n",
    "    \n",
    "    min_error = float('inf')\n",
    "    best_model, best_lam = None, None\n",
    "    for lamb_idx, lamb in enumerate(lambda_vec):\n",
    "        print(\"Lambda:\", lamb)\n",
    "#         cnn = cnn_model(10, lamb, 0)\n",
    "#         cnn.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse','mae'])\n",
    "        \n",
    "        # training on all batches\n",
    "                                    \n",
    "        for i, train_sample in enumerate(train_samples):\n",
    "            for image_num in range(prev_sample + i * batch_size, prev_sample + i * batch_size + train_sample):\n",
    "                print(prev_sample + i * batch_size, prev_sample + i * batch_size + train_sample)\n",
    "                print((prev_sample + i * batch_size - prev_sample) % batch_size, \n",
    "                      (prev_sample + i * batch_size + train_sample - prev_sample)% batch_size)\n",
    "                break\n",
    "\n",
    "        \n",
    "        # validating\n",
    "        print(\"validating\")\n",
    "        val_size = math.ceil(number_sample * validation_size)\n",
    "        for image_num in range(val_size):\n",
    "            print(number_sample, val_size + number_sample)\n",
    "            break\n",
    "     \n",
    "    print(\"Test\") \n",
    "    \n",
    "    # evaluating test images\n",
    "\n",
    "    \n",
    "    for test_num in tqdm.tqdm(range(number_sample + val_size, data_reg.shape[0])):\n",
    "        print(number_sample + val_size, data_reg.shape[0])\n",
    "        break\n",
    "    prev_sample = number_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_f = open('/'.join(image_dir.split('/')[:-1]) +  '/' + 'best_cnn_4000samples' + intensity_degradation + '_' + str(slope) + '_' + \n",
    "                 dtime + \".dat\", \"wb\") # file for saving results\n",
    "pickle.dump(best_model, file=var_f)\n",
    "var_f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## use self-training\n",
    "unlabeled_train_samples = [batch_size] * (len(y_test_p)//batch_size) + ([len(y_test_p)%batch_size] if len(y_test_p)%batch_size else [])\n",
    "labeled_train_samples = [batch_size] * (number_sample//batch_size) + ([number_sample%batch_size] if number_sample%batch_size else [])   \n",
    "min_min_error = float('inf')\n",
    "best_best_model, best_best_lam = None, None\n",
    "for lamb in tqdm.tqdm(lambda_vec):\n",
    "    print(\"Lambda:\", lamb)\n",
    "    cnn = cnn_model(10, lamb, 0)\n",
    "    cnn.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse','mae'])\n",
    "#     cnn.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse','mae'])\n",
    "        \n",
    "    # training on all batches\n",
    "    # training on all batches\n",
    "    for i, train_sample in tqdm.tqdm(enumerate(labeled_train_samples)):\n",
    "        x_train = np.empty((train_sample, number_image_channels, max_x, max_y), dtype=float_memory_used)\n",
    "        y_train = np.empty((train_sample), dtype=float_memory_used)\n",
    "        for image_num in range(i * batch_size, i * batch_size + train_sample):\n",
    "            x_train[image_num % batch_size] = read_image(image_num)\n",
    "            y_train[image_num % batch_size] = np.asarray(data_reg[image_num][-1], dtype=float_memory_used)\n",
    "        cnn.fit(x_train, y_train, epochs=6, verbose=0, batch_size=1, validation_split=0.0)\n",
    "        del x_train, y_train\n",
    "            \n",
    "    for i, train_sample in tqdm.tqdm(enumerate(unlabeled_train_samples)):\n",
    "        x_train = np.empty((train_sample, number_image_channels, max_x, max_y), dtype=float_memory_used)\n",
    "        y_train = np.empty((train_sample), dtype=float_memory_used)\n",
    "        for image_num in range(i * batch_size + number_sample + val_size, i * batch_size + number_sample + val_size + train_sample):\n",
    "            x_train[(image_num-number_sample - val_size) % batch_size] = read_image(image_num)\n",
    "            y_train[(image_num-number_sample - val_size) % batch_size] = np.asarray(y_test_p[image_num-(number_sample + val_size)], dtype=float_memory_used)\n",
    "        cnn.fit(x_train, y_train, epochs=3, verbose=0, batch_size=1, validation_split=0.0)\n",
    "        del x_train, y_train\n",
    "        \n",
    "    # validating\n",
    "    val_size = math.ceil(number_sample * validation_size)\n",
    "    val_mae, val_fp_mae = 0.0, 0.0\n",
    "    for image_num in range(val_size):\n",
    "        val_y = data_reg[image_num + number_sample][-1]\n",
    "        image = read_image(image_num + number_sample)\n",
    "        val_yp = cnn.predict(image)[0][0]\n",
    "        val_mae += abs(val_y - val_yp)\n",
    "        if val_yp > val_y:\n",
    "            val_fp_mae += abs(val_yp - val_y)\n",
    "    val_mae /= val_size\n",
    "    val_fp_mae /= val_size\n",
    "    print(val_mae)\n",
    "    if val_mae < min_min_error:\n",
    "        min_min_error = val_mae\n",
    "        best_best_model = cnn\n",
    "        best_best_lam = lamb\n",
    "    sum_mae, sum_fp_mae = 0, 0\n",
    "    test_size = 0\n",
    "    \n",
    "for test_num in tqdm.tqdm(range(number_sample + val_size, data_reg.shape[0])):\n",
    "    test_size += 1\n",
    "    test_image = read_image(test_num)\n",
    "    test_y = data_reg[test_num][-1]\n",
    "    test_yp = best_best_model.predict(test_image)[0][0]\n",
    "#     y_test_p[test_num - (number_sample + val_size)] = test_yp\n",
    "    sum_mae += abs(test_yp - test_y)\n",
    "    if test_yp > test_y:\n",
    "        sum_fp_mae += abs(test_yp - test_y)\n",
    "fp_mean_power.append(round(sum_fp_mae/ test_size, 3))\n",
    "average_diff_power.append(round(sum_mae / test_size, 3))\n",
    "print('number_samples: ', number_sample, ', average_error: ', average_diff_power[-1], ' fp_average_error: ', \n",
    "      fp_mean_power[-1])\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "6.285, 6.366, 6.45, 6.454, 6.382, 6.26, 6.49, 6.224, 6.052, 5.87, 4.915, 4.836"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN\n",
    "prev_sample = 0\n",
    "lambda_vec = [0, 0.001, 0.003, 0.01, 0.03, 0.1]\n",
    "max_train_samples = math.ceil(number_samples[-1] * (1 + validation_size))\n",
    "x_train = np.empty((max_train_samples, number_image_channels, max_x, max_y), dtype=float_memory_used)\n",
    "# x_train1 = np.empty((max_train_samples, 1, max_x, max_y), dtype=float_memory_used)\n",
    "# x_train2 = np.empty((max_train_samples, 1, max_x, max_y), dtype=float_memory_used)\n",
    "y_train = np.empty((max_train_samples), dtype=float_memory_used)\n",
    "average_diff_power, fp_mean_power = [], []\n",
    "for number_sample in number_samples:\n",
    "    sample = math.ceil(number_sample * (1 + validation_size))\n",
    "    for image_num in range(prev_sample, sample):\n",
    "        prev_sample = sample\n",
    "        if style == \"image_intensity\":\n",
    "            image = plt.imread(image_dir + '/image' + str(image_num)+'.png')\n",
    "            image = np.swapaxes(image, 0, 2)\n",
    "            x_train[image_num] = np.array(image[:number_image_channels], dtype=float_memory_used).reshape(1, number_image_channels, max_x, max_y)\n",
    "            del image\n",
    "        elif  style == \"raw_power_min_max_norm\" or style == \"raw_power_zscore_norm\":\n",
    "            x_train[image_num] = np.load(image_dir + '/image' + str(image_num)+'.npy')\n",
    "#             image = np.load(image_dir + '/image' + str(image_num)+'.npy')\n",
    "#             x_train1[image_num][0] = image[0][0]\n",
    "#             x_train2[image_num][0] = image[0][1]\n",
    "        y_train[image_num] = np.asarray(data_reg[image_num][-1], dtype=float_memory_used)\n",
    "        if image_num + 1 % 100 == 0:\n",
    "            print(image_num)\n",
    "#     cnn = cnn_model(7, 0, 0)\n",
    "#     cnn.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse','mae'])\n",
    "#     cnn.fit(x_train[:sample], y_train[:sample], epochs=5, verbose=1, batch_size=1, validation_split=validation_size/\n",
    "#             (validation_size + 1))\n",
    "    \n",
    "    min_error = float('inf')\n",
    "    best_model, best_lam = None, None\n",
    "    for lamb in lambda_vec:\n",
    "        print(\"Lambda:\", lamb)\n",
    "        cnn = cnn_model(10, lamb, 0)\n",
    "        cnn.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse','mae'])\n",
    "#         cnn.fit([x_train1[:sample], x_train2[:sample]], y_train[:sample], epochs=6, verbose=1, batch_size=1, validation_split=validation_size/\n",
    "#                 (validation_size + 1))\n",
    "        cnn.fit(x_train[:sample], y_train[:sample], epochs=6, verbose=0, batch_size=1, validation_split=validation_size/\n",
    "                (validation_size + 1))\n",
    "        if cnn.history.history['val_mean_absolute_error'][-1] < min_error:\n",
    "            min_error = cnn.history.history['val_mean_absolute_error'][-1]\n",
    "            best_model = cnn\n",
    "            best_lam = lamb\n",
    "    print(\"best_lambda, \", best_lam, \"min_error\", min_error)    \n",
    "    # evaluating test images\n",
    "    sum_mae, sum_fp_mae = 0, 0\n",
    "    test_size = 0\n",
    "#     for test_num in range(max_train_samples, data_reg.shape[0]):\n",
    "    for test_num in range(sample, data_reg.shape[0]):\n",
    "        test_size += 1\n",
    "        if style == \"image_intensity\":\n",
    "            test_image = plt.imread(image_dir + '/image' + str(test_num) + '.png')\n",
    "            test_image = np.swapaxes(test_image, 0, 2)\n",
    "            test_image = np.array(test_image[:number_image_channels]).reshape(1, number_image_channels, max_x, max_y)\n",
    "        elif  style == \"raw_power_min_max_norm\" or style == \"raw_power_zscore_norm\":\n",
    "            test_image = np.load(image_dir + '/image' + str(test_num)+'.npy')\n",
    "        test_y = data_reg[test_num][-1]\n",
    "        test_yp = best_model.predict(test_image)[0][0]\n",
    "        sum_mae += abs(test_yp - test_y)\n",
    "        if test_yp > test_y:\n",
    "            sum_fp_mae += abs(test_yp - test_y)\n",
    "        if test_num % 500 == 0:\n",
    "            print('test: ', test_num)\n",
    "    fp_mean_power.append(round(sum_fp_mae/ test_size, 3))\n",
    "    average_diff_power.append(round(sum_mae / test_size, 3))\n",
    "    print('number_samples: ', number_sample, ', average_error: ', average_diff_power[-1], ' fp_average_error: ', fp_mean_power[-1])\n",
    "    print(\"\\n\")\n",
    "    var_f = open('/'.join(image_dir.split('/')[:-1]) +  '/' + intensity_degradation + '_' + str(slope) + '_' + dtime + \".dat\", \"wb\") # file for saving results\n",
    "    pickle.dump([average_diff_power, fp_mean_power, number_samples], file=var_f)\n",
    "    var_f.close()       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_diff_power[8], average_diff_power[9] = average_diff_power[9], average_diff_power[8]\n",
    "# fp_mean_power = fp_mean_power[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shapee = Input(shape=(number_image_channels, max_x, max_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shapee[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = cnn_model(1, 0)\n",
    "cnn.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse','mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cnn.history.history['val_mean_absolute_error'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = cnn_model(10, 0, 0)\n",
    "cnn.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse','mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cnn.fit(x_train[:sample], y_train[:sample], epochs=5, verbose=1, batch_size=1, validation_split=validation_size/\n",
    "            (validation_size + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_vec = [0, 0.001, 0.003, 0.01, 0.03, 0.1, 0.3, 1, 3]\n",
    "min_error = float('inf')\n",
    "best_model, best_lam = None, None\n",
    "for lamb in lambda_vec:\n",
    "    print(\"Lambda:\", lamb)\n",
    "    cnn = cnn_model(15, lamb, 0)\n",
    "    cnn.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse','mae'])\n",
    "    cnn.fit(x_train[:sample], y_train[:sample], epochs=5, verbose=1, batch_size=1, validation_split=validation_size/\n",
    "            (validation_size + 1))\n",
    "    if cnn.history.history['val_mean_absolute_error'][-1] < min_error:\n",
    "        min_error = cnn.history.history['val_mean_absolute_error'][-1]\n",
    "        best_model = cnn\n",
    "        best_lam = lamb\n",
    "    print(\"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_lam)\n",
    "print(best_model.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# just run to dispaly the image. First change return line from create_image\n",
    "aa = np.swapaxes(np.append(np.array(x_train[50]), np.zeros((2,max_x, max_y), dtype=float_memory_used), axis=0), 0, 2)\n",
    "plt.imshow(aa)\n",
    "# plt.imsave('image.png', aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_diff_power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this cell to read saved variables\n",
    "var_ff = open('ML/data/pictures_1000_1000/log_201912_0705_37.txt', 'rb')\n",
    "[average_diff_power_1, fp_mean_power_1, number_samples_1] = pickle.load(var_ff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_mean_power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_diff_power[-1]*(data_reg.shape[0] - max_train_samples)/(300-sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_fp_mae/200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_mean_power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import pydotplus\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "keras.utils.vis_utils.pydot = pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARALLEL CNN\n",
    "def cnn_model(num_filters, kernel_lam, bias_lam):\n",
    "#     num_filters, lam = 5, 5\n",
    "    data_format = 'channels_first'\n",
    "    convolution_filter, dense_filter = 'selu', 'linear' #softsign, sigmoid; relu, linear\n",
    "    filter_shape, pool_size = (3, 3), (2,2)\n",
    "    # CNN for PU image\n",
    "    input1  = layers.Input(shape=(number_image_channels - 1, max_x, max_y), name='pus_input')\n",
    "    x1 = layers.Conv2D(num_filters, filter_shape, padding='same', activation=convolution_filter, \n",
    "                          input_shape=(number_image_channels - 1, max_x, max_y), data_format=data_format,\n",
    "                          kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "                          kernel_initializer='lecun_normal')(input1)\n",
    "    x1 = layers.MaxPooling2D(pool_size=pool_size, data_format=data_format)(x1)\n",
    "    \n",
    "    x1 = layers.Conv2D(num_filters, filter_shape, padding='same', activation=convolution_filter, \n",
    "                          input_shape=(number_image_channels - 1, max_x, max_y), data_format=data_format,\n",
    "                          kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "                          kernel_initializer='lecun_normal')(x1)\n",
    "    x1 = layers.MaxPooling2D(pool_size=pool_size, data_format=data_format)(x1)\n",
    "    \n",
    "    x1 = layers.Conv2D(num_filters, filter_shape, padding='same', activation=convolution_filter, \n",
    "                          input_shape=(number_image_channels - 1, max_x, max_y), data_format=data_format,\n",
    "                          kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "                          kernel_initializer='lecun_normal')(x1)\n",
    "    x1 = layers.MaxPooling2D(pool_size=pool_size, data_format=data_format)(x1)\n",
    "    \n",
    "    x1 = layers.Conv2D(num_filters, filter_shape, padding='same', activation=convolution_filter, \n",
    "                          input_shape=(number_image_channels - 1, max_x, max_y), data_format=data_format,\n",
    "                          kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "                          kernel_initializer='lecun_normal')(x1)\n",
    "    x1 = layers.MaxPooling2D(pool_size=pool_size, data_format=data_format)(x1)\n",
    "    \n",
    "    x1 = layers.Conv2D(num_filters, filter_shape, padding='same', activation=convolution_filter, \n",
    "                          input_shape=(number_image_channels - 1, max_x, max_y), data_format=data_format,\n",
    "                          kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "                          kernel_initializer='lecun_normal')(x1)\n",
    "    x1 = layers.MaxPooling2D(pool_size=pool_size, data_format=data_format)(x1)\n",
    "    \n",
    "    \n",
    "    # CNN for SU\n",
    "    input2  = layers.Input(shape=(1, max_x, max_y), name='su_input')\n",
    "    x2 = layers.Conv2D(num_filters, filter_shape, padding='same', activation=convolution_filter, \n",
    "                          input_shape=(1, max_x, max_y), data_format=data_format,\n",
    "                          kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "                          kernel_initializer='lecun_normal')(input2)\n",
    "    x2 = layers.MaxPooling2D(pool_size=pool_size, data_format=data_format)(x2)\n",
    "    \n",
    "    x2 = layers.Conv2D(num_filters, filter_shape, padding='same', activation=convolution_filter, \n",
    "                          input_shape=(1, max_x, max_y), data_format=data_format,\n",
    "                          kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "                          kernel_initializer='lecun_normal')(x2)\n",
    "    x2 = layers.MaxPooling2D(pool_size=pool_size, data_format=data_format)(x2)\n",
    "    \n",
    "    x2 = layers.Conv2D(num_filters, filter_shape, padding='same', activation=convolution_filter, \n",
    "                          input_shape=(1, max_x, max_y), data_format=data_format,\n",
    "                          kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "                          kernel_initializer='lecun_normal')(x2)\n",
    "    x2 = layers.MaxPooling2D(pool_size=pool_size, data_format=data_format)(x2)\n",
    "    \n",
    "    x2 = layers.Conv2D(num_filters, filter_shape, padding='same', activation=convolution_filter, \n",
    "                          input_shape=(1, max_x, max_y), data_format=data_format,\n",
    "                          kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "                          kernel_initializer='lecun_normal')(x2)\n",
    "    x2 = layers.MaxPooling2D(pool_size=pool_size, data_format=data_format)(x2)\n",
    "    \n",
    "    x2 = layers.Conv2D(num_filters, filter_shape, padding='same', activation=convolution_filter, \n",
    "                          input_shape=(1, max_x, max_y), data_format=data_format,\n",
    "                          kernel_regularizer=regularizers.l2(kernel_lam), bias_regularizer=regularizers.l2(bias_lam),\n",
    "                          kernel_initializer='lecun_normal')(x2)\n",
    "    x2 = layers.MaxPooling2D(pool_size=pool_size, data_format=data_format)(x2)\n",
    "    \n",
    "    \n",
    "    # concatanate two CNN outputs\n",
    "    x = layers.concatenate([x1, x2])\n",
    "    x = layers.Flatten()(x)\n",
    "    \n",
    "    x = layers.Dense(20, activation=convolution_filter, kernel_regularizer=regularizers.l2(kernel_lam),\n",
    "                         bias_regularizer=regularizers.l2(bias_lam), kernel_initializer='lecun_normal')(x)\n",
    "    x = layers.Dense(20, activation=convolution_filter, kernel_regularizer=regularizers.l2(kernel_lam),\n",
    "                         bias_regularizer=regularizers.l2(bias_lam), kernel_initializer='lecun_normal')(x)\n",
    "    out = layers.Dense(1, activation=dense_filter, kernel_regularizer=regularizers.l2(kernel_lam),\n",
    "                         bias_regularizer=regularizers.l2(bias_lam), kernel_initializer='lecun_normal')(x)\n",
    "    \n",
    "    model = models.Model(inputs=[input1, input2], outputs=out)\n",
    "#     plot_model(model, to_file='model.png')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number_samples = [5] + list(range(10, 101, 10)) + [120, 150, 200, 250, 300, 400, 500, 700] + list(range(1000, 1001, 1000))\n",
    "\n",
    "# validation_size, noise_floor = 0.33, -90.0\n",
    "# su_power = 0 # this is not actually su power just a number to show there is an SU in its image\n",
    "# max_x, max_y, number_image_channels, su_szie = 1000, 1000, 2, 10\n",
    "# pu_shape, su_shape = 'circle', 'square'\n",
    "# style = \"image_intensity\"  # {\"raw_power_zscore_norm\", \"image_intensity\", \"raw_power_min_max_norm\"}\n",
    "# pus_num, intensity_degradation, slope = 15, 'log', 4\n",
    "# average_diff_power = [9.110476626067186, 21.070721128267266, 9.389938883165568, 10.886098907990405,\n",
    "#                                        7.697396928362106, 7.522477509027216, 9.493729427772132, 8.198866980620753,\n",
    "#                                        7.781910785203122, 9.41743984825801, 8.499455442627129, 9.86776958065812,\n",
    "#                                        9.033719411254367, 8.150143941293027, 8.963829050517273, 8.708150642874065,\n",
    "#                                        7.468060397898071, 8.233182799553932,8.206, 7.768]\n",
    "# fp_mean_power =  [8.174990557021465, 0.18043087058937837, 1.5141939559853392, 10.273307557711494,\n",
    "#                                    3.2306742061521443, 4.423113329284006, 8.674172526579392, 2.38235061342411,\n",
    "#                                    5.014172646429496, 6.884079514994618, 3.4544130456368367, 7.81721202679044,\n",
    "#                                    6.438635364829745, 4.069245107144559, 5.202978504937615, 3.405858414831347,\n",
    "#                                    4.117573271657338, 2.8100743146184377, 3.951, 3.502]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MAX_POWER ANAlysis\n",
    "# number_samples = [5] + list(range(10, 101, 10)) + [120, 150, 200, 250, 300, 400, 500, 700] + list(range(1000, 1001, 1000))\n",
    "\n",
    "# validation_size, noise_floor = 0.33, -90.0\n",
    "# su_power = 0 # this is not actually su power just a number to show there is an SU in its image\n",
    "# max_x, max_y, number_image_channels, su_szie = 1000, 1000, 2, 10\n",
    "# pus_num, intensity_degradation, slope = 15, 'log', 4\n",
    "# pu_shape, su_shape = 'circle', 'circle'\n",
    "# style = \"image_intensity\"  # {\"raw_power_zscore_norm\", \"image_intensity\", \"raw_power_min_max_norm\"}\n",
    "# test_size = 3670\n",
    "# average_diff_power = [7.811849328268183, 9.178415418536536, 8.11891504382307, 7.881934146750136, 7.918868224324312,\n",
    "#                       7.709452054502398, 7.471729821563216, 8.63783455122861, 7.7635068514166345, 8.557134470036884,\n",
    "#                       8.103793715416188, 9.189284948409279, 11.977416480154307, 8.291134394492891, 8.960065032512803,\n",
    "#                       9.992745143323642, 8.475335283779392, 8.051642160173987, 7.322538645284376, 7.768582958795206]\n",
    "# fp_mean_power = [6.1844398077234635, 1.6157812496465958, 6.5620574110067595, 2.898169187355567, 6.262096880097353,\n",
    "#                  2.5478307871639267, 3.5784209073932067, 7.416731632966506, 5.5822838290638135, 5.800529848947965,\n",
    "#                  4.6984887763519785, 2.337296353076653, 9.85739104089764, 3.710259461284922, 5.323224159423669, \n",
    "#                  6.198328912769283, 2.302462751745074, 4.023802978234984, 3.781413967880959, 3.2793608103510508]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INIT\n",
    "# number_samples = [5] + list(range(10, 101, 10)) + [120, 150, 200, 250, 300, 400, 500, 700] + list(range(1000, 1001, 1000))\n",
    "\n",
    "# validation_size, noise_floor = 0.33, -90.0\n",
    "# su_power = 0 # this is not actually su power just a number to show there is an SU in its image\n",
    "# max_x, max_y, number_image_channels, su_szie = 1000, 1000, 2, 10\n",
    "# pu_shape, su_shape = 'circle', 'circle'\n",
    "# style = \"raw_power_min_max_norm\"  # {\"raw_power_zscore_norm\", \"image_intensity\", \"raw_power_min_max_norm\"}\n",
    "# pus_num, intensity_degradation, slope = 15, 'log', 4\n",
    "# if su_shape == 'circle':\n",
    "#     su_param = Circle(su_szie)\n",
    "# elif su_shape == 'square':\n",
    "#     su_param = Square(su_szie)\n",
    "# num_pus = 15\n",
    "average_diff_power = [9.711, 7.867, 8.958, 7.571, 7.509, 7.891, 8.272, 7.118, 7.696, 7.689, 8.026, 9.674, 7.51, 7.771, 8.17,\n",
    "                      7.938, 7.869, 7.833, 9.434, 8.501]\n",
    "fp_mean_power = [9.229, 5.101, 8.037, 3.993, 5.095, 2.491, 2.298, 4.654, 3.787, 2.685, 5.676, 8.033, 3.911, 4.235, 3.278,\n",
    "                 5.809, 3.586, 4.257, 4.377, 5.015]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INIT\n",
    "\n",
    "# number_samples = [120, 150, 200, 250, 300, 400, 500, 700] + list(range(1000, 8001, 1000))\n",
    "\n",
    "\n",
    "# cnn_type = \"classification\"  # {\"classification\", \"regression\"}\n",
    "# validation_size, noise_floor = 0.33, -90.0\n",
    "# su_power = 0 # this is not actually su power just a number to show there is an SU in its image\n",
    "# max_x, max_y, number_image_channels, su_szie = 200, 200, 2, 10\n",
    "# pu_shape, su_shape = 'circle', 'circle' # shape = {'circle', 'square', 'point'}\n",
    "# style = \"raw_power_min_max_norm\"  # {\"raw_power_zscore_norm\", \"image_intensity\", \"raw_power_min_max_norm\"}\n",
    "# pus_num, intensity_degradation, slope = 15, 'log', 4\n",
    "# if su_shape == 'circle':\n",
    "#     su_param = Circle(su_szie)\n",
    "# elif su_shape == 'square':\n",
    "#     su_param = Square(su_szie)\n",
    "# else:\n",
    "#     su_param = None\n",
    "# sensors = False\n",
    "# if sensors:\n",
    "#     sensors_num = 50\n",
    "#     sensors_file_path = \"rsc/\" + str(sensors_num) + \"/sensors\"\n",
    "    \n",
    "average_diff_power = [6.779, 5.645, 5.473, 4.982, 4.481, 4.071, 4.05, 3.639, 2.813, 2.343, 2.21, 2.372, 2.005, 1.997,\n",
    "                      1.937, 1.901]\n",
    "\n",
    "fp_mean_power = [4.073, 2.409, 3.424, 3.163, 2.833, 2.663, 2.857, 2.744, 1.744, 1.33, 1.184, 1.55, 0.579, 1.216, 1.492, 1.266]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INIT\n",
    "\n",
    "number_samples = [120, 150, 200, 250, 300, 400, 500, 700] + list(range(1000, 6001, 1000)) + [8000]\n",
    "# dataframe = pd.read_csv('ML/data/dynamic_pus_using_pus50000_15PUs_201912_3000_40_200.txt', delimiter=',', header=None)\n",
    "# dataframe_max = pd.read_csv('ML/data/dynamic_pus_max_power50000_15PUs_201912_3000_40_200.txt', delimiter=',', header=None)\n",
    "\n",
    "\n",
    "# validation_size, noise_floor = 0.33, -90.0\n",
    "# su_power = 0 # this is not actually su power just a number to show there is an SU in its image\n",
    "# max_x, max_y, number_image_channels, su_szie = 200, 200, 4, 10\n",
    "# pu_shape, su_shape = 'circle', 'circle' # shape = {'circle', 'square', 'point'}\n",
    "# style = \"raw_power_min_max_norm\"  # {\"raw_power_zscore_norm\", \"image_intensity\", \"raw_power_min_max_norm\"}\n",
    "# pus_num, intensity_degradation, slope = 15, 'log', 5\n",
    "# if su_shape == 'circle':\n",
    "#     su_param = Circle(su_szie)\n",
    "# elif su_shape == 'square':\n",
    "#     su_param = Square(su_szie)\n",
    "# else:\n",
    "#     su_param = None\n",
    "# sensors = False\n",
    "    \n",
    "average_diff_power = [12.742, 12.906, 12.731, 12.595, 12.859, 13.272, 12.632, 12.647, 11.309, 7.455, 7.131, 5.677,\n",
    "                      5.645, 5.292, 4.445]\n",
    "\n",
    "fp_mean_power = [5.963, 5.861, 8.957, 8.821, 8.215, 9.518, 8.633, 6.644, 6.605, 3.919, 2.539, 3.866, 1.96, 2.717, 1.671]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(average_diff_power)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_width = 5\n",
    "marker_size = 12\n",
    "reg_style = 'solid'\n",
    "class_reg = 'dashed'\n",
    "fig = plt.figure(figsize=(15,8))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "plt.plot(number_samples, average_diff_power, color='r', linewidth=line_width, markersize=marker_size, linestyle=class_reg)\n",
    "plt.plot(number_samples, fp_mean_power, color='midnightblue', linewidth=line_width, markersize=marker_size, linestyle=class_reg)\n",
    "plt.xlabel('# of Training Samples', fontsize=47)\n",
    "plt.ylabel('Avg. Diff. wrt Opt. (dB)', fontsize=45)\n",
    "plt.title('Dynamic PUs(200m*200m)')\n",
    "plt.grid(True)\n",
    "\n",
    "ax.set_yticks(np.arange(0,14, 2))\n",
    "# ax.set_xticks(np.arange(100,7000, 1500))\n",
    "plt.rcParams.update({'font.size': 42})\n",
    "ax.tick_params(axis='x', labelsize=46)\n",
    "ax.tick_params(axis='y', labelsize=45)\n",
    "\n",
    "# matplotlib.rcParams.update({'font.size': 22})\n",
    "\n",
    "ax.set_ylim([0, 14])\n",
    "ax.set_xlim([0, 8000])\n",
    "plt.legend(['Total', 'False-Positive'], ncol=2, loc='best', handletextpad=0.1,borderpad=0, columnspacing=0.2, borderaxespad=0.2)\n",
    "# plt.legend(handletextpad=0.1)\n",
    "plt.savefig('/'.join(image_dir.split('/')[:-1]) +  '/' + intensity_degradation + '_' + str(slope) + '_' + dtime + \".png\", \n",
    "            bbox_inches = 'tight', pad_inches = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.load(image_dir + '/image10.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('/'.join(image_dir.split('/')[:-1]) + '/log_5__202006_2714_19.dat', 'rb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('/home/shahrokh/projects/research/MLSpectrumAllocation/ML/data/pictures_1000_1000/log/noisy_std_1/' +\n",
    "            'pu_circle_su_circle_30/raw_power_min_max_norm/color/log_4/pus/log_4__202005_0512_10.dat', 'rb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[average_diff_power, fp_mean_power, number_samples, best_lambda, \n",
    " dataset_name, max_dataset_name, average_power_conserve, \n",
    " fp_mean_power_conserve] = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(number_samples)\n",
    "print(average_diff_power)\n",
    "print(fp_mean_power)\n",
    "print(best_lambda)\n",
    "print(average_power_conserve)\n",
    "print(fp_mean_power_conserve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fp1, fp2, fp3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(samples1, samples2, samples3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(samples3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
